{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5305-Final Project -Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This files executes second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a custom `InsuranceDataset` class that inherits the `Dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = pd.read_csv('./insurance_data_imputed.csv')\n",
    "        self.X = self.data.drop('premium_amount', axis=1)\n",
    "        self.y = self.data['premium_amount']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X.iloc[idx].values, dtype=torch.float32), torch.tensor(self.y.iloc[idx], dtype=torch.float32)\n",
    "\n",
    "dataset = InsuranceDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'annual_income', 'marital_status',\n",
       "       'number_of_dependents', 'education_level', 'health_score', 'location',\n",
       "       'policy_type', 'previous_claims', 'credit_score', 'insurance_duration',\n",
       "       'smoking_status', 'exercise_frequency', 'occupation_employed',\n",
       "       'occupation_self_employed', 'occupation_unemployed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward Neural Network with 2 hidden layers, with 64 and 32 neurons respectively\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(17, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5) #Dropout rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.output(x)\n",
    "\n",
    "model = FeedForwardNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, testing and validation data\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = int(0.15 * len(dataset))\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/4091], Loss: 617.9430\n",
      "Epoch [1/100], Step [200/4091], Loss: 800.2217\n",
      "Epoch [1/100], Step [300/4091], Loss: 672.3403\n",
      "Epoch [1/100], Step [400/4091], Loss: 815.2747\n",
      "Epoch [1/100], Step [500/4091], Loss: 600.0973\n",
      "Epoch [1/100], Step [600/4091], Loss: 589.1080\n",
      "Epoch [1/100], Step [700/4091], Loss: 541.2977\n",
      "Epoch [1/100], Step [800/4091], Loss: 565.2228\n",
      "Epoch [1/100], Step [900/4091], Loss: 670.4905\n",
      "Epoch [1/100], Step [1000/4091], Loss: 735.6033\n",
      "Epoch [1/100], Step [1100/4091], Loss: 775.3809\n",
      "Epoch [1/100], Step [1200/4091], Loss: 867.5320\n",
      "Epoch [1/100], Step [1300/4091], Loss: 920.0582\n",
      "Epoch [1/100], Step [1400/4091], Loss: 647.6493\n",
      "Epoch [1/100], Step [1500/4091], Loss: 583.6855\n",
      "Epoch [1/100], Step [1600/4091], Loss: 733.9309\n",
      "Epoch [1/100], Step [1700/4091], Loss: 862.0131\n",
      "Epoch [1/100], Step [1800/4091], Loss: 590.0995\n",
      "Epoch [1/100], Step [1900/4091], Loss: 613.2690\n",
      "Epoch [1/100], Step [2000/4091], Loss: 477.7712\n",
      "Epoch [1/100], Step [2100/4091], Loss: 666.1180\n",
      "Epoch [1/100], Step [2200/4091], Loss: 538.6912\n",
      "Epoch [1/100], Step [2300/4091], Loss: 472.7277\n",
      "Epoch [1/100], Step [2400/4091], Loss: 720.6018\n",
      "Epoch [1/100], Step [2500/4091], Loss: 569.0754\n",
      "Epoch [1/100], Step [2600/4091], Loss: 558.0707\n",
      "Epoch [1/100], Step [2700/4091], Loss: 718.2479\n",
      "Epoch [1/100], Step [2800/4091], Loss: 420.0019\n",
      "Epoch [1/100], Step [2900/4091], Loss: 752.1418\n",
      "Epoch [1/100], Step [3000/4091], Loss: 653.6915\n",
      "Epoch [1/100], Step [3100/4091], Loss: 641.2347\n",
      "Epoch [1/100], Step [3200/4091], Loss: 1110.9961\n",
      "Epoch [1/100], Step [3300/4091], Loss: 496.9872\n",
      "Epoch [1/100], Step [3400/4091], Loss: 719.1033\n",
      "Epoch [1/100], Step [3500/4091], Loss: 497.3764\n",
      "Epoch [1/100], Step [3600/4091], Loss: 846.8559\n",
      "Epoch [1/100], Step [3700/4091], Loss: 621.4363\n",
      "Epoch [1/100], Step [3800/4091], Loss: 588.8256\n",
      "Epoch [1/100], Step [3900/4091], Loss: 741.2473\n",
      "Epoch [1/100], Step [4000/4091], Loss: 669.7282\n",
      "Epoch [2/100], Step [100/4091], Loss: 633.0778\n",
      "Epoch [2/100], Step [200/4091], Loss: 497.1234\n",
      "Epoch [2/100], Step [300/4091], Loss: 645.4584\n",
      "Epoch [2/100], Step [400/4091], Loss: 449.2123\n",
      "Epoch [2/100], Step [500/4091], Loss: 510.6795\n",
      "Epoch [2/100], Step [600/4091], Loss: 782.2827\n",
      "Epoch [2/100], Step [700/4091], Loss: 727.9144\n",
      "Epoch [2/100], Step [800/4091], Loss: 470.3954\n",
      "Epoch [2/100], Step [900/4091], Loss: 457.9848\n",
      "Epoch [2/100], Step [1000/4091], Loss: 639.0861\n",
      "Epoch [2/100], Step [1100/4091], Loss: 698.7955\n",
      "Epoch [2/100], Step [1200/4091], Loss: 776.7186\n",
      "Epoch [2/100], Step [1300/4091], Loss: 613.3259\n",
      "Epoch [2/100], Step [1400/4091], Loss: 535.1401\n",
      "Epoch [2/100], Step [1500/4091], Loss: 581.0455\n",
      "Epoch [2/100], Step [1600/4091], Loss: 592.4925\n",
      "Epoch [2/100], Step [1700/4091], Loss: 539.5890\n",
      "Epoch [2/100], Step [1800/4091], Loss: 561.6201\n",
      "Epoch [2/100], Step [1900/4091], Loss: 686.0731\n",
      "Epoch [2/100], Step [2000/4091], Loss: 776.1015\n",
      "Epoch [2/100], Step [2100/4091], Loss: 793.5642\n",
      "Epoch [2/100], Step [2200/4091], Loss: 1017.3218\n",
      "Epoch [2/100], Step [2300/4091], Loss: 720.2946\n",
      "Epoch [2/100], Step [2400/4091], Loss: 827.1251\n",
      "Epoch [2/100], Step [2500/4091], Loss: 771.3295\n",
      "Epoch [2/100], Step [2600/4091], Loss: 580.9427\n",
      "Epoch [2/100], Step [2700/4091], Loss: 675.2975\n",
      "Epoch [2/100], Step [2800/4091], Loss: 637.9393\n",
      "Epoch [2/100], Step [2900/4091], Loss: 610.0264\n",
      "Epoch [2/100], Step [3000/4091], Loss: 771.5358\n",
      "Epoch [2/100], Step [3100/4091], Loss: 724.6060\n",
      "Epoch [2/100], Step [3200/4091], Loss: 473.2214\n",
      "Epoch [2/100], Step [3300/4091], Loss: 622.3755\n",
      "Epoch [2/100], Step [3400/4091], Loss: 420.3082\n",
      "Epoch [2/100], Step [3500/4091], Loss: 928.8300\n",
      "Epoch [2/100], Step [3600/4091], Loss: 418.6189\n",
      "Epoch [2/100], Step [3700/4091], Loss: 482.1684\n",
      "Epoch [2/100], Step [3800/4091], Loss: 923.7856\n",
      "Epoch [2/100], Step [3900/4091], Loss: 914.7841\n",
      "Epoch [2/100], Step [4000/4091], Loss: 664.9708\n",
      "Epoch [3/100], Step [100/4091], Loss: 663.2526\n",
      "Epoch [3/100], Step [200/4091], Loss: 638.1774\n",
      "Epoch [3/100], Step [300/4091], Loss: 692.6946\n",
      "Epoch [3/100], Step [400/4091], Loss: 734.3969\n",
      "Epoch [3/100], Step [500/4091], Loss: 558.0819\n",
      "Epoch [3/100], Step [600/4091], Loss: 551.8873\n",
      "Epoch [3/100], Step [700/4091], Loss: 756.2631\n",
      "Epoch [3/100], Step [800/4091], Loss: 524.3222\n",
      "Epoch [3/100], Step [900/4091], Loss: 595.8242\n",
      "Epoch [3/100], Step [1000/4091], Loss: 474.1263\n",
      "Epoch [3/100], Step [1100/4091], Loss: 571.1493\n",
      "Epoch [3/100], Step [1200/4091], Loss: 618.9689\n",
      "Epoch [3/100], Step [1300/4091], Loss: 848.3154\n",
      "Epoch [3/100], Step [1400/4091], Loss: 751.1542\n",
      "Epoch [3/100], Step [1500/4091], Loss: 582.0594\n",
      "Epoch [3/100], Step [1600/4091], Loss: 840.3221\n",
      "Epoch [3/100], Step [1700/4091], Loss: 713.2516\n",
      "Epoch [3/100], Step [1800/4091], Loss: 480.6417\n",
      "Epoch [3/100], Step [1900/4091], Loss: 494.4980\n",
      "Epoch [3/100], Step [2000/4091], Loss: 802.2903\n",
      "Epoch [3/100], Step [2100/4091], Loss: 724.2119\n",
      "Epoch [3/100], Step [2200/4091], Loss: 627.9803\n",
      "Epoch [3/100], Step [2300/4091], Loss: 677.4095\n",
      "Epoch [3/100], Step [2400/4091], Loss: 506.8768\n",
      "Epoch [3/100], Step [2500/4091], Loss: 712.9309\n",
      "Epoch [3/100], Step [2600/4091], Loss: 771.8994\n",
      "Epoch [3/100], Step [2700/4091], Loss: 866.0718\n",
      "Epoch [3/100], Step [2800/4091], Loss: 612.7107\n",
      "Epoch [3/100], Step [2900/4091], Loss: 746.7781\n",
      "Epoch [3/100], Step [3000/4091], Loss: 538.6383\n",
      "Epoch [3/100], Step [3100/4091], Loss: 717.8932\n",
      "Epoch [3/100], Step [3200/4091], Loss: 520.8962\n",
      "Epoch [3/100], Step [3300/4091], Loss: 611.0946\n",
      "Epoch [3/100], Step [3400/4091], Loss: 540.2123\n",
      "Epoch [3/100], Step [3500/4091], Loss: 539.2079\n",
      "Epoch [3/100], Step [3600/4091], Loss: 621.5843\n",
      "Epoch [3/100], Step [3700/4091], Loss: 633.3993\n",
      "Epoch [3/100], Step [3800/4091], Loss: 431.8450\n",
      "Epoch [3/100], Step [3900/4091], Loss: 422.9467\n",
      "Epoch [3/100], Step [4000/4091], Loss: 796.5096\n",
      "Epoch [4/100], Step [100/4091], Loss: 680.1865\n",
      "Epoch [4/100], Step [200/4091], Loss: 617.5605\n",
      "Epoch [4/100], Step [300/4091], Loss: 648.1790\n",
      "Epoch [4/100], Step [400/4091], Loss: 695.3711\n",
      "Epoch [4/100], Step [500/4091], Loss: 619.5558\n",
      "Epoch [4/100], Step [600/4091], Loss: 417.4418\n",
      "Epoch [4/100], Step [700/4091], Loss: 695.3989\n",
      "Epoch [4/100], Step [800/4091], Loss: 731.2589\n",
      "Epoch [4/100], Step [900/4091], Loss: 520.3303\n",
      "Epoch [4/100], Step [1000/4091], Loss: 681.2781\n",
      "Epoch [4/100], Step [1100/4091], Loss: 714.5035\n",
      "Epoch [4/100], Step [1200/4091], Loss: 587.1967\n",
      "Epoch [4/100], Step [1300/4091], Loss: 852.7411\n",
      "Epoch [4/100], Step [1400/4091], Loss: 500.0714\n",
      "Epoch [4/100], Step [1500/4091], Loss: 551.1186\n",
      "Epoch [4/100], Step [1600/4091], Loss: 592.2104\n",
      "Epoch [4/100], Step [1700/4091], Loss: 810.8030\n",
      "Epoch [4/100], Step [1800/4091], Loss: 527.1268\n",
      "Epoch [4/100], Step [1900/4091], Loss: 447.0304\n",
      "Epoch [4/100], Step [2000/4091], Loss: 517.9988\n",
      "Epoch [4/100], Step [2100/4091], Loss: 751.1467\n",
      "Epoch [4/100], Step [2200/4091], Loss: 724.5226\n",
      "Epoch [4/100], Step [2300/4091], Loss: 529.9421\n",
      "Epoch [4/100], Step [2400/4091], Loss: 593.7762\n",
      "Epoch [4/100], Step [2500/4091], Loss: 618.0529\n",
      "Epoch [4/100], Step [2600/4091], Loss: 734.3429\n",
      "Epoch [4/100], Step [2700/4091], Loss: 651.9675\n",
      "Epoch [4/100], Step [2800/4091], Loss: 622.3134\n",
      "Epoch [4/100], Step [2900/4091], Loss: 557.2424\n",
      "Epoch [4/100], Step [3000/4091], Loss: 581.8669\n",
      "Epoch [4/100], Step [3100/4091], Loss: 567.7114\n",
      "Epoch [4/100], Step [3200/4091], Loss: 562.6772\n",
      "Epoch [4/100], Step [3300/4091], Loss: 664.9999\n",
      "Epoch [4/100], Step [3400/4091], Loss: 750.8200\n",
      "Epoch [4/100], Step [3500/4091], Loss: 806.4036\n",
      "Epoch [4/100], Step [3600/4091], Loss: 481.3336\n",
      "Epoch [4/100], Step [3700/4091], Loss: 679.5591\n",
      "Epoch [4/100], Step [3800/4091], Loss: 577.8773\n",
      "Epoch [4/100], Step [3900/4091], Loss: 530.9722\n",
      "Epoch [4/100], Step [4000/4091], Loss: 703.1765\n",
      "Epoch [5/100], Step [100/4091], Loss: 661.5076\n",
      "Epoch [5/100], Step [200/4091], Loss: 649.0937\n",
      "Epoch [5/100], Step [300/4091], Loss: 1139.7323\n",
      "Epoch [5/100], Step [400/4091], Loss: 668.0886\n",
      "Epoch [5/100], Step [500/4091], Loss: 722.6296\n",
      "Epoch [5/100], Step [600/4091], Loss: 507.6263\n",
      "Epoch [5/100], Step [700/4091], Loss: 711.6649\n",
      "Epoch [5/100], Step [800/4091], Loss: 557.6980\n",
      "Epoch [5/100], Step [900/4091], Loss: 614.1232\n",
      "Epoch [5/100], Step [1000/4091], Loss: 755.7112\n",
      "Epoch [5/100], Step [1100/4091], Loss: 450.4390\n",
      "Epoch [5/100], Step [1200/4091], Loss: 549.5894\n",
      "Epoch [5/100], Step [1300/4091], Loss: 976.8966\n",
      "Epoch [5/100], Step [1400/4091], Loss: 719.9614\n",
      "Epoch [5/100], Step [1500/4091], Loss: 564.2606\n",
      "Epoch [5/100], Step [1600/4091], Loss: 867.1147\n",
      "Epoch [5/100], Step [1700/4091], Loss: 739.8282\n",
      "Epoch [5/100], Step [1800/4091], Loss: 868.9585\n",
      "Epoch [5/100], Step [1900/4091], Loss: 622.6641\n",
      "Epoch [5/100], Step [2000/4091], Loss: 707.0974\n",
      "Epoch [5/100], Step [2100/4091], Loss: 677.1759\n",
      "Epoch [5/100], Step [2200/4091], Loss: 468.6666\n",
      "Epoch [5/100], Step [2300/4091], Loss: 678.0045\n",
      "Epoch [5/100], Step [2400/4091], Loss: 440.8075\n",
      "Epoch [5/100], Step [2500/4091], Loss: 736.2964\n",
      "Epoch [5/100], Step [2600/4091], Loss: 669.7679\n",
      "Epoch [5/100], Step [2700/4091], Loss: 678.6650\n",
      "Epoch [5/100], Step [2800/4091], Loss: 557.7891\n",
      "Epoch [5/100], Step [2900/4091], Loss: 534.3696\n",
      "Epoch [5/100], Step [3000/4091], Loss: 646.4595\n",
      "Epoch [5/100], Step [3100/4091], Loss: 594.4501\n",
      "Epoch [5/100], Step [3200/4091], Loss: 806.5609\n",
      "Epoch [5/100], Step [3300/4091], Loss: 647.6249\n",
      "Epoch [5/100], Step [3400/4091], Loss: 592.0692\n",
      "Epoch [5/100], Step [3500/4091], Loss: 578.6918\n",
      "Epoch [5/100], Step [3600/4091], Loss: 770.8613\n",
      "Epoch [5/100], Step [3700/4091], Loss: 769.2143\n",
      "Epoch [5/100], Step [3800/4091], Loss: 617.9138\n",
      "Epoch [5/100], Step [3900/4091], Loss: 530.4269\n",
      "Epoch [5/100], Step [4000/4091], Loss: 659.6212\n",
      "Epoch [6/100], Step [100/4091], Loss: 497.8271\n",
      "Epoch [6/100], Step [200/4091], Loss: 669.1586\n",
      "Epoch [6/100], Step [300/4091], Loss: 540.2332\n",
      "Epoch [6/100], Step [400/4091], Loss: 487.4486\n",
      "Epoch [6/100], Step [500/4091], Loss: 849.5863\n",
      "Epoch [6/100], Step [600/4091], Loss: 838.2685\n",
      "Epoch [6/100], Step [700/4091], Loss: 670.5424\n",
      "Epoch [6/100], Step [800/4091], Loss: 573.1984\n",
      "Epoch [6/100], Step [900/4091], Loss: 456.4034\n",
      "Epoch [6/100], Step [1000/4091], Loss: 426.3954\n",
      "Epoch [6/100], Step [1100/4091], Loss: 743.7477\n",
      "Epoch [6/100], Step [1200/4091], Loss: 852.6459\n",
      "Epoch [6/100], Step [1300/4091], Loss: 492.5045\n",
      "Epoch [6/100], Step [1400/4091], Loss: 548.4077\n",
      "Epoch [6/100], Step [1500/4091], Loss: 950.5549\n",
      "Epoch [6/100], Step [1600/4091], Loss: 716.8154\n",
      "Epoch [6/100], Step [1700/4091], Loss: 558.5197\n",
      "Epoch [6/100], Step [1800/4091], Loss: 619.5655\n",
      "Epoch [6/100], Step [1900/4091], Loss: 558.3158\n",
      "Epoch [6/100], Step [2000/4091], Loss: 484.1547\n",
      "Epoch [6/100], Step [2100/4091], Loss: 573.0311\n",
      "Epoch [6/100], Step [2200/4091], Loss: 535.3896\n",
      "Epoch [6/100], Step [2300/4091], Loss: 698.5712\n",
      "Epoch [6/100], Step [2400/4091], Loss: 813.9570\n",
      "Epoch [6/100], Step [2500/4091], Loss: 435.1281\n",
      "Epoch [6/100], Step [2600/4091], Loss: 705.0946\n",
      "Epoch [6/100], Step [2700/4091], Loss: 440.2812\n",
      "Epoch [6/100], Step [2800/4091], Loss: 713.9934\n",
      "Epoch [6/100], Step [2900/4091], Loss: 1009.0793\n",
      "Epoch [6/100], Step [3000/4091], Loss: 883.7576\n",
      "Epoch [6/100], Step [3100/4091], Loss: 484.8235\n",
      "Epoch [6/100], Step [3200/4091], Loss: 897.9542\n",
      "Epoch [6/100], Step [3300/4091], Loss: 835.8289\n",
      "Epoch [6/100], Step [3400/4091], Loss: 725.0273\n",
      "Epoch [6/100], Step [3500/4091], Loss: 591.7760\n",
      "Epoch [6/100], Step [3600/4091], Loss: 805.3636\n",
      "Epoch [6/100], Step [3700/4091], Loss: 573.7588\n",
      "Epoch [6/100], Step [3800/4091], Loss: 789.0752\n",
      "Epoch [6/100], Step [3900/4091], Loss: 888.5296\n",
      "Epoch [6/100], Step [4000/4091], Loss: 559.7830\n",
      "Epoch [7/100], Step [100/4091], Loss: 634.5198\n",
      "Epoch [7/100], Step [200/4091], Loss: 777.5706\n",
      "Epoch [7/100], Step [300/4091], Loss: 582.9080\n",
      "Epoch [7/100], Step [400/4091], Loss: 584.7624\n",
      "Epoch [7/100], Step [500/4091], Loss: 592.9260\n",
      "Epoch [7/100], Step [600/4091], Loss: 707.3304\n",
      "Epoch [7/100], Step [700/4091], Loss: 628.6543\n",
      "Epoch [7/100], Step [800/4091], Loss: 573.8204\n",
      "Epoch [7/100], Step [900/4091], Loss: 512.8257\n",
      "Epoch [7/100], Step [1000/4091], Loss: 675.5342\n",
      "Epoch [7/100], Step [1100/4091], Loss: 665.8818\n",
      "Epoch [7/100], Step [1200/4091], Loss: 655.2410\n",
      "Epoch [7/100], Step [1300/4091], Loss: 584.3843\n",
      "Epoch [7/100], Step [1400/4091], Loss: 579.9992\n",
      "Epoch [7/100], Step [1500/4091], Loss: 593.2102\n",
      "Epoch [7/100], Step [1600/4091], Loss: 696.4794\n",
      "Epoch [7/100], Step [1700/4091], Loss: 617.9440\n",
      "Epoch [7/100], Step [1800/4091], Loss: 547.6500\n",
      "Epoch [7/100], Step [1900/4091], Loss: 849.3396\n",
      "Epoch [7/100], Step [2000/4091], Loss: 686.2493\n",
      "Epoch [7/100], Step [2100/4091], Loss: 669.6656\n",
      "Epoch [7/100], Step [2200/4091], Loss: 559.2026\n",
      "Epoch [7/100], Step [2300/4091], Loss: 534.2979\n",
      "Epoch [7/100], Step [2400/4091], Loss: 708.9215\n",
      "Epoch [7/100], Step [2500/4091], Loss: 854.1054\n",
      "Epoch [7/100], Step [2600/4091], Loss: 657.4896\n",
      "Epoch [7/100], Step [2700/4091], Loss: 574.6302\n",
      "Epoch [7/100], Step [2800/4091], Loss: 603.0982\n",
      "Epoch [7/100], Step [2900/4091], Loss: 729.4680\n",
      "Epoch [7/100], Step [3000/4091], Loss: 691.4754\n",
      "Epoch [7/100], Step [3100/4091], Loss: 630.4869\n",
      "Epoch [7/100], Step [3200/4091], Loss: 816.0575\n",
      "Epoch [7/100], Step [3300/4091], Loss: 707.0981\n",
      "Epoch [7/100], Step [3400/4091], Loss: 526.3051\n",
      "Epoch [7/100], Step [3500/4091], Loss: 695.4700\n",
      "Epoch [7/100], Step [3600/4091], Loss: 691.2416\n",
      "Epoch [7/100], Step [3700/4091], Loss: 441.3766\n",
      "Epoch [7/100], Step [3800/4091], Loss: 740.8724\n",
      "Epoch [7/100], Step [3900/4091], Loss: 590.6143\n",
      "Epoch [7/100], Step [4000/4091], Loss: 899.9610\n",
      "Epoch [8/100], Step [100/4091], Loss: 533.6110\n",
      "Epoch [8/100], Step [200/4091], Loss: 561.9586\n",
      "Epoch [8/100], Step [300/4091], Loss: 558.3995\n",
      "Epoch [8/100], Step [400/4091], Loss: 713.3813\n",
      "Epoch [8/100], Step [500/4091], Loss: 973.2158\n",
      "Epoch [8/100], Step [600/4091], Loss: 592.3484\n",
      "Epoch [8/100], Step [700/4091], Loss: 893.3967\n",
      "Epoch [8/100], Step [800/4091], Loss: 623.7499\n",
      "Epoch [8/100], Step [900/4091], Loss: 533.8370\n",
      "Epoch [8/100], Step [1000/4091], Loss: 508.6247\n",
      "Epoch [8/100], Step [1100/4091], Loss: 491.1398\n",
      "Epoch [8/100], Step [1200/4091], Loss: 704.7520\n",
      "Epoch [8/100], Step [1300/4091], Loss: 729.5848\n",
      "Epoch [8/100], Step [1400/4091], Loss: 852.9194\n",
      "Epoch [8/100], Step [1500/4091], Loss: 743.4810\n",
      "Epoch [8/100], Step [1600/4091], Loss: 664.6551\n",
      "Epoch [8/100], Step [1700/4091], Loss: 461.9676\n",
      "Epoch [8/100], Step [1800/4091], Loss: 661.7221\n",
      "Epoch [8/100], Step [1900/4091], Loss: 476.5648\n",
      "Epoch [8/100], Step [2000/4091], Loss: 713.8939\n",
      "Epoch [8/100], Step [2100/4091], Loss: 559.2065\n",
      "Epoch [8/100], Step [2200/4091], Loss: 929.1478\n",
      "Epoch [8/100], Step [2300/4091], Loss: 745.1357\n",
      "Epoch [8/100], Step [2400/4091], Loss: 675.5687\n",
      "Epoch [8/100], Step [2500/4091], Loss: 683.4657\n",
      "Epoch [8/100], Step [2600/4091], Loss: 568.9682\n",
      "Epoch [8/100], Step [2700/4091], Loss: 825.3241\n",
      "Epoch [8/100], Step [2800/4091], Loss: 656.2195\n",
      "Epoch [8/100], Step [2900/4091], Loss: 660.1599\n",
      "Epoch [8/100], Step [3000/4091], Loss: 880.4939\n",
      "Epoch [8/100], Step [3100/4091], Loss: 591.3530\n",
      "Epoch [8/100], Step [3200/4091], Loss: 691.5215\n",
      "Epoch [8/100], Step [3300/4091], Loss: 770.4852\n",
      "Epoch [8/100], Step [3400/4091], Loss: 752.0289\n",
      "Epoch [8/100], Step [3500/4091], Loss: 606.5314\n",
      "Epoch [8/100], Step [3600/4091], Loss: 689.0979\n",
      "Epoch [8/100], Step [3700/4091], Loss: 778.1012\n",
      "Epoch [8/100], Step [3800/4091], Loss: 579.5580\n",
      "Epoch [8/100], Step [3900/4091], Loss: 730.6282\n",
      "Epoch [8/100], Step [4000/4091], Loss: 564.0294\n",
      "Epoch [9/100], Step [100/4091], Loss: 630.1249\n",
      "Epoch [9/100], Step [200/4091], Loss: 796.3363\n",
      "Epoch [9/100], Step [300/4091], Loss: 464.5223\n",
      "Epoch [9/100], Step [400/4091], Loss: 735.3404\n",
      "Epoch [9/100], Step [500/4091], Loss: 653.1378\n",
      "Epoch [9/100], Step [600/4091], Loss: 630.4646\n",
      "Epoch [9/100], Step [700/4091], Loss: 507.1318\n",
      "Epoch [9/100], Step [800/4091], Loss: 814.8631\n",
      "Epoch [9/100], Step [900/4091], Loss: 492.8512\n",
      "Epoch [9/100], Step [1000/4091], Loss: 386.6844\n",
      "Epoch [9/100], Step [1100/4091], Loss: 543.7229\n",
      "Epoch [9/100], Step [1200/4091], Loss: 560.4368\n",
      "Epoch [9/100], Step [1300/4091], Loss: 651.1498\n",
      "Epoch [9/100], Step [1400/4091], Loss: 789.2389\n",
      "Epoch [9/100], Step [1500/4091], Loss: 574.1904\n",
      "Epoch [9/100], Step [1600/4091], Loss: 668.1613\n",
      "Epoch [9/100], Step [1700/4091], Loss: 615.2533\n",
      "Epoch [9/100], Step [1800/4091], Loss: 772.9412\n",
      "Epoch [9/100], Step [1900/4091], Loss: 603.1951\n",
      "Epoch [9/100], Step [2000/4091], Loss: 709.2922\n",
      "Epoch [9/100], Step [2100/4091], Loss: 476.6699\n",
      "Epoch [9/100], Step [2200/4091], Loss: 541.6595\n",
      "Epoch [9/100], Step [2300/4091], Loss: 616.4502\n",
      "Epoch [9/100], Step [2400/4091], Loss: 859.1220\n",
      "Epoch [9/100], Step [2500/4091], Loss: 512.1416\n",
      "Epoch [9/100], Step [2600/4091], Loss: 818.1341\n",
      "Epoch [9/100], Step [2700/4091], Loss: 644.5194\n",
      "Epoch [9/100], Step [2800/4091], Loss: 650.2975\n",
      "Epoch [9/100], Step [2900/4091], Loss: 721.6356\n",
      "Epoch [9/100], Step [3000/4091], Loss: 745.2523\n",
      "Epoch [9/100], Step [3100/4091], Loss: 610.7222\n",
      "Epoch [9/100], Step [3200/4091], Loss: 792.1202\n",
      "Epoch [9/100], Step [3300/4091], Loss: 811.4155\n",
      "Epoch [9/100], Step [3400/4091], Loss: 884.2969\n",
      "Epoch [9/100], Step [3500/4091], Loss: 641.4879\n",
      "Epoch [9/100], Step [3600/4091], Loss: 665.8347\n",
      "Epoch [9/100], Step [3700/4091], Loss: 669.0006\n",
      "Epoch [9/100], Step [3800/4091], Loss: 748.3213\n",
      "Epoch [9/100], Step [3900/4091], Loss: 448.8249\n",
      "Epoch [9/100], Step [4000/4091], Loss: 586.2407\n",
      "Epoch [10/100], Step [100/4091], Loss: 634.1305\n",
      "Epoch [10/100], Step [200/4091], Loss: 589.0544\n",
      "Epoch [10/100], Step [300/4091], Loss: 967.4692\n",
      "Epoch [10/100], Step [400/4091], Loss: 593.6205\n",
      "Epoch [10/100], Step [500/4091], Loss: 610.5592\n",
      "Epoch [10/100], Step [600/4091], Loss: 539.0125\n",
      "Epoch [10/100], Step [700/4091], Loss: 720.1864\n",
      "Epoch [10/100], Step [800/4091], Loss: 449.2395\n",
      "Epoch [10/100], Step [900/4091], Loss: 757.9001\n",
      "Epoch [10/100], Step [1000/4091], Loss: 545.8793\n",
      "Epoch [10/100], Step [1100/4091], Loss: 663.7660\n",
      "Epoch [10/100], Step [1200/4091], Loss: 510.5685\n",
      "Epoch [10/100], Step [1300/4091], Loss: 620.0515\n",
      "Epoch [10/100], Step [1400/4091], Loss: 573.5223\n",
      "Epoch [10/100], Step [1500/4091], Loss: 781.7324\n",
      "Epoch [10/100], Step [1600/4091], Loss: 607.6749\n",
      "Epoch [10/100], Step [1700/4091], Loss: 775.5652\n",
      "Epoch [10/100], Step [1800/4091], Loss: 562.2096\n",
      "Epoch [10/100], Step [1900/4091], Loss: 420.5880\n",
      "Epoch [10/100], Step [2000/4091], Loss: 600.6266\n",
      "Epoch [10/100], Step [2100/4091], Loss: 578.5150\n",
      "Epoch [10/100], Step [2200/4091], Loss: 761.7759\n",
      "Epoch [10/100], Step [2300/4091], Loss: 522.1145\n",
      "Epoch [10/100], Step [2400/4091], Loss: 688.1979\n",
      "Epoch [10/100], Step [2500/4091], Loss: 682.2265\n",
      "Epoch [10/100], Step [2600/4091], Loss: 921.4338\n",
      "Epoch [10/100], Step [2700/4091], Loss: 417.7768\n",
      "Epoch [10/100], Step [2800/4091], Loss: 585.8669\n",
      "Epoch [10/100], Step [2900/4091], Loss: 836.4177\n",
      "Epoch [10/100], Step [3000/4091], Loss: 513.9307\n",
      "Epoch [10/100], Step [3100/4091], Loss: 659.2655\n",
      "Epoch [10/100], Step [3200/4091], Loss: 615.7241\n",
      "Epoch [10/100], Step [3300/4091], Loss: 992.3619\n",
      "Epoch [10/100], Step [3400/4091], Loss: 578.7084\n",
      "Epoch [10/100], Step [3500/4091], Loss: 596.1458\n",
      "Epoch [10/100], Step [3600/4091], Loss: 841.8417\n",
      "Epoch [10/100], Step [3700/4091], Loss: 884.9509\n",
      "Epoch [10/100], Step [3800/4091], Loss: 415.1428\n",
      "Epoch [10/100], Step [3900/4091], Loss: 774.0177\n",
      "Epoch [10/100], Step [4000/4091], Loss: 721.4967\n",
      "Epoch [11/100], Step [100/4091], Loss: 818.9695\n",
      "Epoch [11/100], Step [200/4091], Loss: 606.1289\n",
      "Epoch [11/100], Step [300/4091], Loss: 604.7947\n",
      "Epoch [11/100], Step [400/4091], Loss: 786.3151\n",
      "Epoch [11/100], Step [500/4091], Loss: 703.0433\n",
      "Epoch [11/100], Step [600/4091], Loss: 718.7371\n",
      "Epoch [11/100], Step [700/4091], Loss: 721.6304\n",
      "Epoch [11/100], Step [800/4091], Loss: 573.6981\n",
      "Epoch [11/100], Step [900/4091], Loss: 566.4932\n",
      "Epoch [11/100], Step [1000/4091], Loss: 738.3357\n",
      "Epoch [11/100], Step [1100/4091], Loss: 593.2141\n",
      "Epoch [11/100], Step [1200/4091], Loss: 742.8087\n",
      "Epoch [11/100], Step [1300/4091], Loss: 756.4694\n",
      "Epoch [11/100], Step [1400/4091], Loss: 663.0757\n",
      "Epoch [11/100], Step [1500/4091], Loss: 643.2184\n",
      "Epoch [11/100], Step [1600/4091], Loss: 579.2366\n",
      "Epoch [11/100], Step [1700/4091], Loss: 602.3530\n",
      "Epoch [11/100], Step [1800/4091], Loss: 601.3209\n",
      "Epoch [11/100], Step [1900/4091], Loss: 749.0317\n",
      "Epoch [11/100], Step [2000/4091], Loss: 615.5524\n",
      "Epoch [11/100], Step [2100/4091], Loss: 623.8722\n",
      "Epoch [11/100], Step [2200/4091], Loss: 1012.6075\n",
      "Epoch [11/100], Step [2300/4091], Loss: 740.7032\n",
      "Epoch [11/100], Step [2400/4091], Loss: 597.2160\n",
      "Epoch [11/100], Step [2500/4091], Loss: 697.4373\n",
      "Epoch [11/100], Step [2600/4091], Loss: 654.3029\n",
      "Epoch [11/100], Step [2700/4091], Loss: 675.1932\n",
      "Epoch [11/100], Step [2800/4091], Loss: 607.1550\n",
      "Epoch [11/100], Step [2900/4091], Loss: 746.9554\n",
      "Epoch [11/100], Step [3000/4091], Loss: 588.4316\n",
      "Epoch [11/100], Step [3100/4091], Loss: 563.4636\n",
      "Epoch [11/100], Step [3200/4091], Loss: 690.8244\n",
      "Epoch [11/100], Step [3300/4091], Loss: 577.1541\n",
      "Epoch [11/100], Step [3400/4091], Loss: 728.0949\n",
      "Epoch [11/100], Step [3500/4091], Loss: 757.3887\n",
      "Epoch [11/100], Step [3600/4091], Loss: 731.5278\n",
      "Epoch [11/100], Step [3700/4091], Loss: 592.4941\n",
      "Epoch [11/100], Step [3800/4091], Loss: 552.7034\n",
      "Epoch [11/100], Step [3900/4091], Loss: 626.6864\n",
      "Epoch [11/100], Step [4000/4091], Loss: 709.2246\n",
      "Epoch [12/100], Step [100/4091], Loss: 665.5025\n",
      "Epoch [12/100], Step [200/4091], Loss: 717.6362\n",
      "Epoch [12/100], Step [300/4091], Loss: 610.4058\n",
      "Epoch [12/100], Step [400/4091], Loss: 680.6472\n",
      "Epoch [12/100], Step [500/4091], Loss: 637.4616\n",
      "Epoch [12/100], Step [600/4091], Loss: 727.0886\n",
      "Epoch [12/100], Step [700/4091], Loss: 573.8461\n",
      "Epoch [12/100], Step [800/4091], Loss: 902.2717\n",
      "Epoch [12/100], Step [900/4091], Loss: 471.1019\n",
      "Epoch [12/100], Step [1000/4091], Loss: 630.8627\n",
      "Epoch [12/100], Step [1100/4091], Loss: 854.2817\n",
      "Epoch [12/100], Step [1200/4091], Loss: 772.1992\n",
      "Epoch [12/100], Step [1300/4091], Loss: 962.3421\n",
      "Epoch [12/100], Step [1400/4091], Loss: 405.4621\n",
      "Epoch [12/100], Step [1500/4091], Loss: 777.0343\n",
      "Epoch [12/100], Step [1600/4091], Loss: 571.0182\n",
      "Epoch [12/100], Step [1700/4091], Loss: 692.3445\n",
      "Epoch [12/100], Step [1800/4091], Loss: 586.9083\n",
      "Epoch [12/100], Step [1900/4091], Loss: 710.0129\n",
      "Epoch [12/100], Step [2000/4091], Loss: 640.0444\n",
      "Epoch [12/100], Step [2100/4091], Loss: 660.5710\n",
      "Epoch [12/100], Step [2200/4091], Loss: 640.6263\n",
      "Epoch [12/100], Step [2300/4091], Loss: 808.8668\n",
      "Epoch [12/100], Step [2400/4091], Loss: 602.5112\n",
      "Epoch [12/100], Step [2500/4091], Loss: 498.8698\n",
      "Epoch [12/100], Step [2600/4091], Loss: 719.7203\n",
      "Epoch [12/100], Step [2700/4091], Loss: 898.2303\n",
      "Epoch [12/100], Step [2800/4091], Loss: 561.7097\n",
      "Epoch [12/100], Step [2900/4091], Loss: 665.6075\n",
      "Epoch [12/100], Step [3000/4091], Loss: 372.2402\n",
      "Epoch [12/100], Step [3100/4091], Loss: 752.2525\n",
      "Epoch [12/100], Step [3200/4091], Loss: 590.7058\n",
      "Epoch [12/100], Step [3300/4091], Loss: 554.9943\n",
      "Epoch [12/100], Step [3400/4091], Loss: 777.2848\n",
      "Epoch [12/100], Step [3500/4091], Loss: 835.5018\n",
      "Epoch [12/100], Step [3600/4091], Loss: 598.8403\n",
      "Epoch [12/100], Step [3700/4091], Loss: 579.2427\n",
      "Epoch [12/100], Step [3800/4091], Loss: 629.2317\n",
      "Epoch [12/100], Step [3900/4091], Loss: 578.1508\n",
      "Epoch [12/100], Step [4000/4091], Loss: 588.7544\n",
      "Epoch [13/100], Step [100/4091], Loss: 647.7296\n",
      "Epoch [13/100], Step [200/4091], Loss: 605.5365\n",
      "Epoch [13/100], Step [300/4091], Loss: 838.2835\n",
      "Epoch [13/100], Step [400/4091], Loss: 733.3699\n",
      "Epoch [13/100], Step [500/4091], Loss: 642.0793\n",
      "Epoch [13/100], Step [600/4091], Loss: 817.6364\n",
      "Epoch [13/100], Step [700/4091], Loss: 593.9146\n",
      "Epoch [13/100], Step [800/4091], Loss: 734.5205\n",
      "Epoch [13/100], Step [900/4091], Loss: 768.6771\n",
      "Epoch [13/100], Step [1000/4091], Loss: 604.6000\n",
      "Epoch [13/100], Step [1100/4091], Loss: 618.9037\n",
      "Epoch [13/100], Step [1200/4091], Loss: 773.7376\n",
      "Epoch [13/100], Step [1300/4091], Loss: 780.1378\n",
      "Epoch [13/100], Step [1400/4091], Loss: 680.8656\n",
      "Epoch [13/100], Step [1500/4091], Loss: 710.5234\n",
      "Epoch [13/100], Step [1600/4091], Loss: 497.0983\n",
      "Epoch [13/100], Step [1700/4091], Loss: 486.7448\n",
      "Epoch [13/100], Step [1800/4091], Loss: 779.7514\n",
      "Epoch [13/100], Step [1900/4091], Loss: 518.3392\n",
      "Epoch [13/100], Step [2000/4091], Loss: 603.8297\n",
      "Epoch [13/100], Step [2100/4091], Loss: 840.0365\n",
      "Epoch [13/100], Step [2200/4091], Loss: 642.7816\n",
      "Epoch [13/100], Step [2300/4091], Loss: 915.8007\n",
      "Epoch [13/100], Step [2400/4091], Loss: 590.5519\n",
      "Epoch [13/100], Step [2500/4091], Loss: 763.7791\n",
      "Epoch [13/100], Step [2600/4091], Loss: 595.2238\n",
      "Epoch [13/100], Step [2700/4091], Loss: 628.2073\n",
      "Epoch [13/100], Step [2800/4091], Loss: 734.2136\n",
      "Epoch [13/100], Step [2900/4091], Loss: 755.2688\n",
      "Epoch [13/100], Step [3000/4091], Loss: 451.8791\n",
      "Epoch [13/100], Step [3100/4091], Loss: 671.5172\n",
      "Epoch [13/100], Step [3200/4091], Loss: 515.4105\n",
      "Epoch [13/100], Step [3300/4091], Loss: 755.3196\n",
      "Epoch [13/100], Step [3400/4091], Loss: 479.6415\n",
      "Epoch [13/100], Step [3500/4091], Loss: 649.1725\n",
      "Epoch [13/100], Step [3600/4091], Loss: 770.7354\n",
      "Epoch [13/100], Step [3700/4091], Loss: 622.4143\n",
      "Epoch [13/100], Step [3800/4091], Loss: 859.9173\n",
      "Epoch [13/100], Step [3900/4091], Loss: 574.0792\n",
      "Epoch [13/100], Step [4000/4091], Loss: 395.4799\n",
      "Epoch [14/100], Step [100/4091], Loss: 653.2766\n",
      "Epoch [14/100], Step [200/4091], Loss: 689.4824\n",
      "Epoch [14/100], Step [300/4091], Loss: 608.0645\n",
      "Epoch [14/100], Step [400/4091], Loss: 674.4406\n",
      "Epoch [14/100], Step [500/4091], Loss: 559.2454\n",
      "Epoch [14/100], Step [600/4091], Loss: 646.7287\n",
      "Epoch [14/100], Step [700/4091], Loss: 540.5662\n",
      "Epoch [14/100], Step [800/4091], Loss: 771.6393\n",
      "Epoch [14/100], Step [900/4091], Loss: 404.2450\n",
      "Epoch [14/100], Step [1000/4091], Loss: 790.7836\n",
      "Epoch [14/100], Step [1100/4091], Loss: 600.7736\n",
      "Epoch [14/100], Step [1200/4091], Loss: 476.1338\n",
      "Epoch [14/100], Step [1300/4091], Loss: 900.1008\n",
      "Epoch [14/100], Step [1400/4091], Loss: 554.2427\n",
      "Epoch [14/100], Step [1500/4091], Loss: 539.2756\n",
      "Epoch [14/100], Step [1600/4091], Loss: 679.3875\n",
      "Epoch [14/100], Step [1700/4091], Loss: 571.0359\n",
      "Epoch [14/100], Step [1800/4091], Loss: 805.4464\n",
      "Epoch [14/100], Step [1900/4091], Loss: 612.8917\n",
      "Epoch [14/100], Step [2000/4091], Loss: 558.5534\n",
      "Epoch [14/100], Step [2100/4091], Loss: 589.2106\n",
      "Epoch [14/100], Step [2200/4091], Loss: 638.2548\n",
      "Epoch [14/100], Step [2300/4091], Loss: 599.0688\n",
      "Epoch [14/100], Step [2400/4091], Loss: 467.3521\n",
      "Epoch [14/100], Step [2500/4091], Loss: 500.5437\n",
      "Epoch [14/100], Step [2600/4091], Loss: 845.6943\n",
      "Epoch [14/100], Step [2700/4091], Loss: 793.5704\n",
      "Epoch [14/100], Step [2800/4091], Loss: 508.4947\n",
      "Epoch [14/100], Step [2900/4091], Loss: 535.7761\n",
      "Epoch [14/100], Step [3000/4091], Loss: 755.4906\n",
      "Epoch [14/100], Step [3100/4091], Loss: 456.2163\n",
      "Epoch [14/100], Step [3200/4091], Loss: 659.6478\n",
      "Epoch [14/100], Step [3300/4091], Loss: 638.1536\n",
      "Epoch [14/100], Step [3400/4091], Loss: 703.6208\n",
      "Epoch [14/100], Step [3500/4091], Loss: 796.2560\n",
      "Epoch [14/100], Step [3600/4091], Loss: 557.0472\n",
      "Epoch [14/100], Step [3700/4091], Loss: 557.4403\n",
      "Epoch [14/100], Step [3800/4091], Loss: 629.9627\n",
      "Epoch [14/100], Step [3900/4091], Loss: 587.2310\n",
      "Epoch [14/100], Step [4000/4091], Loss: 739.2084\n",
      "Epoch [15/100], Step [100/4091], Loss: 1085.9510\n",
      "Epoch [15/100], Step [200/4091], Loss: 642.9097\n",
      "Epoch [15/100], Step [300/4091], Loss: 906.4651\n",
      "Epoch [15/100], Step [400/4091], Loss: 637.4656\n",
      "Epoch [15/100], Step [500/4091], Loss: 648.4517\n",
      "Epoch [15/100], Step [600/4091], Loss: 662.2042\n",
      "Epoch [15/100], Step [700/4091], Loss: 662.3460\n",
      "Epoch [15/100], Step [800/4091], Loss: 535.0636\n",
      "Epoch [15/100], Step [900/4091], Loss: 773.9929\n",
      "Epoch [15/100], Step [1000/4091], Loss: 691.7461\n",
      "Epoch [15/100], Step [1100/4091], Loss: 387.4023\n",
      "Epoch [15/100], Step [1200/4091], Loss: 406.2328\n",
      "Epoch [15/100], Step [1300/4091], Loss: 463.4059\n",
      "Epoch [15/100], Step [1400/4091], Loss: 639.0873\n",
      "Epoch [15/100], Step [1500/4091], Loss: 565.2929\n",
      "Epoch [15/100], Step [1600/4091], Loss: 1002.8236\n",
      "Epoch [15/100], Step [1700/4091], Loss: 559.8357\n",
      "Epoch [15/100], Step [1800/4091], Loss: 559.6288\n",
      "Epoch [15/100], Step [1900/4091], Loss: 714.8499\n",
      "Epoch [15/100], Step [2000/4091], Loss: 887.7242\n",
      "Epoch [15/100], Step [2100/4091], Loss: 403.2429\n",
      "Epoch [15/100], Step [2200/4091], Loss: 615.2997\n",
      "Epoch [15/100], Step [2300/4091], Loss: 611.4665\n",
      "Epoch [15/100], Step [2400/4091], Loss: 524.8651\n",
      "Epoch [15/100], Step [2500/4091], Loss: 995.0464\n",
      "Epoch [15/100], Step [2600/4091], Loss: 745.7433\n",
      "Epoch [15/100], Step [2700/4091], Loss: 562.3070\n",
      "Epoch [15/100], Step [2800/4091], Loss: 718.7659\n",
      "Epoch [15/100], Step [2900/4091], Loss: 676.1794\n",
      "Epoch [15/100], Step [3000/4091], Loss: 662.1906\n",
      "Epoch [15/100], Step [3100/4091], Loss: 481.1049\n",
      "Epoch [15/100], Step [3200/4091], Loss: 738.1497\n",
      "Epoch [15/100], Step [3300/4091], Loss: 854.7986\n",
      "Epoch [15/100], Step [3400/4091], Loss: 804.7917\n",
      "Epoch [15/100], Step [3500/4091], Loss: 519.2219\n",
      "Epoch [15/100], Step [3600/4091], Loss: 691.8383\n",
      "Epoch [15/100], Step [3700/4091], Loss: 671.1575\n",
      "Epoch [15/100], Step [3800/4091], Loss: 755.4363\n",
      "Epoch [15/100], Step [3900/4091], Loss: 817.6981\n",
      "Epoch [15/100], Step [4000/4091], Loss: 723.4018\n",
      "Epoch [16/100], Step [100/4091], Loss: 660.2377\n",
      "Epoch [16/100], Step [200/4091], Loss: 794.2849\n",
      "Epoch [16/100], Step [300/4091], Loss: 661.0437\n",
      "Epoch [16/100], Step [400/4091], Loss: 811.5814\n",
      "Epoch [16/100], Step [500/4091], Loss: 577.2943\n",
      "Epoch [16/100], Step [600/4091], Loss: 682.8870\n",
      "Epoch [16/100], Step [700/4091], Loss: 747.0753\n",
      "Epoch [16/100], Step [800/4091], Loss: 657.8806\n",
      "Epoch [16/100], Step [900/4091], Loss: 556.7833\n",
      "Epoch [16/100], Step [1000/4091], Loss: 685.4205\n",
      "Epoch [16/100], Step [1100/4091], Loss: 571.2490\n",
      "Epoch [16/100], Step [1200/4091], Loss: 884.9687\n",
      "Epoch [16/100], Step [1300/4091], Loss: 619.6367\n",
      "Epoch [16/100], Step [1400/4091], Loss: 757.2534\n",
      "Epoch [16/100], Step [1500/4091], Loss: 626.4667\n",
      "Epoch [16/100], Step [1600/4091], Loss: 878.7332\n",
      "Epoch [16/100], Step [1700/4091], Loss: 598.9265\n",
      "Epoch [16/100], Step [1800/4091], Loss: 542.3574\n",
      "Epoch [16/100], Step [1900/4091], Loss: 829.2014\n",
      "Epoch [16/100], Step [2000/4091], Loss: 758.8678\n",
      "Epoch [16/100], Step [2100/4091], Loss: 412.2947\n",
      "Epoch [16/100], Step [2200/4091], Loss: 705.9744\n",
      "Epoch [16/100], Step [2300/4091], Loss: 656.3746\n",
      "Epoch [16/100], Step [2400/4091], Loss: 681.3432\n",
      "Epoch [16/100], Step [2500/4091], Loss: 674.9321\n",
      "Epoch [16/100], Step [2600/4091], Loss: 671.0797\n",
      "Epoch [16/100], Step [2700/4091], Loss: 734.9460\n",
      "Epoch [16/100], Step [2800/4091], Loss: 764.3065\n",
      "Epoch [16/100], Step [2900/4091], Loss: 652.0555\n",
      "Epoch [16/100], Step [3000/4091], Loss: 595.7951\n",
      "Epoch [16/100], Step [3100/4091], Loss: 782.5831\n",
      "Epoch [16/100], Step [3200/4091], Loss: 633.8294\n",
      "Epoch [16/100], Step [3300/4091], Loss: 640.9565\n",
      "Epoch [16/100], Step [3400/4091], Loss: 662.0300\n",
      "Epoch [16/100], Step [3500/4091], Loss: 674.2852\n",
      "Epoch [16/100], Step [3600/4091], Loss: 598.1666\n",
      "Epoch [16/100], Step [3700/4091], Loss: 1037.6251\n",
      "Epoch [16/100], Step [3800/4091], Loss: 551.8496\n",
      "Epoch [16/100], Step [3900/4091], Loss: 772.4238\n",
      "Epoch [16/100], Step [4000/4091], Loss: 623.5724\n",
      "Epoch [17/100], Step [100/4091], Loss: 406.3896\n",
      "Epoch [17/100], Step [200/4091], Loss: 649.2046\n",
      "Epoch [17/100], Step [300/4091], Loss: 630.4161\n",
      "Epoch [17/100], Step [400/4091], Loss: 651.7902\n",
      "Epoch [17/100], Step [500/4091], Loss: 567.0846\n",
      "Epoch [17/100], Step [600/4091], Loss: 595.4759\n",
      "Epoch [17/100], Step [700/4091], Loss: 661.4286\n",
      "Epoch [17/100], Step [800/4091], Loss: 600.0784\n",
      "Epoch [17/100], Step [900/4091], Loss: 828.9048\n",
      "Epoch [17/100], Step [1000/4091], Loss: 661.2094\n",
      "Epoch [17/100], Step [1100/4091], Loss: 775.3453\n",
      "Epoch [17/100], Step [1200/4091], Loss: 823.5295\n",
      "Epoch [17/100], Step [1300/4091], Loss: 551.6711\n",
      "Epoch [17/100], Step [1400/4091], Loss: 695.2018\n",
      "Epoch [17/100], Step [1500/4091], Loss: 854.0662\n",
      "Epoch [17/100], Step [1600/4091], Loss: 528.9813\n",
      "Epoch [17/100], Step [1700/4091], Loss: 573.8992\n",
      "Epoch [17/100], Step [1800/4091], Loss: 633.4819\n",
      "Epoch [17/100], Step [1900/4091], Loss: 395.7449\n",
      "Epoch [17/100], Step [2000/4091], Loss: 734.7717\n",
      "Epoch [17/100], Step [2100/4091], Loss: 737.3381\n",
      "Epoch [17/100], Step [2200/4091], Loss: 687.4697\n",
      "Epoch [17/100], Step [2300/4091], Loss: 624.1614\n",
      "Epoch [17/100], Step [2400/4091], Loss: 785.9750\n",
      "Epoch [17/100], Step [2500/4091], Loss: 672.9092\n",
      "Epoch [17/100], Step [2600/4091], Loss: 482.5367\n",
      "Epoch [17/100], Step [2700/4091], Loss: 340.9373\n",
      "Epoch [17/100], Step [2800/4091], Loss: 631.5399\n",
      "Epoch [17/100], Step [2900/4091], Loss: 645.5479\n",
      "Epoch [17/100], Step [3000/4091], Loss: 680.4369\n",
      "Epoch [17/100], Step [3100/4091], Loss: 636.9429\n",
      "Epoch [17/100], Step [3200/4091], Loss: 582.0208\n",
      "Epoch [17/100], Step [3300/4091], Loss: 572.9174\n",
      "Epoch [17/100], Step [3400/4091], Loss: 613.1160\n",
      "Epoch [17/100], Step [3500/4091], Loss: 490.4715\n",
      "Epoch [17/100], Step [3600/4091], Loss: 548.3560\n",
      "Epoch [17/100], Step [3700/4091], Loss: 648.0967\n",
      "Epoch [17/100], Step [3800/4091], Loss: 968.7177\n",
      "Epoch [17/100], Step [3900/4091], Loss: 674.9651\n",
      "Epoch [17/100], Step [4000/4091], Loss: 673.9308\n",
      "Epoch [18/100], Step [100/4091], Loss: 550.3495\n",
      "Epoch [18/100], Step [200/4091], Loss: 823.0715\n",
      "Epoch [18/100], Step [300/4091], Loss: 706.1183\n",
      "Epoch [18/100], Step [400/4091], Loss: 598.7725\n",
      "Epoch [18/100], Step [500/4091], Loss: 547.5023\n",
      "Epoch [18/100], Step [600/4091], Loss: 530.7427\n",
      "Epoch [18/100], Step [700/4091], Loss: 613.5427\n",
      "Epoch [18/100], Step [800/4091], Loss: 763.5877\n",
      "Epoch [18/100], Step [900/4091], Loss: 670.7920\n",
      "Epoch [18/100], Step [1000/4091], Loss: 761.8593\n",
      "Epoch [18/100], Step [1100/4091], Loss: 587.8284\n",
      "Epoch [18/100], Step [1200/4091], Loss: 720.5826\n",
      "Epoch [18/100], Step [1300/4091], Loss: 750.9200\n",
      "Epoch [18/100], Step [1400/4091], Loss: 461.8246\n",
      "Epoch [18/100], Step [1500/4091], Loss: 594.6990\n",
      "Epoch [18/100], Step [1600/4091], Loss: 559.1383\n",
      "Epoch [18/100], Step [1700/4091], Loss: 850.5376\n",
      "Epoch [18/100], Step [1800/4091], Loss: 796.2653\n",
      "Epoch [18/100], Step [1900/4091], Loss: 573.1844\n",
      "Epoch [18/100], Step [2000/4091], Loss: 916.5463\n",
      "Epoch [18/100], Step [2100/4091], Loss: 988.8173\n",
      "Epoch [18/100], Step [2200/4091], Loss: 929.6592\n",
      "Epoch [18/100], Step [2300/4091], Loss: 460.8435\n",
      "Epoch [18/100], Step [2400/4091], Loss: 624.4353\n",
      "Epoch [18/100], Step [2500/4091], Loss: 841.4244\n",
      "Epoch [18/100], Step [2600/4091], Loss: 602.8336\n",
      "Epoch [18/100], Step [2700/4091], Loss: 669.1382\n",
      "Epoch [18/100], Step [2800/4091], Loss: 714.1766\n",
      "Epoch [18/100], Step [2900/4091], Loss: 426.2825\n",
      "Epoch [18/100], Step [3000/4091], Loss: 795.5523\n",
      "Epoch [18/100], Step [3100/4091], Loss: 694.6624\n",
      "Epoch [18/100], Step [3200/4091], Loss: 649.5420\n",
      "Epoch [18/100], Step [3300/4091], Loss: 755.5467\n",
      "Epoch [18/100], Step [3400/4091], Loss: 744.5538\n",
      "Epoch [18/100], Step [3500/4091], Loss: 654.2626\n",
      "Epoch [18/100], Step [3600/4091], Loss: 829.1664\n",
      "Epoch [18/100], Step [3700/4091], Loss: 671.6237\n",
      "Epoch [18/100], Step [3800/4091], Loss: 735.0618\n",
      "Epoch [18/100], Step [3900/4091], Loss: 614.3308\n",
      "Epoch [18/100], Step [4000/4091], Loss: 636.1010\n",
      "Epoch [19/100], Step [100/4091], Loss: 583.6728\n",
      "Epoch [19/100], Step [200/4091], Loss: 425.5306\n",
      "Epoch [19/100], Step [300/4091], Loss: 629.8441\n",
      "Epoch [19/100], Step [400/4091], Loss: 649.5789\n",
      "Epoch [19/100], Step [500/4091], Loss: 674.5496\n",
      "Epoch [19/100], Step [600/4091], Loss: 467.6235\n",
      "Epoch [19/100], Step [700/4091], Loss: 594.3739\n",
      "Epoch [19/100], Step [800/4091], Loss: 383.6737\n",
      "Epoch [19/100], Step [900/4091], Loss: 523.0522\n",
      "Epoch [19/100], Step [1000/4091], Loss: 446.4330\n",
      "Epoch [19/100], Step [1100/4091], Loss: 880.7141\n",
      "Epoch [19/100], Step [1200/4091], Loss: 661.2447\n",
      "Epoch [19/100], Step [1300/4091], Loss: 803.9789\n",
      "Epoch [19/100], Step [1400/4091], Loss: 895.8555\n",
      "Epoch [19/100], Step [1500/4091], Loss: 849.7108\n",
      "Epoch [19/100], Step [1600/4091], Loss: 564.8545\n",
      "Epoch [19/100], Step [1700/4091], Loss: 462.9593\n",
      "Epoch [19/100], Step [1800/4091], Loss: 872.3815\n",
      "Epoch [19/100], Step [1900/4091], Loss: 706.8928\n",
      "Epoch [19/100], Step [2000/4091], Loss: 690.8794\n",
      "Epoch [19/100], Step [2100/4091], Loss: 607.4611\n",
      "Epoch [19/100], Step [2200/4091], Loss: 442.6263\n",
      "Epoch [19/100], Step [2300/4091], Loss: 586.8438\n",
      "Epoch [19/100], Step [2400/4091], Loss: 948.9423\n",
      "Epoch [19/100], Step [2500/4091], Loss: 751.2127\n",
      "Epoch [19/100], Step [2600/4091], Loss: 604.5150\n",
      "Epoch [19/100], Step [2700/4091], Loss: 638.2087\n",
      "Epoch [19/100], Step [2800/4091], Loss: 484.7985\n",
      "Epoch [19/100], Step [2900/4091], Loss: 620.2218\n",
      "Epoch [19/100], Step [3000/4091], Loss: 624.5020\n",
      "Epoch [19/100], Step [3100/4091], Loss: 699.7048\n",
      "Epoch [19/100], Step [3200/4091], Loss: 812.0239\n",
      "Epoch [19/100], Step [3300/4091], Loss: 599.7502\n",
      "Epoch [19/100], Step [3400/4091], Loss: 575.2834\n",
      "Epoch [19/100], Step [3500/4091], Loss: 595.9168\n",
      "Epoch [19/100], Step [3600/4091], Loss: 693.3009\n",
      "Epoch [19/100], Step [3700/4091], Loss: 756.0602\n",
      "Epoch [19/100], Step [3800/4091], Loss: 555.0131\n",
      "Epoch [19/100], Step [3900/4091], Loss: 707.7984\n",
      "Epoch [19/100], Step [4000/4091], Loss: 845.8691\n",
      "Epoch [20/100], Step [100/4091], Loss: 734.7648\n",
      "Epoch [20/100], Step [200/4091], Loss: 756.2502\n",
      "Epoch [20/100], Step [300/4091], Loss: 572.3584\n",
      "Epoch [20/100], Step [400/4091], Loss: 756.6044\n",
      "Epoch [20/100], Step [500/4091], Loss: 767.3196\n",
      "Epoch [20/100], Step [600/4091], Loss: 610.3758\n",
      "Epoch [20/100], Step [700/4091], Loss: 646.6590\n",
      "Epoch [20/100], Step [800/4091], Loss: 866.0635\n",
      "Epoch [20/100], Step [900/4091], Loss: 534.9571\n",
      "Epoch [20/100], Step [1000/4091], Loss: 633.0145\n",
      "Epoch [20/100], Step [1100/4091], Loss: 848.6921\n",
      "Epoch [20/100], Step [1200/4091], Loss: 743.2749\n",
      "Epoch [20/100], Step [1300/4091], Loss: 880.5737\n",
      "Epoch [20/100], Step [1400/4091], Loss: 766.3939\n",
      "Epoch [20/100], Step [1500/4091], Loss: 596.2017\n",
      "Epoch [20/100], Step [1600/4091], Loss: 978.6501\n",
      "Epoch [20/100], Step [1700/4091], Loss: 590.8256\n",
      "Epoch [20/100], Step [1800/4091], Loss: 529.5020\n",
      "Epoch [20/100], Step [1900/4091], Loss: 693.7284\n",
      "Epoch [20/100], Step [2000/4091], Loss: 721.9133\n",
      "Epoch [20/100], Step [2100/4091], Loss: 846.3542\n",
      "Epoch [20/100], Step [2200/4091], Loss: 847.2195\n",
      "Epoch [20/100], Step [2300/4091], Loss: 688.9058\n",
      "Epoch [20/100], Step [2400/4091], Loss: 809.0257\n",
      "Epoch [20/100], Step [2500/4091], Loss: 890.8655\n",
      "Epoch [20/100], Step [2600/4091], Loss: 698.8587\n",
      "Epoch [20/100], Step [2700/4091], Loss: 974.3823\n",
      "Epoch [20/100], Step [2800/4091], Loss: 745.5634\n",
      "Epoch [20/100], Step [2900/4091], Loss: 801.4852\n",
      "Epoch [20/100], Step [3000/4091], Loss: 751.2217\n",
      "Epoch [20/100], Step [3100/4091], Loss: 442.3884\n",
      "Epoch [20/100], Step [3200/4091], Loss: 1003.3063\n",
      "Epoch [20/100], Step [3300/4091], Loss: 673.6794\n",
      "Epoch [20/100], Step [3400/4091], Loss: 582.5257\n",
      "Epoch [20/100], Step [3500/4091], Loss: 1066.0444\n",
      "Epoch [20/100], Step [3600/4091], Loss: 898.9228\n",
      "Epoch [20/100], Step [3700/4091], Loss: 645.2486\n",
      "Epoch [20/100], Step [3800/4091], Loss: 485.6781\n",
      "Epoch [20/100], Step [3900/4091], Loss: 794.1500\n",
      "Epoch [20/100], Step [4000/4091], Loss: 622.6056\n",
      "Epoch [21/100], Step [100/4091], Loss: 708.5214\n",
      "Epoch [21/100], Step [200/4091], Loss: 576.2640\n",
      "Epoch [21/100], Step [300/4091], Loss: 538.2101\n",
      "Epoch [21/100], Step [400/4091], Loss: 566.7018\n",
      "Epoch [21/100], Step [500/4091], Loss: 896.9323\n",
      "Epoch [21/100], Step [600/4091], Loss: 763.5699\n",
      "Epoch [21/100], Step [700/4091], Loss: 499.7062\n",
      "Epoch [21/100], Step [800/4091], Loss: 762.3959\n",
      "Epoch [21/100], Step [900/4091], Loss: 751.8281\n",
      "Epoch [21/100], Step [1000/4091], Loss: 775.0935\n",
      "Epoch [21/100], Step [1100/4091], Loss: 994.8567\n",
      "Epoch [21/100], Step [1200/4091], Loss: 705.6243\n",
      "Epoch [21/100], Step [1300/4091], Loss: 648.3815\n",
      "Epoch [21/100], Step [1400/4091], Loss: 570.2969\n",
      "Epoch [21/100], Step [1500/4091], Loss: 745.3077\n",
      "Epoch [21/100], Step [1600/4091], Loss: 574.6351\n",
      "Epoch [21/100], Step [1700/4091], Loss: 599.0366\n",
      "Epoch [21/100], Step [1800/4091], Loss: 510.9174\n",
      "Epoch [21/100], Step [1900/4091], Loss: 708.0730\n",
      "Epoch [21/100], Step [2000/4091], Loss: 543.0276\n",
      "Epoch [21/100], Step [2100/4091], Loss: 525.6483\n",
      "Epoch [21/100], Step [2200/4091], Loss: 679.6639\n",
      "Epoch [21/100], Step [2300/4091], Loss: 566.3557\n",
      "Epoch [21/100], Step [2400/4091], Loss: 836.7177\n",
      "Epoch [21/100], Step [2500/4091], Loss: 442.3542\n",
      "Epoch [21/100], Step [2600/4091], Loss: 739.7090\n",
      "Epoch [21/100], Step [2700/4091], Loss: 668.4989\n",
      "Epoch [21/100], Step [2800/4091], Loss: 856.0305\n",
      "Epoch [21/100], Step [2900/4091], Loss: 680.1389\n",
      "Epoch [21/100], Step [3000/4091], Loss: 607.0363\n",
      "Epoch [21/100], Step [3100/4091], Loss: 700.1641\n",
      "Epoch [21/100], Step [3200/4091], Loss: 793.2238\n",
      "Epoch [21/100], Step [3300/4091], Loss: 576.9617\n",
      "Epoch [21/100], Step [3400/4091], Loss: 783.5541\n",
      "Epoch [21/100], Step [3500/4091], Loss: 466.7669\n",
      "Epoch [21/100], Step [3600/4091], Loss: 578.2073\n",
      "Epoch [21/100], Step [3700/4091], Loss: 658.9231\n",
      "Epoch [21/100], Step [3800/4091], Loss: 651.0258\n",
      "Epoch [21/100], Step [3900/4091], Loss: 585.8049\n",
      "Epoch [21/100], Step [4000/4091], Loss: 496.6262\n",
      "Epoch [22/100], Step [100/4091], Loss: 702.6490\n",
      "Epoch [22/100], Step [200/4091], Loss: 572.8470\n",
      "Epoch [22/100], Step [300/4091], Loss: 766.1642\n",
      "Epoch [22/100], Step [400/4091], Loss: 471.6245\n",
      "Epoch [22/100], Step [500/4091], Loss: 477.7367\n",
      "Epoch [22/100], Step [600/4091], Loss: 908.7869\n",
      "Epoch [22/100], Step [700/4091], Loss: 626.6130\n",
      "Epoch [22/100], Step [800/4091], Loss: 788.3685\n",
      "Epoch [22/100], Step [900/4091], Loss: 667.2263\n",
      "Epoch [22/100], Step [1000/4091], Loss: 538.4698\n",
      "Epoch [22/100], Step [1100/4091], Loss: 685.9780\n",
      "Epoch [22/100], Step [1200/4091], Loss: 700.7478\n",
      "Epoch [22/100], Step [1300/4091], Loss: 578.6252\n",
      "Epoch [22/100], Step [1400/4091], Loss: 586.5033\n",
      "Epoch [22/100], Step [1500/4091], Loss: 726.4610\n",
      "Epoch [22/100], Step [1600/4091], Loss: 684.7693\n",
      "Epoch [22/100], Step [1700/4091], Loss: 524.4896\n",
      "Epoch [22/100], Step [1800/4091], Loss: 519.1947\n",
      "Epoch [22/100], Step [1900/4091], Loss: 498.6600\n",
      "Epoch [22/100], Step [2000/4091], Loss: 737.4895\n",
      "Epoch [22/100], Step [2100/4091], Loss: 758.8657\n",
      "Epoch [22/100], Step [2200/4091], Loss: 680.1330\n",
      "Epoch [22/100], Step [2300/4091], Loss: 604.2259\n",
      "Epoch [22/100], Step [2400/4091], Loss: 608.4352\n",
      "Epoch [22/100], Step [2500/4091], Loss: 565.5009\n",
      "Epoch [22/100], Step [2600/4091], Loss: 872.7390\n",
      "Epoch [22/100], Step [2700/4091], Loss: 662.9134\n",
      "Epoch [22/100], Step [2800/4091], Loss: 739.9664\n",
      "Epoch [22/100], Step [2900/4091], Loss: 529.1038\n",
      "Epoch [22/100], Step [3000/4091], Loss: 556.1224\n",
      "Epoch [22/100], Step [3100/4091], Loss: 604.9335\n",
      "Epoch [22/100], Step [3200/4091], Loss: 774.5258\n",
      "Epoch [22/100], Step [3300/4091], Loss: 681.9673\n",
      "Epoch [22/100], Step [3400/4091], Loss: 683.3076\n",
      "Epoch [22/100], Step [3500/4091], Loss: 825.2873\n",
      "Epoch [22/100], Step [3600/4091], Loss: 717.3310\n",
      "Epoch [22/100], Step [3700/4091], Loss: 505.7387\n",
      "Epoch [22/100], Step [3800/4091], Loss: 837.1971\n",
      "Epoch [22/100], Step [3900/4091], Loss: 730.5545\n",
      "Epoch [22/100], Step [4000/4091], Loss: 736.8608\n",
      "Epoch [23/100], Step [100/4091], Loss: 580.0615\n",
      "Epoch [23/100], Step [200/4091], Loss: 845.5108\n",
      "Epoch [23/100], Step [300/4091], Loss: 535.1539\n",
      "Epoch [23/100], Step [400/4091], Loss: 781.2823\n",
      "Epoch [23/100], Step [500/4091], Loss: 750.3160\n",
      "Epoch [23/100], Step [600/4091], Loss: 734.6005\n",
      "Epoch [23/100], Step [700/4091], Loss: 810.6540\n",
      "Epoch [23/100], Step [800/4091], Loss: 721.6522\n",
      "Epoch [23/100], Step [900/4091], Loss: 565.8651\n",
      "Epoch [23/100], Step [1000/4091], Loss: 751.3625\n",
      "Epoch [23/100], Step [1100/4091], Loss: 654.7528\n",
      "Epoch [23/100], Step [1200/4091], Loss: 644.6565\n",
      "Epoch [23/100], Step [1300/4091], Loss: 762.4700\n",
      "Epoch [23/100], Step [1400/4091], Loss: 479.2255\n",
      "Epoch [23/100], Step [1500/4091], Loss: 604.8601\n",
      "Epoch [23/100], Step [1600/4091], Loss: 608.6116\n",
      "Epoch [23/100], Step [1700/4091], Loss: 524.7332\n",
      "Epoch [23/100], Step [1800/4091], Loss: 601.4326\n",
      "Epoch [23/100], Step [1900/4091], Loss: 699.5026\n",
      "Epoch [23/100], Step [2000/4091], Loss: 671.1319\n",
      "Epoch [23/100], Step [2100/4091], Loss: 842.4346\n",
      "Epoch [23/100], Step [2200/4091], Loss: 895.7362\n",
      "Epoch [23/100], Step [2300/4091], Loss: 595.4368\n",
      "Epoch [23/100], Step [2400/4091], Loss: 568.9258\n",
      "Epoch [23/100], Step [2500/4091], Loss: 565.6639\n",
      "Epoch [23/100], Step [2600/4091], Loss: 560.9543\n",
      "Epoch [23/100], Step [2700/4091], Loss: 665.0489\n",
      "Epoch [23/100], Step [2800/4091], Loss: 621.5897\n",
      "Epoch [23/100], Step [2900/4091], Loss: 601.5514\n",
      "Epoch [23/100], Step [3000/4091], Loss: 647.6151\n",
      "Epoch [23/100], Step [3100/4091], Loss: 511.6066\n",
      "Epoch [23/100], Step [3200/4091], Loss: 711.5018\n",
      "Epoch [23/100], Step [3300/4091], Loss: 647.9432\n",
      "Epoch [23/100], Step [3400/4091], Loss: 641.8387\n",
      "Epoch [23/100], Step [3500/4091], Loss: 506.8078\n",
      "Epoch [23/100], Step [3600/4091], Loss: 821.0151\n",
      "Epoch [23/100], Step [3700/4091], Loss: 824.1584\n",
      "Epoch [23/100], Step [3800/4091], Loss: 629.6844\n",
      "Epoch [23/100], Step [3900/4091], Loss: 667.1260\n",
      "Epoch [23/100], Step [4000/4091], Loss: 774.6377\n",
      "Epoch [24/100], Step [100/4091], Loss: 655.8963\n",
      "Epoch [24/100], Step [200/4091], Loss: 831.9995\n",
      "Epoch [24/100], Step [300/4091], Loss: 781.0131\n",
      "Epoch [24/100], Step [400/4091], Loss: 626.6417\n",
      "Epoch [24/100], Step [500/4091], Loss: 687.0365\n",
      "Epoch [24/100], Step [600/4091], Loss: 557.8434\n",
      "Epoch [24/100], Step [700/4091], Loss: 777.0077\n",
      "Epoch [24/100], Step [800/4091], Loss: 770.8672\n",
      "Epoch [24/100], Step [900/4091], Loss: 761.0453\n",
      "Epoch [24/100], Step [1000/4091], Loss: 558.5566\n",
      "Epoch [24/100], Step [1100/4091], Loss: 605.5458\n",
      "Epoch [24/100], Step [1200/4091], Loss: 660.0485\n",
      "Epoch [24/100], Step [1300/4091], Loss: 620.7352\n",
      "Epoch [24/100], Step [1400/4091], Loss: 564.5334\n",
      "Epoch [24/100], Step [1500/4091], Loss: 744.6046\n",
      "Epoch [24/100], Step [1600/4091], Loss: 878.3886\n",
      "Epoch [24/100], Step [1700/4091], Loss: 603.7797\n",
      "Epoch [24/100], Step [1800/4091], Loss: 664.6173\n",
      "Epoch [24/100], Step [1900/4091], Loss: 656.4822\n",
      "Epoch [24/100], Step [2000/4091], Loss: 482.3188\n",
      "Epoch [24/100], Step [2100/4091], Loss: 817.8506\n",
      "Epoch [24/100], Step [2200/4091], Loss: 645.6407\n",
      "Epoch [24/100], Step [2300/4091], Loss: 584.8472\n",
      "Epoch [24/100], Step [2400/4091], Loss: 1016.2742\n",
      "Epoch [24/100], Step [2500/4091], Loss: 694.1161\n",
      "Epoch [24/100], Step [2600/4091], Loss: 794.6216\n",
      "Epoch [24/100], Step [2700/4091], Loss: 798.0070\n",
      "Epoch [24/100], Step [2800/4091], Loss: 710.2325\n",
      "Epoch [24/100], Step [2900/4091], Loss: 589.9823\n",
      "Epoch [24/100], Step [3000/4091], Loss: 705.6679\n",
      "Epoch [24/100], Step [3100/4091], Loss: 806.8030\n",
      "Epoch [24/100], Step [3200/4091], Loss: 618.3411\n",
      "Epoch [24/100], Step [3300/4091], Loss: 557.3065\n",
      "Epoch [24/100], Step [3400/4091], Loss: 533.4108\n",
      "Epoch [24/100], Step [3500/4091], Loss: 492.9004\n",
      "Epoch [24/100], Step [3600/4091], Loss: 694.0511\n",
      "Epoch [24/100], Step [3700/4091], Loss: 374.3418\n",
      "Epoch [24/100], Step [3800/4091], Loss: 783.8135\n",
      "Epoch [24/100], Step [3900/4091], Loss: 629.7998\n",
      "Epoch [24/100], Step [4000/4091], Loss: 689.8731\n",
      "Epoch [25/100], Step [100/4091], Loss: 470.0150\n",
      "Epoch [25/100], Step [200/4091], Loss: 938.5237\n",
      "Epoch [25/100], Step [300/4091], Loss: 622.7990\n",
      "Epoch [25/100], Step [400/4091], Loss: 615.9318\n",
      "Epoch [25/100], Step [500/4091], Loss: 786.2010\n",
      "Epoch [25/100], Step [600/4091], Loss: 617.8143\n",
      "Epoch [25/100], Step [700/4091], Loss: 616.3737\n",
      "Epoch [25/100], Step [800/4091], Loss: 715.5647\n",
      "Epoch [25/100], Step [900/4091], Loss: 747.8082\n",
      "Epoch [25/100], Step [1000/4091], Loss: 614.1589\n",
      "Epoch [25/100], Step [1100/4091], Loss: 559.7083\n",
      "Epoch [25/100], Step [1200/4091], Loss: 674.8484\n",
      "Epoch [25/100], Step [1300/4091], Loss: 642.5452\n",
      "Epoch [25/100], Step [1400/4091], Loss: 737.0228\n",
      "Epoch [25/100], Step [1500/4091], Loss: 750.5319\n",
      "Epoch [25/100], Step [1600/4091], Loss: 667.7486\n",
      "Epoch [25/100], Step [1700/4091], Loss: 548.8009\n",
      "Epoch [25/100], Step [1800/4091], Loss: 568.3942\n",
      "Epoch [25/100], Step [1900/4091], Loss: 822.9905\n",
      "Epoch [25/100], Step [2000/4091], Loss: 602.4631\n",
      "Epoch [25/100], Step [2100/4091], Loss: 759.2196\n",
      "Epoch [25/100], Step [2200/4091], Loss: 553.1098\n",
      "Epoch [25/100], Step [2300/4091], Loss: 673.5048\n",
      "Epoch [25/100], Step [2400/4091], Loss: 586.8414\n",
      "Epoch [25/100], Step [2500/4091], Loss: 730.0769\n",
      "Epoch [25/100], Step [2600/4091], Loss: 863.9660\n",
      "Epoch [25/100], Step [2700/4091], Loss: 418.7644\n",
      "Epoch [25/100], Step [2800/4091], Loss: 794.6309\n",
      "Epoch [25/100], Step [2900/4091], Loss: 822.6366\n",
      "Epoch [25/100], Step [3000/4091], Loss: 587.4151\n",
      "Epoch [25/100], Step [3100/4091], Loss: 819.7101\n",
      "Epoch [25/100], Step [3200/4091], Loss: 727.9451\n",
      "Epoch [25/100], Step [3300/4091], Loss: 658.8682\n",
      "Epoch [25/100], Step [3400/4091], Loss: 366.9073\n",
      "Epoch [25/100], Step [3500/4091], Loss: 636.7104\n",
      "Epoch [25/100], Step [3600/4091], Loss: 496.2484\n",
      "Epoch [25/100], Step [3700/4091], Loss: 740.9754\n",
      "Epoch [25/100], Step [3800/4091], Loss: 731.5084\n",
      "Epoch [25/100], Step [3900/4091], Loss: 825.8184\n",
      "Epoch [25/100], Step [4000/4091], Loss: 725.7410\n",
      "Epoch [26/100], Step [100/4091], Loss: 565.8300\n",
      "Epoch [26/100], Step [200/4091], Loss: 665.5411\n",
      "Epoch [26/100], Step [300/4091], Loss: 889.4893\n",
      "Epoch [26/100], Step [400/4091], Loss: 776.2704\n",
      "Epoch [26/100], Step [500/4091], Loss: 525.3185\n",
      "Epoch [26/100], Step [600/4091], Loss: 757.4644\n",
      "Epoch [26/100], Step [700/4091], Loss: 839.8993\n",
      "Epoch [26/100], Step [800/4091], Loss: 822.5814\n",
      "Epoch [26/100], Step [900/4091], Loss: 778.1082\n",
      "Epoch [26/100], Step [1000/4091], Loss: 748.4241\n",
      "Epoch [26/100], Step [1100/4091], Loss: 615.1844\n",
      "Epoch [26/100], Step [1200/4091], Loss: 714.8971\n",
      "Epoch [26/100], Step [1300/4091], Loss: 640.8616\n",
      "Epoch [26/100], Step [1400/4091], Loss: 820.7695\n",
      "Epoch [26/100], Step [1500/4091], Loss: 748.9785\n",
      "Epoch [26/100], Step [1600/4091], Loss: 853.7070\n",
      "Epoch [26/100], Step [1700/4091], Loss: 604.6254\n",
      "Epoch [26/100], Step [1800/4091], Loss: 618.1442\n",
      "Epoch [26/100], Step [1900/4091], Loss: 661.1705\n",
      "Epoch [26/100], Step [2000/4091], Loss: 548.8171\n",
      "Epoch [26/100], Step [2100/4091], Loss: 513.1544\n",
      "Epoch [26/100], Step [2200/4091], Loss: 456.0355\n",
      "Epoch [26/100], Step [2300/4091], Loss: 553.6715\n",
      "Epoch [26/100], Step [2400/4091], Loss: 948.1161\n",
      "Epoch [26/100], Step [2500/4091], Loss: 472.0766\n",
      "Epoch [26/100], Step [2600/4091], Loss: 682.0497\n",
      "Epoch [26/100], Step [2700/4091], Loss: 642.3255\n",
      "Epoch [26/100], Step [2800/4091], Loss: 581.6902\n",
      "Epoch [26/100], Step [2900/4091], Loss: 988.5033\n",
      "Epoch [26/100], Step [3000/4091], Loss: 644.7125\n",
      "Epoch [26/100], Step [3100/4091], Loss: 672.0321\n",
      "Epoch [26/100], Step [3200/4091], Loss: 603.0818\n",
      "Epoch [26/100], Step [3300/4091], Loss: 610.1995\n",
      "Epoch [26/100], Step [3400/4091], Loss: 440.9128\n",
      "Epoch [26/100], Step [3500/4091], Loss: 410.3614\n",
      "Epoch [26/100], Step [3600/4091], Loss: 667.0151\n",
      "Epoch [26/100], Step [3700/4091], Loss: 585.9744\n",
      "Epoch [26/100], Step [3800/4091], Loss: 551.0259\n",
      "Epoch [26/100], Step [3900/4091], Loss: 792.9977\n",
      "Epoch [26/100], Step [4000/4091], Loss: 667.3493\n",
      "Epoch [27/100], Step [100/4091], Loss: 638.1633\n",
      "Epoch [27/100], Step [200/4091], Loss: 716.9939\n",
      "Epoch [27/100], Step [300/4091], Loss: 750.9131\n",
      "Epoch [27/100], Step [400/4091], Loss: 647.6129\n",
      "Epoch [27/100], Step [500/4091], Loss: 808.0881\n",
      "Epoch [27/100], Step [600/4091], Loss: 618.6107\n",
      "Epoch [27/100], Step [700/4091], Loss: 490.3657\n",
      "Epoch [27/100], Step [800/4091], Loss: 777.9017\n",
      "Epoch [27/100], Step [900/4091], Loss: 839.0155\n",
      "Epoch [27/100], Step [1000/4091], Loss: 715.7285\n",
      "Epoch [27/100], Step [1100/4091], Loss: 616.9193\n",
      "Epoch [27/100], Step [1200/4091], Loss: 552.5211\n",
      "Epoch [27/100], Step [1300/4091], Loss: 859.6519\n",
      "Epoch [27/100], Step [1400/4091], Loss: 710.5486\n",
      "Epoch [27/100], Step [1500/4091], Loss: 770.6498\n",
      "Epoch [27/100], Step [1600/4091], Loss: 925.4924\n",
      "Epoch [27/100], Step [1700/4091], Loss: 745.4789\n",
      "Epoch [27/100], Step [1800/4091], Loss: 501.1850\n",
      "Epoch [27/100], Step [1900/4091], Loss: 687.5289\n",
      "Epoch [27/100], Step [2000/4091], Loss: 749.5375\n",
      "Epoch [27/100], Step [2100/4091], Loss: 846.3658\n",
      "Epoch [27/100], Step [2200/4091], Loss: 626.8129\n",
      "Epoch [27/100], Step [2300/4091], Loss: 698.5856\n",
      "Epoch [27/100], Step [2400/4091], Loss: 699.3207\n",
      "Epoch [27/100], Step [2500/4091], Loss: 738.3488\n",
      "Epoch [27/100], Step [2600/4091], Loss: 443.2419\n",
      "Epoch [27/100], Step [2700/4091], Loss: 578.2537\n",
      "Epoch [27/100], Step [2800/4091], Loss: 719.1434\n",
      "Epoch [27/100], Step [2900/4091], Loss: 529.7474\n",
      "Epoch [27/100], Step [3000/4091], Loss: 572.7322\n",
      "Epoch [27/100], Step [3100/4091], Loss: 681.4238\n",
      "Epoch [27/100], Step [3200/4091], Loss: 500.7560\n",
      "Epoch [27/100], Step [3300/4091], Loss: 783.2184\n",
      "Epoch [27/100], Step [3400/4091], Loss: 632.9068\n",
      "Epoch [27/100], Step [3500/4091], Loss: 599.8007\n",
      "Epoch [27/100], Step [3600/4091], Loss: 677.5699\n",
      "Epoch [27/100], Step [3700/4091], Loss: 707.6826\n",
      "Epoch [27/100], Step [3800/4091], Loss: 664.3249\n",
      "Epoch [27/100], Step [3900/4091], Loss: 794.7529\n",
      "Epoch [27/100], Step [4000/4091], Loss: 729.7102\n",
      "Epoch [28/100], Step [100/4091], Loss: 644.3862\n",
      "Epoch [28/100], Step [200/4091], Loss: 792.6199\n",
      "Epoch [28/100], Step [300/4091], Loss: 761.5879\n",
      "Epoch [28/100], Step [400/4091], Loss: 590.1389\n",
      "Epoch [28/100], Step [500/4091], Loss: 539.9298\n",
      "Epoch [28/100], Step [600/4091], Loss: 580.0081\n",
      "Epoch [28/100], Step [700/4091], Loss: 525.9215\n",
      "Epoch [28/100], Step [800/4091], Loss: 720.3410\n",
      "Epoch [28/100], Step [900/4091], Loss: 642.6926\n",
      "Epoch [28/100], Step [1000/4091], Loss: 576.4346\n",
      "Epoch [28/100], Step [1100/4091], Loss: 620.4476\n",
      "Epoch [28/100], Step [1200/4091], Loss: 489.8733\n",
      "Epoch [28/100], Step [1300/4091], Loss: 701.9686\n",
      "Epoch [28/100], Step [1400/4091], Loss: 679.9863\n",
      "Epoch [28/100], Step [1500/4091], Loss: 760.3025\n",
      "Epoch [28/100], Step [1600/4091], Loss: 567.6437\n",
      "Epoch [28/100], Step [1700/4091], Loss: 572.2554\n",
      "Epoch [28/100], Step [1800/4091], Loss: 690.8040\n",
      "Epoch [28/100], Step [1900/4091], Loss: 776.9020\n",
      "Epoch [28/100], Step [2000/4091], Loss: 714.7352\n",
      "Epoch [28/100], Step [2100/4091], Loss: 542.1037\n",
      "Epoch [28/100], Step [2200/4091], Loss: 516.5428\n",
      "Epoch [28/100], Step [2300/4091], Loss: 593.7096\n",
      "Epoch [28/100], Step [2400/4091], Loss: 581.3290\n",
      "Epoch [28/100], Step [2500/4091], Loss: 531.4189\n",
      "Epoch [28/100], Step [2600/4091], Loss: 476.8595\n",
      "Epoch [28/100], Step [2700/4091], Loss: 600.2922\n",
      "Epoch [28/100], Step [2800/4091], Loss: 462.0229\n",
      "Epoch [28/100], Step [2900/4091], Loss: 498.3059\n",
      "Epoch [28/100], Step [3000/4091], Loss: 695.0247\n",
      "Epoch [28/100], Step [3100/4091], Loss: 442.1789\n",
      "Epoch [28/100], Step [3200/4091], Loss: 852.1421\n",
      "Epoch [28/100], Step [3300/4091], Loss: 739.5004\n",
      "Epoch [28/100], Step [3400/4091], Loss: 560.5540\n",
      "Epoch [28/100], Step [3500/4091], Loss: 538.8770\n",
      "Epoch [28/100], Step [3600/4091], Loss: 794.2650\n",
      "Epoch [28/100], Step [3700/4091], Loss: 607.9569\n",
      "Epoch [28/100], Step [3800/4091], Loss: 494.8406\n",
      "Epoch [28/100], Step [3900/4091], Loss: 764.5468\n",
      "Epoch [28/100], Step [4000/4091], Loss: 644.5194\n",
      "Epoch [29/100], Step [100/4091], Loss: 651.8303\n",
      "Epoch [29/100], Step [200/4091], Loss: 589.3422\n",
      "Epoch [29/100], Step [300/4091], Loss: 806.5543\n",
      "Epoch [29/100], Step [400/4091], Loss: 520.5881\n",
      "Epoch [29/100], Step [500/4091], Loss: 635.9696\n",
      "Epoch [29/100], Step [600/4091], Loss: 644.7475\n",
      "Epoch [29/100], Step [700/4091], Loss: 494.4021\n",
      "Epoch [29/100], Step [800/4091], Loss: 493.2939\n",
      "Epoch [29/100], Step [900/4091], Loss: 749.2631\n",
      "Epoch [29/100], Step [1000/4091], Loss: 801.1517\n",
      "Epoch [29/100], Step [1100/4091], Loss: 795.5266\n",
      "Epoch [29/100], Step [1200/4091], Loss: 726.8181\n",
      "Epoch [29/100], Step [1300/4091], Loss: 763.9054\n",
      "Epoch [29/100], Step [1400/4091], Loss: 700.0972\n",
      "Epoch [29/100], Step [1500/4091], Loss: 814.5615\n",
      "Epoch [29/100], Step [1600/4091], Loss: 674.0428\n",
      "Epoch [29/100], Step [1700/4091], Loss: 809.1708\n",
      "Epoch [29/100], Step [1800/4091], Loss: 741.2716\n",
      "Epoch [29/100], Step [1900/4091], Loss: 505.8103\n",
      "Epoch [29/100], Step [2000/4091], Loss: 608.8184\n",
      "Epoch [29/100], Step [2100/4091], Loss: 788.5019\n",
      "Epoch [29/100], Step [2200/4091], Loss: 487.9271\n",
      "Epoch [29/100], Step [2300/4091], Loss: 785.0602\n",
      "Epoch [29/100], Step [2400/4091], Loss: 562.9731\n",
      "Epoch [29/100], Step [2500/4091], Loss: 716.3889\n",
      "Epoch [29/100], Step [2600/4091], Loss: 753.0847\n",
      "Epoch [29/100], Step [2700/4091], Loss: 889.3620\n",
      "Epoch [29/100], Step [2800/4091], Loss: 923.7852\n",
      "Epoch [29/100], Step [2900/4091], Loss: 699.2480\n",
      "Epoch [29/100], Step [3000/4091], Loss: 731.3152\n",
      "Epoch [29/100], Step [3100/4091], Loss: 691.9236\n",
      "Epoch [29/100], Step [3200/4091], Loss: 577.8946\n",
      "Epoch [29/100], Step [3300/4091], Loss: 570.6183\n",
      "Epoch [29/100], Step [3400/4091], Loss: 464.7571\n",
      "Epoch [29/100], Step [3500/4091], Loss: 822.9020\n",
      "Epoch [29/100], Step [3600/4091], Loss: 748.8088\n",
      "Epoch [29/100], Step [3700/4091], Loss: 565.1208\n",
      "Epoch [29/100], Step [3800/4091], Loss: 737.5689\n",
      "Epoch [29/100], Step [3900/4091], Loss: 716.5494\n",
      "Epoch [29/100], Step [4000/4091], Loss: 702.9582\n",
      "Epoch [30/100], Step [100/4091], Loss: 725.8083\n",
      "Epoch [30/100], Step [200/4091], Loss: 797.0018\n",
      "Epoch [30/100], Step [300/4091], Loss: 905.3555\n",
      "Epoch [30/100], Step [400/4091], Loss: 773.1174\n",
      "Epoch [30/100], Step [500/4091], Loss: 647.4692\n",
      "Epoch [30/100], Step [600/4091], Loss: 499.5261\n",
      "Epoch [30/100], Step [700/4091], Loss: 930.8234\n",
      "Epoch [30/100], Step [800/4091], Loss: 478.7849\n",
      "Epoch [30/100], Step [900/4091], Loss: 612.2069\n",
      "Epoch [30/100], Step [1000/4091], Loss: 796.1917\n",
      "Epoch [30/100], Step [1100/4091], Loss: 837.8183\n",
      "Epoch [30/100], Step [1200/4091], Loss: 661.4016\n",
      "Epoch [30/100], Step [1300/4091], Loss: 720.1164\n",
      "Epoch [30/100], Step [1400/4091], Loss: 506.2055\n",
      "Epoch [30/100], Step [1500/4091], Loss: 619.9435\n",
      "Epoch [30/100], Step [1600/4091], Loss: 579.3419\n",
      "Epoch [30/100], Step [1700/4091], Loss: 698.2868\n",
      "Epoch [30/100], Step [1800/4091], Loss: 600.1271\n",
      "Epoch [30/100], Step [1900/4091], Loss: 718.0156\n",
      "Epoch [30/100], Step [2000/4091], Loss: 833.3228\n",
      "Epoch [30/100], Step [2100/4091], Loss: 619.2225\n",
      "Epoch [30/100], Step [2200/4091], Loss: 745.2291\n",
      "Epoch [30/100], Step [2300/4091], Loss: 560.8107\n",
      "Epoch [30/100], Step [2400/4091], Loss: 872.0980\n",
      "Epoch [30/100], Step [2500/4091], Loss: 683.0659\n",
      "Epoch [30/100], Step [2600/4091], Loss: 545.4058\n",
      "Epoch [30/100], Step [2700/4091], Loss: 782.7638\n",
      "Epoch [30/100], Step [2800/4091], Loss: 761.5966\n",
      "Epoch [30/100], Step [2900/4091], Loss: 618.9179\n",
      "Epoch [30/100], Step [3000/4091], Loss: 788.0832\n",
      "Epoch [30/100], Step [3100/4091], Loss: 577.5400\n",
      "Epoch [30/100], Step [3200/4091], Loss: 557.0435\n",
      "Epoch [30/100], Step [3300/4091], Loss: 731.4667\n",
      "Epoch [30/100], Step [3400/4091], Loss: 617.8118\n",
      "Epoch [30/100], Step [3500/4091], Loss: 946.8247\n",
      "Epoch [30/100], Step [3600/4091], Loss: 665.9442\n",
      "Epoch [30/100], Step [3700/4091], Loss: 741.5986\n",
      "Epoch [30/100], Step [3800/4091], Loss: 864.3665\n",
      "Epoch [30/100], Step [3900/4091], Loss: 543.4933\n",
      "Epoch [30/100], Step [4000/4091], Loss: 650.9739\n",
      "Epoch [31/100], Step [100/4091], Loss: 446.0127\n",
      "Epoch [31/100], Step [200/4091], Loss: 623.6146\n",
      "Epoch [31/100], Step [300/4091], Loss: 631.0643\n",
      "Epoch [31/100], Step [400/4091], Loss: 928.5984\n",
      "Epoch [31/100], Step [500/4091], Loss: 631.4366\n",
      "Epoch [31/100], Step [600/4091], Loss: 696.9202\n",
      "Epoch [31/100], Step [700/4091], Loss: 623.8716\n",
      "Epoch [31/100], Step [800/4091], Loss: 637.3640\n",
      "Epoch [31/100], Step [900/4091], Loss: 641.1778\n",
      "Epoch [31/100], Step [1000/4091], Loss: 535.4462\n",
      "Epoch [31/100], Step [1100/4091], Loss: 595.6450\n",
      "Epoch [31/100], Step [1200/4091], Loss: 662.7620\n",
      "Epoch [31/100], Step [1300/4091], Loss: 817.0735\n",
      "Epoch [31/100], Step [1400/4091], Loss: 529.6599\n",
      "Epoch [31/100], Step [1500/4091], Loss: 612.7841\n",
      "Epoch [31/100], Step [1600/4091], Loss: 791.7916\n",
      "Epoch [31/100], Step [1700/4091], Loss: 691.0193\n",
      "Epoch [31/100], Step [1800/4091], Loss: 782.7916\n",
      "Epoch [31/100], Step [1900/4091], Loss: 807.8353\n",
      "Epoch [31/100], Step [2000/4091], Loss: 412.8223\n",
      "Epoch [31/100], Step [2100/4091], Loss: 796.6952\n",
      "Epoch [31/100], Step [2200/4091], Loss: 554.7979\n",
      "Epoch [31/100], Step [2300/4091], Loss: 827.7943\n",
      "Epoch [31/100], Step [2400/4091], Loss: 554.3457\n",
      "Epoch [31/100], Step [2500/4091], Loss: 649.1669\n",
      "Epoch [31/100], Step [2600/4091], Loss: 639.4407\n",
      "Epoch [31/100], Step [2700/4091], Loss: 854.6287\n",
      "Epoch [31/100], Step [2800/4091], Loss: 915.0266\n",
      "Epoch [31/100], Step [2900/4091], Loss: 500.8500\n",
      "Epoch [31/100], Step [3000/4091], Loss: 546.5670\n",
      "Epoch [31/100], Step [3100/4091], Loss: 767.3940\n",
      "Epoch [31/100], Step [3200/4091], Loss: 981.8563\n",
      "Epoch [31/100], Step [3300/4091], Loss: 670.8407\n",
      "Epoch [31/100], Step [3400/4091], Loss: 595.8547\n",
      "Epoch [31/100], Step [3500/4091], Loss: 835.3671\n",
      "Epoch [31/100], Step [3600/4091], Loss: 689.6624\n",
      "Epoch [31/100], Step [3700/4091], Loss: 636.5259\n",
      "Epoch [31/100], Step [3800/4091], Loss: 562.9321\n",
      "Epoch [31/100], Step [3900/4091], Loss: 973.6264\n",
      "Epoch [31/100], Step [4000/4091], Loss: 570.9799\n",
      "Epoch [32/100], Step [100/4091], Loss: 720.4051\n",
      "Epoch [32/100], Step [200/4091], Loss: 738.0875\n",
      "Epoch [32/100], Step [300/4091], Loss: 688.5407\n",
      "Epoch [32/100], Step [400/4091], Loss: 730.5486\n",
      "Epoch [32/100], Step [500/4091], Loss: 481.4489\n",
      "Epoch [32/100], Step [600/4091], Loss: 613.8396\n",
      "Epoch [32/100], Step [700/4091], Loss: 744.3187\n",
      "Epoch [32/100], Step [800/4091], Loss: 609.5827\n",
      "Epoch [32/100], Step [900/4091], Loss: 665.9583\n",
      "Epoch [32/100], Step [1000/4091], Loss: 717.7252\n",
      "Epoch [32/100], Step [1100/4091], Loss: 598.6769\n",
      "Epoch [32/100], Step [1200/4091], Loss: 752.3857\n",
      "Epoch [32/100], Step [1300/4091], Loss: 705.7595\n",
      "Epoch [32/100], Step [1400/4091], Loss: 809.9467\n",
      "Epoch [32/100], Step [1500/4091], Loss: 530.7462\n",
      "Epoch [32/100], Step [1600/4091], Loss: 792.6962\n",
      "Epoch [32/100], Step [1700/4091], Loss: 771.4028\n",
      "Epoch [32/100], Step [1800/4091], Loss: 493.3133\n",
      "Epoch [32/100], Step [1900/4091], Loss: 681.2167\n",
      "Epoch [32/100], Step [2000/4091], Loss: 729.2389\n",
      "Epoch [32/100], Step [2100/4091], Loss: 622.8658\n",
      "Epoch [32/100], Step [2200/4091], Loss: 601.1260\n",
      "Epoch [32/100], Step [2300/4091], Loss: 639.9374\n",
      "Epoch [32/100], Step [2400/4091], Loss: 582.6986\n",
      "Epoch [32/100], Step [2500/4091], Loss: 380.8331\n",
      "Epoch [32/100], Step [2600/4091], Loss: 590.4608\n",
      "Epoch [32/100], Step [2700/4091], Loss: 587.3938\n",
      "Epoch [32/100], Step [2800/4091], Loss: 969.9115\n",
      "Epoch [32/100], Step [2900/4091], Loss: 736.5065\n",
      "Epoch [32/100], Step [3000/4091], Loss: 812.4080\n",
      "Epoch [32/100], Step [3100/4091], Loss: 641.8997\n",
      "Epoch [32/100], Step [3200/4091], Loss: 629.9960\n",
      "Epoch [32/100], Step [3300/4091], Loss: 823.8253\n",
      "Epoch [32/100], Step [3400/4091], Loss: 625.7134\n",
      "Epoch [32/100], Step [3500/4091], Loss: 894.0714\n",
      "Epoch [32/100], Step [3600/4091], Loss: 540.1987\n",
      "Epoch [32/100], Step [3700/4091], Loss: 802.3963\n",
      "Epoch [32/100], Step [3800/4091], Loss: 735.9779\n",
      "Epoch [32/100], Step [3900/4091], Loss: 499.5221\n",
      "Epoch [32/100], Step [4000/4091], Loss: 580.0542\n",
      "Epoch [33/100], Step [100/4091], Loss: 615.0053\n",
      "Epoch [33/100], Step [200/4091], Loss: 596.5159\n",
      "Epoch [33/100], Step [300/4091], Loss: 753.6640\n",
      "Epoch [33/100], Step [400/4091], Loss: 546.6312\n",
      "Epoch [33/100], Step [500/4091], Loss: 489.8824\n",
      "Epoch [33/100], Step [600/4091], Loss: 759.3538\n",
      "Epoch [33/100], Step [700/4091], Loss: 1072.2921\n",
      "Epoch [33/100], Step [800/4091], Loss: 594.5515\n",
      "Epoch [33/100], Step [900/4091], Loss: 828.0579\n",
      "Epoch [33/100], Step [1000/4091], Loss: 493.6089\n",
      "Epoch [33/100], Step [1100/4091], Loss: 548.0320\n",
      "Epoch [33/100], Step [1200/4091], Loss: 817.3218\n",
      "Epoch [33/100], Step [1300/4091], Loss: 692.5293\n",
      "Epoch [33/100], Step [1400/4091], Loss: 575.3795\n",
      "Epoch [33/100], Step [1500/4091], Loss: 731.6423\n",
      "Epoch [33/100], Step [1600/4091], Loss: 643.2889\n",
      "Epoch [33/100], Step [1700/4091], Loss: 752.1915\n",
      "Epoch [33/100], Step [1800/4091], Loss: 577.6657\n",
      "Epoch [33/100], Step [1900/4091], Loss: 509.0464\n",
      "Epoch [33/100], Step [2000/4091], Loss: 710.2619\n",
      "Epoch [33/100], Step [2100/4091], Loss: 645.7471\n",
      "Epoch [33/100], Step [2200/4091], Loss: 729.8449\n",
      "Epoch [33/100], Step [2300/4091], Loss: 701.6205\n",
      "Epoch [33/100], Step [2400/4091], Loss: 670.6810\n",
      "Epoch [33/100], Step [2500/4091], Loss: 621.2854\n",
      "Epoch [33/100], Step [2600/4091], Loss: 785.8179\n",
      "Epoch [33/100], Step [2700/4091], Loss: 701.1191\n",
      "Epoch [33/100], Step [2800/4091], Loss: 666.4341\n",
      "Epoch [33/100], Step [2900/4091], Loss: 498.6210\n",
      "Epoch [33/100], Step [3000/4091], Loss: 623.6730\n",
      "Epoch [33/100], Step [3100/4091], Loss: 671.6126\n",
      "Epoch [33/100], Step [3200/4091], Loss: 690.6851\n",
      "Epoch [33/100], Step [3300/4091], Loss: 432.0789\n",
      "Epoch [33/100], Step [3400/4091], Loss: 757.3227\n",
      "Epoch [33/100], Step [3500/4091], Loss: 674.9896\n",
      "Epoch [33/100], Step [3600/4091], Loss: 692.6866\n",
      "Epoch [33/100], Step [3700/4091], Loss: 748.8901\n",
      "Epoch [33/100], Step [3800/4091], Loss: 532.2303\n",
      "Epoch [33/100], Step [3900/4091], Loss: 797.8867\n",
      "Epoch [33/100], Step [4000/4091], Loss: 884.4895\n",
      "Epoch [34/100], Step [100/4091], Loss: 703.5152\n",
      "Epoch [34/100], Step [200/4091], Loss: 634.4476\n",
      "Epoch [34/100], Step [300/4091], Loss: 638.5411\n",
      "Epoch [34/100], Step [400/4091], Loss: 591.7486\n",
      "Epoch [34/100], Step [500/4091], Loss: 711.4952\n",
      "Epoch [34/100], Step [600/4091], Loss: 863.7201\n",
      "Epoch [34/100], Step [700/4091], Loss: 933.1068\n",
      "Epoch [34/100], Step [800/4091], Loss: 668.1033\n",
      "Epoch [34/100], Step [900/4091], Loss: 542.7849\n",
      "Epoch [34/100], Step [1000/4091], Loss: 604.4481\n",
      "Epoch [34/100], Step [1100/4091], Loss: 545.6412\n",
      "Epoch [34/100], Step [1200/4091], Loss: 538.0040\n",
      "Epoch [34/100], Step [1300/4091], Loss: 402.3524\n",
      "Epoch [34/100], Step [1400/4091], Loss: 824.5355\n",
      "Epoch [34/100], Step [1500/4091], Loss: 713.4709\n",
      "Epoch [34/100], Step [1600/4091], Loss: 515.2224\n",
      "Epoch [34/100], Step [1700/4091], Loss: 792.3446\n",
      "Epoch [34/100], Step [1800/4091], Loss: 697.3528\n",
      "Epoch [34/100], Step [1900/4091], Loss: 703.8450\n",
      "Epoch [34/100], Step [2000/4091], Loss: 657.8284\n",
      "Epoch [34/100], Step [2100/4091], Loss: 712.7975\n",
      "Epoch [34/100], Step [2200/4091], Loss: 531.4537\n",
      "Epoch [34/100], Step [2300/4091], Loss: 565.4087\n",
      "Epoch [34/100], Step [2400/4091], Loss: 808.5616\n",
      "Epoch [34/100], Step [2500/4091], Loss: 992.6238\n",
      "Epoch [34/100], Step [2600/4091], Loss: 684.4412\n",
      "Epoch [34/100], Step [2700/4091], Loss: 594.8022\n",
      "Epoch [34/100], Step [2800/4091], Loss: 669.7310\n",
      "Epoch [34/100], Step [2900/4091], Loss: 659.7585\n",
      "Epoch [34/100], Step [3000/4091], Loss: 745.3516\n",
      "Epoch [34/100], Step [3100/4091], Loss: 635.2890\n",
      "Epoch [34/100], Step [3200/4091], Loss: 764.2589\n",
      "Epoch [34/100], Step [3300/4091], Loss: 549.3320\n",
      "Epoch [34/100], Step [3400/4091], Loss: 706.3520\n",
      "Epoch [34/100], Step [3500/4091], Loss: 678.7701\n",
      "Epoch [34/100], Step [3600/4091], Loss: 530.6865\n",
      "Epoch [34/100], Step [3700/4091], Loss: 555.6206\n",
      "Epoch [34/100], Step [3800/4091], Loss: 788.9951\n",
      "Epoch [34/100], Step [3900/4091], Loss: 706.9882\n",
      "Epoch [34/100], Step [4000/4091], Loss: 768.2308\n",
      "Epoch [35/100], Step [100/4091], Loss: 530.0239\n",
      "Epoch [35/100], Step [200/4091], Loss: 549.5721\n",
      "Epoch [35/100], Step [300/4091], Loss: 714.2098\n",
      "Epoch [35/100], Step [400/4091], Loss: 664.4652\n",
      "Epoch [35/100], Step [500/4091], Loss: 730.5289\n",
      "Epoch [35/100], Step [600/4091], Loss: 545.8458\n",
      "Epoch [35/100], Step [700/4091], Loss: 755.0612\n",
      "Epoch [35/100], Step [800/4091], Loss: 630.9066\n",
      "Epoch [35/100], Step [900/4091], Loss: 617.0071\n",
      "Epoch [35/100], Step [1000/4091], Loss: 630.7095\n",
      "Epoch [35/100], Step [1100/4091], Loss: 660.0206\n",
      "Epoch [35/100], Step [1200/4091], Loss: 710.2983\n",
      "Epoch [35/100], Step [1300/4091], Loss: 687.1294\n",
      "Epoch [35/100], Step [1400/4091], Loss: 723.0562\n",
      "Epoch [35/100], Step [1500/4091], Loss: 881.6384\n",
      "Epoch [35/100], Step [1600/4091], Loss: 687.7733\n",
      "Epoch [35/100], Step [1700/4091], Loss: 673.8575\n",
      "Epoch [35/100], Step [1800/4091], Loss: 650.7433\n",
      "Epoch [35/100], Step [1900/4091], Loss: 728.9630\n",
      "Epoch [35/100], Step [2000/4091], Loss: 803.6274\n",
      "Epoch [35/100], Step [2100/4091], Loss: 482.1366\n",
      "Epoch [35/100], Step [2200/4091], Loss: 634.0811\n",
      "Epoch [35/100], Step [2300/4091], Loss: 439.2082\n",
      "Epoch [35/100], Step [2400/4091], Loss: 780.4612\n",
      "Epoch [35/100], Step [2500/4091], Loss: 615.1509\n",
      "Epoch [35/100], Step [2600/4091], Loss: 739.6141\n",
      "Epoch [35/100], Step [2700/4091], Loss: 668.3324\n",
      "Epoch [35/100], Step [2800/4091], Loss: 817.1805\n",
      "Epoch [35/100], Step [2900/4091], Loss: 522.6454\n",
      "Epoch [35/100], Step [3000/4091], Loss: 804.8968\n",
      "Epoch [35/100], Step [3100/4091], Loss: 635.2720\n",
      "Epoch [35/100], Step [3200/4091], Loss: 750.7126\n",
      "Epoch [35/100], Step [3300/4091], Loss: 793.4510\n",
      "Epoch [35/100], Step [3400/4091], Loss: 792.1917\n",
      "Epoch [35/100], Step [3500/4091], Loss: 687.0627\n",
      "Epoch [35/100], Step [3600/4091], Loss: 679.2495\n",
      "Epoch [35/100], Step [3700/4091], Loss: 710.6300\n",
      "Epoch [35/100], Step [3800/4091], Loss: 537.1652\n",
      "Epoch [35/100], Step [3900/4091], Loss: 766.5345\n",
      "Epoch [35/100], Step [4000/4091], Loss: 806.4688\n",
      "Epoch [36/100], Step [100/4091], Loss: 364.8343\n",
      "Epoch [36/100], Step [200/4091], Loss: 855.1144\n",
      "Epoch [36/100], Step [300/4091], Loss: 684.4774\n",
      "Epoch [36/100], Step [400/4091], Loss: 605.9781\n",
      "Epoch [36/100], Step [500/4091], Loss: 681.8751\n",
      "Epoch [36/100], Step [600/4091], Loss: 653.8398\n",
      "Epoch [36/100], Step [700/4091], Loss: 568.6790\n",
      "Epoch [36/100], Step [800/4091], Loss: 708.3849\n",
      "Epoch [36/100], Step [900/4091], Loss: 589.4211\n",
      "Epoch [36/100], Step [1000/4091], Loss: 588.8316\n",
      "Epoch [36/100], Step [1100/4091], Loss: 547.8817\n",
      "Epoch [36/100], Step [1200/4091], Loss: 598.0185\n",
      "Epoch [36/100], Step [1300/4091], Loss: 678.6128\n",
      "Epoch [36/100], Step [1400/4091], Loss: 705.2289\n",
      "Epoch [36/100], Step [1500/4091], Loss: 554.4915\n",
      "Epoch [36/100], Step [1600/4091], Loss: 1055.8417\n",
      "Epoch [36/100], Step [1700/4091], Loss: 727.8492\n",
      "Epoch [36/100], Step [1800/4091], Loss: 605.6086\n",
      "Epoch [36/100], Step [1900/4091], Loss: 930.6317\n",
      "Epoch [36/100], Step [2000/4091], Loss: 712.6179\n",
      "Epoch [36/100], Step [2100/4091], Loss: 910.2614\n",
      "Epoch [36/100], Step [2200/4091], Loss: 691.7364\n",
      "Epoch [36/100], Step [2300/4091], Loss: 641.3835\n",
      "Epoch [36/100], Step [2400/4091], Loss: 893.7637\n",
      "Epoch [36/100], Step [2500/4091], Loss: 706.5595\n",
      "Epoch [36/100], Step [2600/4091], Loss: 681.2560\n",
      "Epoch [36/100], Step [2700/4091], Loss: 700.8554\n",
      "Epoch [36/100], Step [2800/4091], Loss: 704.2095\n",
      "Epoch [36/100], Step [2900/4091], Loss: 479.0435\n",
      "Epoch [36/100], Step [3000/4091], Loss: 601.3756\n",
      "Epoch [36/100], Step [3100/4091], Loss: 802.2955\n",
      "Epoch [36/100], Step [3200/4091], Loss: 538.5587\n",
      "Epoch [36/100], Step [3300/4091], Loss: 603.7338\n",
      "Epoch [36/100], Step [3400/4091], Loss: 789.4428\n",
      "Epoch [36/100], Step [3500/4091], Loss: 596.5527\n",
      "Epoch [36/100], Step [3600/4091], Loss: 690.3369\n",
      "Epoch [36/100], Step [3700/4091], Loss: 625.5704\n",
      "Epoch [36/100], Step [3800/4091], Loss: 939.8985\n",
      "Epoch [36/100], Step [3900/4091], Loss: 966.4041\n",
      "Epoch [36/100], Step [4000/4091], Loss: 1016.0873\n",
      "Epoch [37/100], Step [100/4091], Loss: 602.7427\n",
      "Epoch [37/100], Step [200/4091], Loss: 545.4891\n",
      "Epoch [37/100], Step [300/4091], Loss: 812.7478\n",
      "Epoch [37/100], Step [400/4091], Loss: 630.7039\n",
      "Epoch [37/100], Step [500/4091], Loss: 902.0594\n",
      "Epoch [37/100], Step [600/4091], Loss: 582.1545\n",
      "Epoch [37/100], Step [700/4091], Loss: 605.4659\n",
      "Epoch [37/100], Step [800/4091], Loss: 800.3817\n",
      "Epoch [37/100], Step [900/4091], Loss: 949.2905\n",
      "Epoch [37/100], Step [1000/4091], Loss: 493.9758\n",
      "Epoch [37/100], Step [1100/4091], Loss: 822.1678\n",
      "Epoch [37/100], Step [1200/4091], Loss: 685.8647\n",
      "Epoch [37/100], Step [1300/4091], Loss: 680.8460\n",
      "Epoch [37/100], Step [1400/4091], Loss: 594.9250\n",
      "Epoch [37/100], Step [1500/4091], Loss: 539.5559\n",
      "Epoch [37/100], Step [1600/4091], Loss: 592.7275\n",
      "Epoch [37/100], Step [1700/4091], Loss: 416.8361\n",
      "Epoch [37/100], Step [1800/4091], Loss: 526.1105\n",
      "Epoch [37/100], Step [1900/4091], Loss: 854.9021\n",
      "Epoch [37/100], Step [2000/4091], Loss: 554.5710\n",
      "Epoch [37/100], Step [2100/4091], Loss: 717.4413\n",
      "Epoch [37/100], Step [2200/4091], Loss: 632.5641\n",
      "Epoch [37/100], Step [2300/4091], Loss: 741.0485\n",
      "Epoch [37/100], Step [2400/4091], Loss: 847.9442\n",
      "Epoch [37/100], Step [2500/4091], Loss: 734.1434\n",
      "Epoch [37/100], Step [2600/4091], Loss: 563.7657\n",
      "Epoch [37/100], Step [2700/4091], Loss: 496.5684\n",
      "Epoch [37/100], Step [2800/4091], Loss: 496.3514\n",
      "Epoch [37/100], Step [2900/4091], Loss: 611.9048\n",
      "Epoch [37/100], Step [3000/4091], Loss: 575.3159\n",
      "Epoch [37/100], Step [3100/4091], Loss: 644.9114\n",
      "Epoch [37/100], Step [3200/4091], Loss: 628.0757\n",
      "Epoch [37/100], Step [3300/4091], Loss: 693.9955\n",
      "Epoch [37/100], Step [3400/4091], Loss: 571.9328\n",
      "Epoch [37/100], Step [3500/4091], Loss: 736.7825\n",
      "Epoch [37/100], Step [3600/4091], Loss: 592.2754\n",
      "Epoch [37/100], Step [3700/4091], Loss: 484.8863\n",
      "Epoch [37/100], Step [3800/4091], Loss: 596.8835\n",
      "Epoch [37/100], Step [3900/4091], Loss: 593.3584\n",
      "Epoch [37/100], Step [4000/4091], Loss: 544.9665\n",
      "Epoch [38/100], Step [100/4091], Loss: 625.5430\n",
      "Epoch [38/100], Step [200/4091], Loss: 807.8416\n",
      "Epoch [38/100], Step [300/4091], Loss: 844.4977\n",
      "Epoch [38/100], Step [400/4091], Loss: 747.2510\n",
      "Epoch [38/100], Step [500/4091], Loss: 777.9719\n",
      "Epoch [38/100], Step [600/4091], Loss: 637.2785\n",
      "Epoch [38/100], Step [700/4091], Loss: 595.3041\n",
      "Epoch [38/100], Step [800/4091], Loss: 568.9256\n",
      "Epoch [38/100], Step [900/4091], Loss: 771.8575\n",
      "Epoch [38/100], Step [1000/4091], Loss: 791.4639\n",
      "Epoch [38/100], Step [1100/4091], Loss: 665.5950\n",
      "Epoch [38/100], Step [1200/4091], Loss: 589.0766\n",
      "Epoch [38/100], Step [1300/4091], Loss: 646.4515\n",
      "Epoch [38/100], Step [1400/4091], Loss: 501.3756\n",
      "Epoch [38/100], Step [1500/4091], Loss: 539.4091\n",
      "Epoch [38/100], Step [1600/4091], Loss: 815.2986\n",
      "Epoch [38/100], Step [1700/4091], Loss: 834.7068\n",
      "Epoch [38/100], Step [1800/4091], Loss: 543.5992\n",
      "Epoch [38/100], Step [1900/4091], Loss: 470.1251\n",
      "Epoch [38/100], Step [2000/4091], Loss: 662.7238\n",
      "Epoch [38/100], Step [2100/4091], Loss: 694.3955\n",
      "Epoch [38/100], Step [2200/4091], Loss: 611.3680\n",
      "Epoch [38/100], Step [2300/4091], Loss: 608.9144\n",
      "Epoch [38/100], Step [2400/4091], Loss: 475.4097\n",
      "Epoch [38/100], Step [2500/4091], Loss: 610.3695\n",
      "Epoch [38/100], Step [2600/4091], Loss: 647.0955\n",
      "Epoch [38/100], Step [2700/4091], Loss: 753.0725\n",
      "Epoch [38/100], Step [2800/4091], Loss: 889.5853\n",
      "Epoch [38/100], Step [2900/4091], Loss: 575.1271\n",
      "Epoch [38/100], Step [3000/4091], Loss: 568.5104\n",
      "Epoch [38/100], Step [3100/4091], Loss: 512.7698\n",
      "Epoch [38/100], Step [3200/4091], Loss: 681.9922\n",
      "Epoch [38/100], Step [3300/4091], Loss: 649.8516\n",
      "Epoch [38/100], Step [3400/4091], Loss: 875.2182\n",
      "Epoch [38/100], Step [3500/4091], Loss: 544.0380\n",
      "Epoch [38/100], Step [3600/4091], Loss: 736.3066\n",
      "Epoch [38/100], Step [3700/4091], Loss: 645.7421\n",
      "Epoch [38/100], Step [3800/4091], Loss: 523.1725\n",
      "Epoch [38/100], Step [3900/4091], Loss: 568.4884\n",
      "Epoch [38/100], Step [4000/4091], Loss: 663.1025\n",
      "Epoch [39/100], Step [100/4091], Loss: 714.3550\n",
      "Epoch [39/100], Step [200/4091], Loss: 691.0918\n",
      "Epoch [39/100], Step [300/4091], Loss: 642.6476\n",
      "Epoch [39/100], Step [400/4091], Loss: 736.2150\n",
      "Epoch [39/100], Step [500/4091], Loss: 564.8619\n",
      "Epoch [39/100], Step [600/4091], Loss: 461.0142\n",
      "Epoch [39/100], Step [700/4091], Loss: 977.0789\n",
      "Epoch [39/100], Step [800/4091], Loss: 594.3640\n",
      "Epoch [39/100], Step [900/4091], Loss: 641.3525\n",
      "Epoch [39/100], Step [1000/4091], Loss: 517.4188\n",
      "Epoch [39/100], Step [1100/4091], Loss: 676.5701\n",
      "Epoch [39/100], Step [1200/4091], Loss: 518.1653\n",
      "Epoch [39/100], Step [1300/4091], Loss: 563.7321\n",
      "Epoch [39/100], Step [1400/4091], Loss: 501.9117\n",
      "Epoch [39/100], Step [1500/4091], Loss: 548.8025\n",
      "Epoch [39/100], Step [1600/4091], Loss: 720.1483\n",
      "Epoch [39/100], Step [1700/4091], Loss: 818.7602\n",
      "Epoch [39/100], Step [1800/4091], Loss: 591.7380\n",
      "Epoch [39/100], Step [1900/4091], Loss: 428.9134\n",
      "Epoch [39/100], Step [2000/4091], Loss: 654.1202\n",
      "Epoch [39/100], Step [2100/4091], Loss: 549.6175\n",
      "Epoch [39/100], Step [2200/4091], Loss: 562.2937\n",
      "Epoch [39/100], Step [2300/4091], Loss: 613.9011\n",
      "Epoch [39/100], Step [2400/4091], Loss: 629.2506\n",
      "Epoch [39/100], Step [2500/4091], Loss: 739.9459\n",
      "Epoch [39/100], Step [2600/4091], Loss: 575.6416\n",
      "Epoch [39/100], Step [2700/4091], Loss: 573.5734\n",
      "Epoch [39/100], Step [2800/4091], Loss: 490.4784\n",
      "Epoch [39/100], Step [2900/4091], Loss: 713.4888\n",
      "Epoch [39/100], Step [3000/4091], Loss: 483.4642\n",
      "Epoch [39/100], Step [3100/4091], Loss: 808.7878\n",
      "Epoch [39/100], Step [3200/4091], Loss: 612.4990\n",
      "Epoch [39/100], Step [3300/4091], Loss: 558.7863\n",
      "Epoch [39/100], Step [3400/4091], Loss: 689.9097\n",
      "Epoch [39/100], Step [3500/4091], Loss: 701.0101\n",
      "Epoch [39/100], Step [3600/4091], Loss: 593.0496\n",
      "Epoch [39/100], Step [3700/4091], Loss: 629.2030\n",
      "Epoch [39/100], Step [3800/4091], Loss: 536.8048\n",
      "Epoch [39/100], Step [3900/4091], Loss: 533.5818\n",
      "Epoch [39/100], Step [4000/4091], Loss: 500.7034\n",
      "Epoch [40/100], Step [100/4091], Loss: 826.9673\n",
      "Epoch [40/100], Step [200/4091], Loss: 743.0134\n",
      "Epoch [40/100], Step [300/4091], Loss: 517.2028\n",
      "Epoch [40/100], Step [400/4091], Loss: 526.1490\n",
      "Epoch [40/100], Step [500/4091], Loss: 449.8212\n",
      "Epoch [40/100], Step [600/4091], Loss: 656.0422\n",
      "Epoch [40/100], Step [700/4091], Loss: 798.6096\n",
      "Epoch [40/100], Step [800/4091], Loss: 608.4677\n",
      "Epoch [40/100], Step [900/4091], Loss: 600.2045\n",
      "Epoch [40/100], Step [1000/4091], Loss: 775.9870\n",
      "Epoch [40/100], Step [1100/4091], Loss: 708.0651\n",
      "Epoch [40/100], Step [1200/4091], Loss: 671.6334\n",
      "Epoch [40/100], Step [1300/4091], Loss: 487.2283\n",
      "Epoch [40/100], Step [1400/4091], Loss: 749.4028\n",
      "Epoch [40/100], Step [1500/4091], Loss: 710.1031\n",
      "Epoch [40/100], Step [1600/4091], Loss: 724.2393\n",
      "Epoch [40/100], Step [1700/4091], Loss: 653.4473\n",
      "Epoch [40/100], Step [1800/4091], Loss: 726.1643\n",
      "Epoch [40/100], Step [1900/4091], Loss: 595.5209\n",
      "Epoch [40/100], Step [2000/4091], Loss: 809.5064\n",
      "Epoch [40/100], Step [2100/4091], Loss: 688.9679\n",
      "Epoch [40/100], Step [2200/4091], Loss: 579.2598\n",
      "Epoch [40/100], Step [2300/4091], Loss: 607.8115\n",
      "Epoch [40/100], Step [2400/4091], Loss: 991.9166\n",
      "Epoch [40/100], Step [2500/4091], Loss: 530.2730\n",
      "Epoch [40/100], Step [2600/4091], Loss: 664.5726\n",
      "Epoch [40/100], Step [2700/4091], Loss: 782.4061\n",
      "Epoch [40/100], Step [2800/4091], Loss: 570.4843\n",
      "Epoch [40/100], Step [2900/4091], Loss: 660.9808\n",
      "Epoch [40/100], Step [3000/4091], Loss: 737.3419\n",
      "Epoch [40/100], Step [3100/4091], Loss: 804.5013\n",
      "Epoch [40/100], Step [3200/4091], Loss: 467.9822\n",
      "Epoch [40/100], Step [3300/4091], Loss: 528.2620\n",
      "Epoch [40/100], Step [3400/4091], Loss: 750.5161\n",
      "Epoch [40/100], Step [3500/4091], Loss: 587.5129\n",
      "Epoch [40/100], Step [3600/4091], Loss: 646.6257\n",
      "Epoch [40/100], Step [3700/4091], Loss: 885.6240\n",
      "Epoch [40/100], Step [3800/4091], Loss: 552.7835\n",
      "Epoch [40/100], Step [3900/4091], Loss: 599.1031\n",
      "Epoch [40/100], Step [4000/4091], Loss: 679.7425\n",
      "Epoch [41/100], Step [100/4091], Loss: 766.6925\n",
      "Epoch [41/100], Step [200/4091], Loss: 535.8807\n",
      "Epoch [41/100], Step [300/4091], Loss: 726.1027\n",
      "Epoch [41/100], Step [400/4091], Loss: 683.0299\n",
      "Epoch [41/100], Step [500/4091], Loss: 524.2667\n",
      "Epoch [41/100], Step [600/4091], Loss: 685.9985\n",
      "Epoch [41/100], Step [700/4091], Loss: 885.7744\n",
      "Epoch [41/100], Step [800/4091], Loss: 606.7374\n",
      "Epoch [41/100], Step [900/4091], Loss: 534.3549\n",
      "Epoch [41/100], Step [1000/4091], Loss: 518.2292\n",
      "Epoch [41/100], Step [1100/4091], Loss: 541.3134\n",
      "Epoch [41/100], Step [1200/4091], Loss: 846.6243\n",
      "Epoch [41/100], Step [1300/4091], Loss: 687.4524\n",
      "Epoch [41/100], Step [1400/4091], Loss: 706.3517\n",
      "Epoch [41/100], Step [1500/4091], Loss: 605.9062\n",
      "Epoch [41/100], Step [1600/4091], Loss: 609.8485\n",
      "Epoch [41/100], Step [1700/4091], Loss: 519.4743\n",
      "Epoch [41/100], Step [1800/4091], Loss: 604.5441\n",
      "Epoch [41/100], Step [1900/4091], Loss: 1003.4979\n",
      "Epoch [41/100], Step [2000/4091], Loss: 781.2541\n",
      "Epoch [41/100], Step [2100/4091], Loss: 709.4318\n",
      "Epoch [41/100], Step [2200/4091], Loss: 799.8291\n",
      "Epoch [41/100], Step [2300/4091], Loss: 714.2943\n",
      "Epoch [41/100], Step [2400/4091], Loss: 734.8582\n",
      "Epoch [41/100], Step [2500/4091], Loss: 655.8832\n",
      "Epoch [41/100], Step [2600/4091], Loss: 673.9641\n",
      "Epoch [41/100], Step [2700/4091], Loss: 627.5132\n",
      "Epoch [41/100], Step [2800/4091], Loss: 601.4229\n",
      "Epoch [41/100], Step [2900/4091], Loss: 766.3571\n",
      "Epoch [41/100], Step [3000/4091], Loss: 842.7331\n",
      "Epoch [41/100], Step [3100/4091], Loss: 587.1129\n",
      "Epoch [41/100], Step [3200/4091], Loss: 612.7067\n",
      "Epoch [41/100], Step [3300/4091], Loss: 744.0803\n",
      "Epoch [41/100], Step [3400/4091], Loss: 640.7010\n",
      "Epoch [41/100], Step [3500/4091], Loss: 689.0225\n",
      "Epoch [41/100], Step [3600/4091], Loss: 629.7556\n",
      "Epoch [41/100], Step [3700/4091], Loss: 824.7905\n",
      "Epoch [41/100], Step [3800/4091], Loss: 553.8131\n",
      "Epoch [41/100], Step [3900/4091], Loss: 665.1883\n",
      "Epoch [41/100], Step [4000/4091], Loss: 606.3856\n",
      "Epoch [42/100], Step [100/4091], Loss: 613.9220\n",
      "Epoch [42/100], Step [200/4091], Loss: 534.9957\n",
      "Epoch [42/100], Step [300/4091], Loss: 707.7283\n",
      "Epoch [42/100], Step [400/4091], Loss: 717.4348\n",
      "Epoch [42/100], Step [500/4091], Loss: 617.9344\n",
      "Epoch [42/100], Step [600/4091], Loss: 507.5439\n",
      "Epoch [42/100], Step [700/4091], Loss: 589.5756\n",
      "Epoch [42/100], Step [800/4091], Loss: 689.8228\n",
      "Epoch [42/100], Step [900/4091], Loss: 674.1317\n",
      "Epoch [42/100], Step [1000/4091], Loss: 643.3166\n",
      "Epoch [42/100], Step [1100/4091], Loss: 694.6284\n",
      "Epoch [42/100], Step [1200/4091], Loss: 443.7926\n",
      "Epoch [42/100], Step [1300/4091], Loss: 659.2567\n",
      "Epoch [42/100], Step [1400/4091], Loss: 679.1594\n",
      "Epoch [42/100], Step [1500/4091], Loss: 717.9582\n",
      "Epoch [42/100], Step [1600/4091], Loss: 429.0602\n",
      "Epoch [42/100], Step [1700/4091], Loss: 845.7227\n",
      "Epoch [42/100], Step [1800/4091], Loss: 526.3022\n",
      "Epoch [42/100], Step [1900/4091], Loss: 632.3709\n",
      "Epoch [42/100], Step [2000/4091], Loss: 564.6531\n",
      "Epoch [42/100], Step [2100/4091], Loss: 506.2998\n",
      "Epoch [42/100], Step [2200/4091], Loss: 774.2004\n",
      "Epoch [42/100], Step [2300/4091], Loss: 603.6344\n",
      "Epoch [42/100], Step [2400/4091], Loss: 767.4167\n",
      "Epoch [42/100], Step [2500/4091], Loss: 624.2826\n",
      "Epoch [42/100], Step [2600/4091], Loss: 558.9073\n",
      "Epoch [42/100], Step [2700/4091], Loss: 565.3261\n",
      "Epoch [42/100], Step [2800/4091], Loss: 719.5219\n",
      "Epoch [42/100], Step [2900/4091], Loss: 557.8341\n",
      "Epoch [42/100], Step [3000/4091], Loss: 682.7630\n",
      "Epoch [42/100], Step [3100/4091], Loss: 468.1017\n",
      "Epoch [42/100], Step [3200/4091], Loss: 859.8372\n",
      "Epoch [42/100], Step [3300/4091], Loss: 733.0602\n",
      "Epoch [42/100], Step [3400/4091], Loss: 938.1022\n",
      "Epoch [42/100], Step [3500/4091], Loss: 673.3254\n",
      "Epoch [42/100], Step [3600/4091], Loss: 792.7422\n",
      "Epoch [42/100], Step [3700/4091], Loss: 624.7076\n",
      "Epoch [42/100], Step [3800/4091], Loss: 746.1412\n",
      "Epoch [42/100], Step [3900/4091], Loss: 681.1824\n",
      "Epoch [42/100], Step [4000/4091], Loss: 303.3720\n",
      "Epoch [43/100], Step [100/4091], Loss: 576.8790\n",
      "Epoch [43/100], Step [200/4091], Loss: 732.8157\n",
      "Epoch [43/100], Step [300/4091], Loss: 669.5765\n",
      "Epoch [43/100], Step [400/4091], Loss: 812.9172\n",
      "Epoch [43/100], Step [500/4091], Loss: 718.3665\n",
      "Epoch [43/100], Step [600/4091], Loss: 663.4352\n",
      "Epoch [43/100], Step [700/4091], Loss: 779.7178\n",
      "Epoch [43/100], Step [800/4091], Loss: 547.1700\n",
      "Epoch [43/100], Step [900/4091], Loss: 715.7455\n",
      "Epoch [43/100], Step [1000/4091], Loss: 667.4651\n",
      "Epoch [43/100], Step [1100/4091], Loss: 654.1068\n",
      "Epoch [43/100], Step [1200/4091], Loss: 665.7759\n",
      "Epoch [43/100], Step [1300/4091], Loss: 795.3214\n",
      "Epoch [43/100], Step [1400/4091], Loss: 600.0179\n",
      "Epoch [43/100], Step [1500/4091], Loss: 849.2538\n",
      "Epoch [43/100], Step [1600/4091], Loss: 776.5530\n",
      "Epoch [43/100], Step [1700/4091], Loss: 575.5900\n",
      "Epoch [43/100], Step [1800/4091], Loss: 686.0289\n",
      "Epoch [43/100], Step [1900/4091], Loss: 528.2522\n",
      "Epoch [43/100], Step [2000/4091], Loss: 657.6609\n",
      "Epoch [43/100], Step [2100/4091], Loss: 659.2829\n",
      "Epoch [43/100], Step [2200/4091], Loss: 679.0152\n",
      "Epoch [43/100], Step [2300/4091], Loss: 645.6165\n",
      "Epoch [43/100], Step [2400/4091], Loss: 438.5146\n",
      "Epoch [43/100], Step [2500/4091], Loss: 801.8995\n",
      "Epoch [43/100], Step [2600/4091], Loss: 628.6287\n",
      "Epoch [43/100], Step [2700/4091], Loss: 725.3564\n",
      "Epoch [43/100], Step [2800/4091], Loss: 547.1154\n",
      "Epoch [43/100], Step [2900/4091], Loss: 635.2437\n",
      "Epoch [43/100], Step [3000/4091], Loss: 517.8274\n",
      "Epoch [43/100], Step [3100/4091], Loss: 569.1252\n",
      "Epoch [43/100], Step [3200/4091], Loss: 608.1559\n",
      "Epoch [43/100], Step [3300/4091], Loss: 650.9176\n",
      "Epoch [43/100], Step [3400/4091], Loss: 713.6796\n",
      "Epoch [43/100], Step [3500/4091], Loss: 603.7028\n",
      "Epoch [43/100], Step [3600/4091], Loss: 558.4975\n",
      "Epoch [43/100], Step [3700/4091], Loss: 498.2379\n",
      "Epoch [43/100], Step [3800/4091], Loss: 738.6770\n",
      "Epoch [43/100], Step [3900/4091], Loss: 740.4617\n",
      "Epoch [43/100], Step [4000/4091], Loss: 762.5763\n",
      "Epoch [44/100], Step [100/4091], Loss: 603.5045\n",
      "Epoch [44/100], Step [200/4091], Loss: 497.0016\n",
      "Epoch [44/100], Step [300/4091], Loss: 651.6280\n",
      "Epoch [44/100], Step [400/4091], Loss: 602.6288\n",
      "Epoch [44/100], Step [500/4091], Loss: 440.8207\n",
      "Epoch [44/100], Step [600/4091], Loss: 697.0714\n",
      "Epoch [44/100], Step [700/4091], Loss: 660.9061\n",
      "Epoch [44/100], Step [800/4091], Loss: 545.5928\n",
      "Epoch [44/100], Step [900/4091], Loss: 728.9324\n",
      "Epoch [44/100], Step [1000/4091], Loss: 672.8845\n",
      "Epoch [44/100], Step [1100/4091], Loss: 483.8508\n",
      "Epoch [44/100], Step [1200/4091], Loss: 922.8279\n",
      "Epoch [44/100], Step [1300/4091], Loss: 546.6895\n",
      "Epoch [44/100], Step [1400/4091], Loss: 539.6483\n",
      "Epoch [44/100], Step [1500/4091], Loss: 410.3582\n",
      "Epoch [44/100], Step [1600/4091], Loss: 479.4305\n",
      "Epoch [44/100], Step [1700/4091], Loss: 720.9979\n",
      "Epoch [44/100], Step [1800/4091], Loss: 529.4031\n",
      "Epoch [44/100], Step [1900/4091], Loss: 709.8362\n",
      "Epoch [44/100], Step [2000/4091], Loss: 757.6046\n",
      "Epoch [44/100], Step [2100/4091], Loss: 575.9404\n",
      "Epoch [44/100], Step [2200/4091], Loss: 641.4329\n",
      "Epoch [44/100], Step [2300/4091], Loss: 621.6125\n",
      "Epoch [44/100], Step [2400/4091], Loss: 579.3646\n",
      "Epoch [44/100], Step [2500/4091], Loss: 625.6290\n",
      "Epoch [44/100], Step [2600/4091], Loss: 602.7835\n",
      "Epoch [44/100], Step [2700/4091], Loss: 591.7177\n",
      "Epoch [44/100], Step [2800/4091], Loss: 633.9575\n",
      "Epoch [44/100], Step [2900/4091], Loss: 782.4497\n",
      "Epoch [44/100], Step [3000/4091], Loss: 630.9745\n",
      "Epoch [44/100], Step [3100/4091], Loss: 449.9387\n",
      "Epoch [44/100], Step [3200/4091], Loss: 675.0782\n",
      "Epoch [44/100], Step [3300/4091], Loss: 532.3348\n",
      "Epoch [44/100], Step [3400/4091], Loss: 502.2179\n",
      "Epoch [44/100], Step [3500/4091], Loss: 543.8174\n",
      "Epoch [44/100], Step [3600/4091], Loss: 926.7483\n",
      "Epoch [44/100], Step [3700/4091], Loss: 759.2026\n",
      "Epoch [44/100], Step [3800/4091], Loss: 646.6504\n",
      "Epoch [44/100], Step [3900/4091], Loss: 582.2372\n",
      "Epoch [44/100], Step [4000/4091], Loss: 597.5543\n",
      "Epoch [45/100], Step [100/4091], Loss: 609.0275\n",
      "Epoch [45/100], Step [200/4091], Loss: 797.5209\n",
      "Epoch [45/100], Step [300/4091], Loss: 607.0527\n",
      "Epoch [45/100], Step [400/4091], Loss: 479.3498\n",
      "Epoch [45/100], Step [500/4091], Loss: 645.7513\n",
      "Epoch [45/100], Step [600/4091], Loss: 723.0560\n",
      "Epoch [45/100], Step [700/4091], Loss: 744.9777\n",
      "Epoch [45/100], Step [800/4091], Loss: 599.3688\n",
      "Epoch [45/100], Step [900/4091], Loss: 612.9106\n",
      "Epoch [45/100], Step [1000/4091], Loss: 699.5212\n",
      "Epoch [45/100], Step [1100/4091], Loss: 757.9526\n",
      "Epoch [45/100], Step [1200/4091], Loss: 568.9579\n",
      "Epoch [45/100], Step [1300/4091], Loss: 647.1032\n",
      "Epoch [45/100], Step [1400/4091], Loss: 576.3641\n",
      "Epoch [45/100], Step [1500/4091], Loss: 699.2159\n",
      "Epoch [45/100], Step [1600/4091], Loss: 782.5712\n",
      "Epoch [45/100], Step [1700/4091], Loss: 848.9818\n",
      "Epoch [45/100], Step [1800/4091], Loss: 483.3084\n",
      "Epoch [45/100], Step [1900/4091], Loss: 666.0248\n",
      "Epoch [45/100], Step [2000/4091], Loss: 623.3262\n",
      "Epoch [45/100], Step [2100/4091], Loss: 538.6303\n",
      "Epoch [45/100], Step [2200/4091], Loss: 981.4884\n",
      "Epoch [45/100], Step [2300/4091], Loss: 659.8093\n",
      "Epoch [45/100], Step [2400/4091], Loss: 641.4711\n",
      "Epoch [45/100], Step [2500/4091], Loss: 691.1812\n",
      "Epoch [45/100], Step [2600/4091], Loss: 632.2465\n",
      "Epoch [45/100], Step [2700/4091], Loss: 517.3087\n",
      "Epoch [45/100], Step [2800/4091], Loss: 670.1799\n",
      "Epoch [45/100], Step [2900/4091], Loss: 649.3572\n",
      "Epoch [45/100], Step [3000/4091], Loss: 656.2491\n",
      "Epoch [45/100], Step [3100/4091], Loss: 526.0070\n",
      "Epoch [45/100], Step [3200/4091], Loss: 632.3662\n",
      "Epoch [45/100], Step [3300/4091], Loss: 724.9369\n",
      "Epoch [45/100], Step [3400/4091], Loss: 666.1742\n",
      "Epoch [45/100], Step [3500/4091], Loss: 655.7952\n",
      "Epoch [45/100], Step [3600/4091], Loss: 770.4011\n",
      "Epoch [45/100], Step [3700/4091], Loss: 644.3781\n",
      "Epoch [45/100], Step [3800/4091], Loss: 587.9709\n",
      "Epoch [45/100], Step [3900/4091], Loss: 676.8972\n",
      "Epoch [45/100], Step [4000/4091], Loss: 735.6918\n",
      "Epoch [46/100], Step [100/4091], Loss: 536.7167\n",
      "Epoch [46/100], Step [200/4091], Loss: 761.7523\n",
      "Epoch [46/100], Step [300/4091], Loss: 639.7731\n",
      "Epoch [46/100], Step [400/4091], Loss: 901.1774\n",
      "Epoch [46/100], Step [500/4091], Loss: 459.8526\n",
      "Epoch [46/100], Step [600/4091], Loss: 749.6812\n",
      "Epoch [46/100], Step [700/4091], Loss: 557.6876\n",
      "Epoch [46/100], Step [800/4091], Loss: 670.3147\n",
      "Epoch [46/100], Step [900/4091], Loss: 650.9356\n",
      "Epoch [46/100], Step [1000/4091], Loss: 801.9193\n",
      "Epoch [46/100], Step [1100/4091], Loss: 594.2797\n",
      "Epoch [46/100], Step [1200/4091], Loss: 593.7332\n",
      "Epoch [46/100], Step [1300/4091], Loss: 546.5209\n",
      "Epoch [46/100], Step [1400/4091], Loss: 971.3893\n",
      "Epoch [46/100], Step [1500/4091], Loss: 828.3585\n",
      "Epoch [46/100], Step [1600/4091], Loss: 653.8302\n",
      "Epoch [46/100], Step [1700/4091], Loss: 648.1409\n",
      "Epoch [46/100], Step [1800/4091], Loss: 584.7719\n",
      "Epoch [46/100], Step [1900/4091], Loss: 630.2485\n",
      "Epoch [46/100], Step [2000/4091], Loss: 977.2161\n",
      "Epoch [46/100], Step [2100/4091], Loss: 664.5801\n",
      "Epoch [46/100], Step [2200/4091], Loss: 642.6224\n",
      "Epoch [46/100], Step [2300/4091], Loss: 575.2872\n",
      "Epoch [46/100], Step [2400/4091], Loss: 425.8661\n",
      "Epoch [46/100], Step [2500/4091], Loss: 633.4316\n",
      "Epoch [46/100], Step [2600/4091], Loss: 524.2276\n",
      "Epoch [46/100], Step [2700/4091], Loss: 606.3873\n",
      "Epoch [46/100], Step [2800/4091], Loss: 765.3641\n",
      "Epoch [46/100], Step [2900/4091], Loss: 868.1808\n",
      "Epoch [46/100], Step [3000/4091], Loss: 1038.5305\n",
      "Epoch [46/100], Step [3100/4091], Loss: 698.5976\n",
      "Epoch [46/100], Step [3200/4091], Loss: 721.7166\n",
      "Epoch [46/100], Step [3300/4091], Loss: 804.0549\n",
      "Epoch [46/100], Step [3400/4091], Loss: 763.3679\n",
      "Epoch [46/100], Step [3500/4091], Loss: 629.5422\n",
      "Epoch [46/100], Step [3600/4091], Loss: 496.0746\n",
      "Epoch [46/100], Step [3700/4091], Loss: 488.6975\n",
      "Epoch [46/100], Step [3800/4091], Loss: 601.1237\n",
      "Epoch [46/100], Step [3900/4091], Loss: 667.1848\n",
      "Epoch [46/100], Step [4000/4091], Loss: 687.2009\n",
      "Epoch [47/100], Step [100/4091], Loss: 605.8938\n",
      "Epoch [47/100], Step [200/4091], Loss: 800.7979\n",
      "Epoch [47/100], Step [300/4091], Loss: 658.1445\n",
      "Epoch [47/100], Step [400/4091], Loss: 598.3193\n",
      "Epoch [47/100], Step [500/4091], Loss: 544.1153\n",
      "Epoch [47/100], Step [600/4091], Loss: 725.2788\n",
      "Epoch [47/100], Step [700/4091], Loss: 438.4875\n",
      "Epoch [47/100], Step [800/4091], Loss: 755.7145\n",
      "Epoch [47/100], Step [900/4091], Loss: 551.0792\n",
      "Epoch [47/100], Step [1000/4091], Loss: 683.4169\n",
      "Epoch [47/100], Step [1100/4091], Loss: 573.7245\n",
      "Epoch [47/100], Step [1200/4091], Loss: 583.7661\n",
      "Epoch [47/100], Step [1300/4091], Loss: 605.3418\n",
      "Epoch [47/100], Step [1400/4091], Loss: 654.1611\n",
      "Epoch [47/100], Step [1500/4091], Loss: 947.0701\n",
      "Epoch [47/100], Step [1600/4091], Loss: 512.9109\n",
      "Epoch [47/100], Step [1700/4091], Loss: 828.1342\n",
      "Epoch [47/100], Step [1800/4091], Loss: 517.0391\n",
      "Epoch [47/100], Step [1900/4091], Loss: 741.3956\n",
      "Epoch [47/100], Step [2000/4091], Loss: 870.4396\n",
      "Epoch [47/100], Step [2100/4091], Loss: 695.0039\n",
      "Epoch [47/100], Step [2200/4091], Loss: 618.8497\n",
      "Epoch [47/100], Step [2300/4091], Loss: 970.5355\n",
      "Epoch [47/100], Step [2400/4091], Loss: 786.7458\n",
      "Epoch [47/100], Step [2500/4091], Loss: 520.1385\n",
      "Epoch [47/100], Step [2600/4091], Loss: 648.2145\n",
      "Epoch [47/100], Step [2700/4091], Loss: 612.8672\n",
      "Epoch [47/100], Step [2800/4091], Loss: 742.9672\n",
      "Epoch [47/100], Step [2900/4091], Loss: 762.8672\n",
      "Epoch [47/100], Step [3000/4091], Loss: 713.4448\n",
      "Epoch [47/100], Step [3100/4091], Loss: 759.5767\n",
      "Epoch [47/100], Step [3200/4091], Loss: 791.3967\n",
      "Epoch [47/100], Step [3300/4091], Loss: 540.6315\n",
      "Epoch [47/100], Step [3400/4091], Loss: 794.2753\n",
      "Epoch [47/100], Step [3500/4091], Loss: 699.4583\n",
      "Epoch [47/100], Step [3600/4091], Loss: 629.0248\n",
      "Epoch [47/100], Step [3700/4091], Loss: 627.2029\n",
      "Epoch [47/100], Step [3800/4091], Loss: 643.3235\n",
      "Epoch [47/100], Step [3900/4091], Loss: 692.7873\n",
      "Epoch [47/100], Step [4000/4091], Loss: 526.3577\n",
      "Epoch [48/100], Step [100/4091], Loss: 697.0914\n",
      "Epoch [48/100], Step [200/4091], Loss: 654.1967\n",
      "Epoch [48/100], Step [300/4091], Loss: 547.9065\n",
      "Epoch [48/100], Step [400/4091], Loss: 742.4373\n",
      "Epoch [48/100], Step [500/4091], Loss: 833.8488\n",
      "Epoch [48/100], Step [600/4091], Loss: 446.9939\n",
      "Epoch [48/100], Step [700/4091], Loss: 582.7286\n",
      "Epoch [48/100], Step [800/4091], Loss: 721.3821\n",
      "Epoch [48/100], Step [900/4091], Loss: 648.3930\n",
      "Epoch [48/100], Step [1000/4091], Loss: 561.9434\n",
      "Epoch [48/100], Step [1100/4091], Loss: 873.7692\n",
      "Epoch [48/100], Step [1200/4091], Loss: 876.1002\n",
      "Epoch [48/100], Step [1300/4091], Loss: 597.1581\n",
      "Epoch [48/100], Step [1400/4091], Loss: 665.2181\n",
      "Epoch [48/100], Step [1500/4091], Loss: 663.3696\n",
      "Epoch [48/100], Step [1600/4091], Loss: 715.0716\n",
      "Epoch [48/100], Step [1700/4091], Loss: 692.6730\n",
      "Epoch [48/100], Step [1800/4091], Loss: 458.3544\n",
      "Epoch [48/100], Step [1900/4091], Loss: 643.1905\n",
      "Epoch [48/100], Step [2000/4091], Loss: 840.8258\n",
      "Epoch [48/100], Step [2100/4091], Loss: 873.0773\n",
      "Epoch [48/100], Step [2200/4091], Loss: 559.6190\n",
      "Epoch [48/100], Step [2300/4091], Loss: 734.3811\n",
      "Epoch [48/100], Step [2400/4091], Loss: 502.2900\n",
      "Epoch [48/100], Step [2500/4091], Loss: 609.4157\n",
      "Epoch [48/100], Step [2600/4091], Loss: 567.7783\n",
      "Epoch [48/100], Step [2700/4091], Loss: 864.9539\n",
      "Epoch [48/100], Step [2800/4091], Loss: 504.4096\n",
      "Epoch [48/100], Step [2900/4091], Loss: 702.6103\n",
      "Epoch [48/100], Step [3000/4091], Loss: 735.6649\n",
      "Epoch [48/100], Step [3100/4091], Loss: 763.2587\n",
      "Epoch [48/100], Step [3200/4091], Loss: 582.3875\n",
      "Epoch [48/100], Step [3300/4091], Loss: 790.1982\n",
      "Epoch [48/100], Step [3400/4091], Loss: 687.0071\n",
      "Epoch [48/100], Step [3500/4091], Loss: 866.9973\n",
      "Epoch [48/100], Step [3600/4091], Loss: 739.8533\n",
      "Epoch [48/100], Step [3700/4091], Loss: 656.6805\n",
      "Epoch [48/100], Step [3800/4091], Loss: 746.6493\n",
      "Epoch [48/100], Step [3900/4091], Loss: 723.5677\n",
      "Epoch [48/100], Step [4000/4091], Loss: 527.4594\n",
      "Epoch [49/100], Step [100/4091], Loss: 665.8109\n",
      "Epoch [49/100], Step [200/4091], Loss: 574.9133\n",
      "Epoch [49/100], Step [300/4091], Loss: 640.4274\n",
      "Epoch [49/100], Step [400/4091], Loss: 863.4377\n",
      "Epoch [49/100], Step [500/4091], Loss: 820.5933\n",
      "Epoch [49/100], Step [600/4091], Loss: 734.0907\n",
      "Epoch [49/100], Step [700/4091], Loss: 750.2987\n",
      "Epoch [49/100], Step [800/4091], Loss: 589.9247\n",
      "Epoch [49/100], Step [900/4091], Loss: 668.8022\n",
      "Epoch [49/100], Step [1000/4091], Loss: 544.7083\n",
      "Epoch [49/100], Step [1100/4091], Loss: 698.8071\n",
      "Epoch [49/100], Step [1200/4091], Loss: 787.8662\n",
      "Epoch [49/100], Step [1300/4091], Loss: 625.8010\n",
      "Epoch [49/100], Step [1400/4091], Loss: 708.1215\n",
      "Epoch [49/100], Step [1500/4091], Loss: 745.3210\n",
      "Epoch [49/100], Step [1600/4091], Loss: 555.3463\n",
      "Epoch [49/100], Step [1700/4091], Loss: 779.2480\n",
      "Epoch [49/100], Step [1800/4091], Loss: 608.3310\n",
      "Epoch [49/100], Step [1900/4091], Loss: 638.1334\n",
      "Epoch [49/100], Step [2000/4091], Loss: 440.9204\n",
      "Epoch [49/100], Step [2100/4091], Loss: 542.8795\n",
      "Epoch [49/100], Step [2200/4091], Loss: 856.9164\n",
      "Epoch [49/100], Step [2300/4091], Loss: 563.9378\n",
      "Epoch [49/100], Step [2400/4091], Loss: 720.0878\n",
      "Epoch [49/100], Step [2500/4091], Loss: 519.3785\n",
      "Epoch [49/100], Step [2600/4091], Loss: 648.0560\n",
      "Epoch [49/100], Step [2700/4091], Loss: 836.6897\n",
      "Epoch [49/100], Step [2800/4091], Loss: 616.2811\n",
      "Epoch [49/100], Step [2900/4091], Loss: 637.8954\n",
      "Epoch [49/100], Step [3000/4091], Loss: 763.1310\n",
      "Epoch [49/100], Step [3100/4091], Loss: 812.4590\n",
      "Epoch [49/100], Step [3200/4091], Loss: 427.3209\n",
      "Epoch [49/100], Step [3300/4091], Loss: 664.6201\n",
      "Epoch [49/100], Step [3400/4091], Loss: 624.4481\n",
      "Epoch [49/100], Step [3500/4091], Loss: 679.2718\n",
      "Epoch [49/100], Step [3600/4091], Loss: 642.5211\n",
      "Epoch [49/100], Step [3700/4091], Loss: 409.5543\n",
      "Epoch [49/100], Step [3800/4091], Loss: 654.7567\n",
      "Epoch [49/100], Step [3900/4091], Loss: 872.1321\n",
      "Epoch [49/100], Step [4000/4091], Loss: 721.5838\n",
      "Epoch [50/100], Step [100/4091], Loss: 536.1606\n",
      "Epoch [50/100], Step [200/4091], Loss: 767.7922\n",
      "Epoch [50/100], Step [300/4091], Loss: 582.2268\n",
      "Epoch [50/100], Step [400/4091], Loss: 933.2390\n",
      "Epoch [50/100], Step [500/4091], Loss: 782.2350\n",
      "Epoch [50/100], Step [600/4091], Loss: 589.5796\n",
      "Epoch [50/100], Step [700/4091], Loss: 762.8575\n",
      "Epoch [50/100], Step [800/4091], Loss: 1050.3289\n",
      "Epoch [50/100], Step [900/4091], Loss: 707.7190\n",
      "Epoch [50/100], Step [1000/4091], Loss: 934.9924\n",
      "Epoch [50/100], Step [1100/4091], Loss: 392.1503\n",
      "Epoch [50/100], Step [1200/4091], Loss: 741.2783\n",
      "Epoch [50/100], Step [1300/4091], Loss: 506.4523\n",
      "Epoch [50/100], Step [1400/4091], Loss: 746.6172\n",
      "Epoch [50/100], Step [1500/4091], Loss: 481.2443\n",
      "Epoch [50/100], Step [1600/4091], Loss: 511.5035\n",
      "Epoch [50/100], Step [1700/4091], Loss: 666.1590\n",
      "Epoch [50/100], Step [1800/4091], Loss: 569.1108\n",
      "Epoch [50/100], Step [1900/4091], Loss: 431.8893\n",
      "Epoch [50/100], Step [2000/4091], Loss: 827.4096\n",
      "Epoch [50/100], Step [2100/4091], Loss: 729.7321\n",
      "Epoch [50/100], Step [2200/4091], Loss: 686.2422\n",
      "Epoch [50/100], Step [2300/4091], Loss: 725.9880\n",
      "Epoch [50/100], Step [2400/4091], Loss: 735.3478\n",
      "Epoch [50/100], Step [2500/4091], Loss: 751.3891\n",
      "Epoch [50/100], Step [2600/4091], Loss: 570.2205\n",
      "Epoch [50/100], Step [2700/4091], Loss: 576.8094\n",
      "Epoch [50/100], Step [2800/4091], Loss: 559.1097\n",
      "Epoch [50/100], Step [2900/4091], Loss: 757.7581\n",
      "Epoch [50/100], Step [3000/4091], Loss: 895.1606\n",
      "Epoch [50/100], Step [3100/4091], Loss: 588.8567\n",
      "Epoch [50/100], Step [3200/4091], Loss: 723.1483\n",
      "Epoch [50/100], Step [3300/4091], Loss: 671.0316\n",
      "Epoch [50/100], Step [3400/4091], Loss: 721.3155\n",
      "Epoch [50/100], Step [3500/4091], Loss: 535.1741\n",
      "Epoch [50/100], Step [3600/4091], Loss: 555.2925\n",
      "Epoch [50/100], Step [3700/4091], Loss: 569.2172\n",
      "Epoch [50/100], Step [3800/4091], Loss: 616.5471\n",
      "Epoch [50/100], Step [3900/4091], Loss: 622.6030\n",
      "Epoch [50/100], Step [4000/4091], Loss: 663.3995\n",
      "Epoch [51/100], Step [100/4091], Loss: 627.9078\n",
      "Epoch [51/100], Step [200/4091], Loss: 545.5270\n",
      "Epoch [51/100], Step [300/4091], Loss: 735.0420\n",
      "Epoch [51/100], Step [400/4091], Loss: 668.7757\n",
      "Epoch [51/100], Step [500/4091], Loss: 635.6553\n",
      "Epoch [51/100], Step [600/4091], Loss: 520.8262\n",
      "Epoch [51/100], Step [700/4091], Loss: 791.3506\n",
      "Epoch [51/100], Step [800/4091], Loss: 760.4705\n",
      "Epoch [51/100], Step [900/4091], Loss: 837.8301\n",
      "Epoch [51/100], Step [1000/4091], Loss: 697.9939\n",
      "Epoch [51/100], Step [1100/4091], Loss: 483.1218\n",
      "Epoch [51/100], Step [1200/4091], Loss: 843.4927\n",
      "Epoch [51/100], Step [1300/4091], Loss: 581.8965\n",
      "Epoch [51/100], Step [1400/4091], Loss: 696.7399\n",
      "Epoch [51/100], Step [1500/4091], Loss: 524.3539\n",
      "Epoch [51/100], Step [1600/4091], Loss: 800.3538\n",
      "Epoch [51/100], Step [1700/4091], Loss: 721.4587\n",
      "Epoch [51/100], Step [1800/4091], Loss: 704.8507\n",
      "Epoch [51/100], Step [1900/4091], Loss: 702.4845\n",
      "Epoch [51/100], Step [2000/4091], Loss: 677.2173\n",
      "Epoch [51/100], Step [2100/4091], Loss: 602.4553\n",
      "Epoch [51/100], Step [2200/4091], Loss: 790.9869\n",
      "Epoch [51/100], Step [2300/4091], Loss: 623.6715\n",
      "Epoch [51/100], Step [2400/4091], Loss: 630.9339\n",
      "Epoch [51/100], Step [2500/4091], Loss: 907.9095\n",
      "Epoch [51/100], Step [2600/4091], Loss: 894.7204\n",
      "Epoch [51/100], Step [2700/4091], Loss: 568.2400\n",
      "Epoch [51/100], Step [2800/4091], Loss: 579.0468\n",
      "Epoch [51/100], Step [2900/4091], Loss: 608.4171\n",
      "Epoch [51/100], Step [3000/4091], Loss: 649.3036\n",
      "Epoch [51/100], Step [3100/4091], Loss: 770.3696\n",
      "Epoch [51/100], Step [3200/4091], Loss: 714.3826\n",
      "Epoch [51/100], Step [3300/4091], Loss: 513.5476\n",
      "Epoch [51/100], Step [3400/4091], Loss: 654.7559\n",
      "Epoch [51/100], Step [3500/4091], Loss: 756.9615\n",
      "Epoch [51/100], Step [3600/4091], Loss: 603.5714\n",
      "Epoch [51/100], Step [3700/4091], Loss: 611.4272\n",
      "Epoch [51/100], Step [3800/4091], Loss: 669.6219\n",
      "Epoch [51/100], Step [3900/4091], Loss: 625.7260\n",
      "Epoch [51/100], Step [4000/4091], Loss: 721.7507\n",
      "Epoch [52/100], Step [100/4091], Loss: 481.9257\n",
      "Epoch [52/100], Step [200/4091], Loss: 613.4356\n",
      "Epoch [52/100], Step [300/4091], Loss: 614.1810\n",
      "Epoch [52/100], Step [400/4091], Loss: 684.8976\n",
      "Epoch [52/100], Step [500/4091], Loss: 834.8206\n",
      "Epoch [52/100], Step [600/4091], Loss: 606.5252\n",
      "Epoch [52/100], Step [700/4091], Loss: 648.8763\n",
      "Epoch [52/100], Step [800/4091], Loss: 542.0649\n",
      "Epoch [52/100], Step [900/4091], Loss: 482.0938\n",
      "Epoch [52/100], Step [1000/4091], Loss: 746.2430\n",
      "Epoch [52/100], Step [1100/4091], Loss: 860.9805\n",
      "Epoch [52/100], Step [1200/4091], Loss: 503.7102\n",
      "Epoch [52/100], Step [1300/4091], Loss: 907.2339\n",
      "Epoch [52/100], Step [1400/4091], Loss: 696.7189\n",
      "Epoch [52/100], Step [1500/4091], Loss: 679.3165\n",
      "Epoch [52/100], Step [1600/4091], Loss: 502.9925\n",
      "Epoch [52/100], Step [1700/4091], Loss: 499.2358\n",
      "Epoch [52/100], Step [1800/4091], Loss: 752.8069\n",
      "Epoch [52/100], Step [1900/4091], Loss: 564.1289\n",
      "Epoch [52/100], Step [2000/4091], Loss: 563.7216\n",
      "Epoch [52/100], Step [2100/4091], Loss: 707.8312\n",
      "Epoch [52/100], Step [2200/4091], Loss: 614.4807\n",
      "Epoch [52/100], Step [2300/4091], Loss: 590.7811\n",
      "Epoch [52/100], Step [2400/4091], Loss: 671.3118\n",
      "Epoch [52/100], Step [2500/4091], Loss: 707.6741\n",
      "Epoch [52/100], Step [2600/4091], Loss: 629.8251\n",
      "Epoch [52/100], Step [2700/4091], Loss: 666.2408\n",
      "Epoch [52/100], Step [2800/4091], Loss: 523.1366\n",
      "Epoch [52/100], Step [2900/4091], Loss: 870.7896\n",
      "Epoch [52/100], Step [3000/4091], Loss: 532.6910\n",
      "Epoch [52/100], Step [3100/4091], Loss: 629.9847\n",
      "Epoch [52/100], Step [3200/4091], Loss: 656.7023\n",
      "Epoch [52/100], Step [3300/4091], Loss: 600.2997\n",
      "Epoch [52/100], Step [3400/4091], Loss: 736.8651\n",
      "Epoch [52/100], Step [3500/4091], Loss: 552.2827\n",
      "Epoch [52/100], Step [3600/4091], Loss: 835.4150\n",
      "Epoch [52/100], Step [3700/4091], Loss: 503.7869\n",
      "Epoch [52/100], Step [3800/4091], Loss: 607.4133\n",
      "Epoch [52/100], Step [3900/4091], Loss: 669.4515\n",
      "Epoch [52/100], Step [4000/4091], Loss: 542.8211\n",
      "Epoch [53/100], Step [100/4091], Loss: 554.0350\n",
      "Epoch [53/100], Step [200/4091], Loss: 818.9210\n",
      "Epoch [53/100], Step [300/4091], Loss: 998.0486\n",
      "Epoch [53/100], Step [400/4091], Loss: 665.2269\n",
      "Epoch [53/100], Step [500/4091], Loss: 885.1656\n",
      "Epoch [53/100], Step [600/4091], Loss: 757.3724\n",
      "Epoch [53/100], Step [700/4091], Loss: 661.1229\n",
      "Epoch [53/100], Step [800/4091], Loss: 855.1254\n",
      "Epoch [53/100], Step [900/4091], Loss: 678.7457\n",
      "Epoch [53/100], Step [1000/4091], Loss: 687.3950\n",
      "Epoch [53/100], Step [1100/4091], Loss: 662.4056\n",
      "Epoch [53/100], Step [1200/4091], Loss: 610.0608\n",
      "Epoch [53/100], Step [1300/4091], Loss: 717.4624\n",
      "Epoch [53/100], Step [1400/4091], Loss: 546.3682\n",
      "Epoch [53/100], Step [1500/4091], Loss: 653.2887\n",
      "Epoch [53/100], Step [1600/4091], Loss: 524.5286\n",
      "Epoch [53/100], Step [1700/4091], Loss: 817.1909\n",
      "Epoch [53/100], Step [1800/4091], Loss: 644.9965\n",
      "Epoch [53/100], Step [1900/4091], Loss: 618.1716\n",
      "Epoch [53/100], Step [2000/4091], Loss: 545.6980\n",
      "Epoch [53/100], Step [2100/4091], Loss: 621.8375\n",
      "Epoch [53/100], Step [2200/4091], Loss: 649.2967\n",
      "Epoch [53/100], Step [2300/4091], Loss: 656.4103\n",
      "Epoch [53/100], Step [2400/4091], Loss: 614.6987\n",
      "Epoch [53/100], Step [2500/4091], Loss: 577.9787\n",
      "Epoch [53/100], Step [2600/4091], Loss: 580.2749\n",
      "Epoch [53/100], Step [2700/4091], Loss: 456.0728\n",
      "Epoch [53/100], Step [2800/4091], Loss: 529.0689\n",
      "Epoch [53/100], Step [2900/4091], Loss: 543.4388\n",
      "Epoch [53/100], Step [3000/4091], Loss: 717.5079\n",
      "Epoch [53/100], Step [3100/4091], Loss: 765.7201\n",
      "Epoch [53/100], Step [3200/4091], Loss: 680.1149\n",
      "Epoch [53/100], Step [3300/4091], Loss: 495.5685\n",
      "Epoch [53/100], Step [3400/4091], Loss: 657.2433\n",
      "Epoch [53/100], Step [3500/4091], Loss: 599.3647\n",
      "Epoch [53/100], Step [3600/4091], Loss: 750.0712\n",
      "Epoch [53/100], Step [3700/4091], Loss: 626.3901\n",
      "Epoch [53/100], Step [3800/4091], Loss: 713.6534\n",
      "Epoch [53/100], Step [3900/4091], Loss: 685.8806\n",
      "Epoch [53/100], Step [4000/4091], Loss: 903.5915\n",
      "Epoch [54/100], Step [100/4091], Loss: 649.5542\n",
      "Epoch [54/100], Step [200/4091], Loss: 601.7509\n",
      "Epoch [54/100], Step [300/4091], Loss: 538.4661\n",
      "Epoch [54/100], Step [400/4091], Loss: 726.1810\n",
      "Epoch [54/100], Step [500/4091], Loss: 742.0604\n",
      "Epoch [54/100], Step [600/4091], Loss: 531.6730\n",
      "Epoch [54/100], Step [700/4091], Loss: 590.9470\n",
      "Epoch [54/100], Step [800/4091], Loss: 565.2032\n",
      "Epoch [54/100], Step [900/4091], Loss: 531.7124\n",
      "Epoch [54/100], Step [1000/4091], Loss: 540.1201\n",
      "Epoch [54/100], Step [1100/4091], Loss: 619.0235\n",
      "Epoch [54/100], Step [1200/4091], Loss: 768.0214\n",
      "Epoch [54/100], Step [1300/4091], Loss: 559.8840\n",
      "Epoch [54/100], Step [1400/4091], Loss: 602.7831\n",
      "Epoch [54/100], Step [1500/4091], Loss: 537.8720\n",
      "Epoch [54/100], Step [1600/4091], Loss: 672.2330\n",
      "Epoch [54/100], Step [1700/4091], Loss: 688.2316\n",
      "Epoch [54/100], Step [1800/4091], Loss: 664.0110\n",
      "Epoch [54/100], Step [1900/4091], Loss: 789.3453\n",
      "Epoch [54/100], Step [2000/4091], Loss: 523.0530\n",
      "Epoch [54/100], Step [2100/4091], Loss: 823.2251\n",
      "Epoch [54/100], Step [2200/4091], Loss: 586.9409\n",
      "Epoch [54/100], Step [2300/4091], Loss: 592.0711\n",
      "Epoch [54/100], Step [2400/4091], Loss: 762.3794\n",
      "Epoch [54/100], Step [2500/4091], Loss: 729.2390\n",
      "Epoch [54/100], Step [2600/4091], Loss: 703.3620\n",
      "Epoch [54/100], Step [2700/4091], Loss: 724.7565\n",
      "Epoch [54/100], Step [2800/4091], Loss: 861.0205\n",
      "Epoch [54/100], Step [2900/4091], Loss: 860.2878\n",
      "Epoch [54/100], Step [3000/4091], Loss: 862.1484\n",
      "Epoch [54/100], Step [3100/4091], Loss: 562.4537\n",
      "Epoch [54/100], Step [3200/4091], Loss: 768.9379\n",
      "Epoch [54/100], Step [3300/4091], Loss: 451.4614\n",
      "Epoch [54/100], Step [3400/4091], Loss: 544.4183\n",
      "Epoch [54/100], Step [3500/4091], Loss: 702.7899\n",
      "Epoch [54/100], Step [3600/4091], Loss: 610.3040\n",
      "Epoch [54/100], Step [3700/4091], Loss: 491.5289\n",
      "Epoch [54/100], Step [3800/4091], Loss: 617.4935\n",
      "Epoch [54/100], Step [3900/4091], Loss: 568.3436\n",
      "Epoch [54/100], Step [4000/4091], Loss: 509.2128\n",
      "Epoch [55/100], Step [100/4091], Loss: 633.8500\n",
      "Epoch [55/100], Step [200/4091], Loss: 781.9865\n",
      "Epoch [55/100], Step [300/4091], Loss: 480.3168\n",
      "Epoch [55/100], Step [400/4091], Loss: 717.9269\n",
      "Epoch [55/100], Step [500/4091], Loss: 553.1555\n",
      "Epoch [55/100], Step [600/4091], Loss: 725.7775\n",
      "Epoch [55/100], Step [700/4091], Loss: 678.4698\n",
      "Epoch [55/100], Step [800/4091], Loss: 456.5963\n",
      "Epoch [55/100], Step [900/4091], Loss: 507.3881\n",
      "Epoch [55/100], Step [1000/4091], Loss: 595.6921\n",
      "Epoch [55/100], Step [1100/4091], Loss: 601.1733\n",
      "Epoch [55/100], Step [1200/4091], Loss: 425.1958\n",
      "Epoch [55/100], Step [1300/4091], Loss: 431.2401\n",
      "Epoch [55/100], Step [1400/4091], Loss: 573.5640\n",
      "Epoch [55/100], Step [1500/4091], Loss: 668.8785\n",
      "Epoch [55/100], Step [1600/4091], Loss: 765.1349\n",
      "Epoch [55/100], Step [1700/4091], Loss: 624.5287\n",
      "Epoch [55/100], Step [1800/4091], Loss: 589.7581\n",
      "Epoch [55/100], Step [1900/4091], Loss: 739.2160\n",
      "Epoch [55/100], Step [2000/4091], Loss: 581.0140\n",
      "Epoch [55/100], Step [2100/4091], Loss: 631.3986\n",
      "Epoch [55/100], Step [2200/4091], Loss: 699.4018\n",
      "Epoch [55/100], Step [2300/4091], Loss: 768.0645\n",
      "Epoch [55/100], Step [2400/4091], Loss: 1000.7640\n",
      "Epoch [55/100], Step [2500/4091], Loss: 570.8495\n",
      "Epoch [55/100], Step [2600/4091], Loss: 576.0109\n",
      "Epoch [55/100], Step [2700/4091], Loss: 653.2486\n",
      "Epoch [55/100], Step [2800/4091], Loss: 741.6923\n",
      "Epoch [55/100], Step [2900/4091], Loss: 651.3466\n",
      "Epoch [55/100], Step [3000/4091], Loss: 490.0665\n",
      "Epoch [55/100], Step [3100/4091], Loss: 657.9208\n",
      "Epoch [55/100], Step [3200/4091], Loss: 565.1724\n",
      "Epoch [55/100], Step [3300/4091], Loss: 664.7920\n",
      "Epoch [55/100], Step [3400/4091], Loss: 497.4691\n",
      "Epoch [55/100], Step [3500/4091], Loss: 556.6222\n",
      "Epoch [55/100], Step [3600/4091], Loss: 761.5464\n",
      "Epoch [55/100], Step [3700/4091], Loss: 594.1057\n",
      "Epoch [55/100], Step [3800/4091], Loss: 568.2075\n",
      "Epoch [55/100], Step [3900/4091], Loss: 484.4086\n",
      "Epoch [55/100], Step [4000/4091], Loss: 631.3104\n",
      "Epoch [56/100], Step [100/4091], Loss: 725.4680\n",
      "Epoch [56/100], Step [200/4091], Loss: 739.3048\n",
      "Epoch [56/100], Step [300/4091], Loss: 731.3654\n",
      "Epoch [56/100], Step [400/4091], Loss: 738.9911\n",
      "Epoch [56/100], Step [500/4091], Loss: 583.0797\n",
      "Epoch [56/100], Step [600/4091], Loss: 830.0127\n",
      "Epoch [56/100], Step [700/4091], Loss: 733.9344\n",
      "Epoch [56/100], Step [800/4091], Loss: 651.0573\n",
      "Epoch [56/100], Step [900/4091], Loss: 813.1957\n",
      "Epoch [56/100], Step [1000/4091], Loss: 837.8787\n",
      "Epoch [56/100], Step [1100/4091], Loss: 699.2333\n",
      "Epoch [56/100], Step [1200/4091], Loss: 557.7764\n",
      "Epoch [56/100], Step [1300/4091], Loss: 666.0887\n",
      "Epoch [56/100], Step [1400/4091], Loss: 621.7723\n",
      "Epoch [56/100], Step [1500/4091], Loss: 667.2194\n",
      "Epoch [56/100], Step [1600/4091], Loss: 632.6498\n",
      "Epoch [56/100], Step [1700/4091], Loss: 639.8905\n",
      "Epoch [56/100], Step [1800/4091], Loss: 602.3508\n",
      "Epoch [56/100], Step [1900/4091], Loss: 684.2831\n",
      "Epoch [56/100], Step [2000/4091], Loss: 549.5613\n",
      "Epoch [56/100], Step [2100/4091], Loss: 585.2571\n",
      "Epoch [56/100], Step [2200/4091], Loss: 754.1342\n",
      "Epoch [56/100], Step [2300/4091], Loss: 583.8921\n",
      "Epoch [56/100], Step [2400/4091], Loss: 498.4351\n",
      "Epoch [56/100], Step [2500/4091], Loss: 759.2680\n",
      "Epoch [56/100], Step [2600/4091], Loss: 519.9244\n",
      "Epoch [56/100], Step [2700/4091], Loss: 544.7576\n",
      "Epoch [56/100], Step [2800/4091], Loss: 759.5256\n",
      "Epoch [56/100], Step [2900/4091], Loss: 545.0626\n",
      "Epoch [56/100], Step [3000/4091], Loss: 617.5955\n",
      "Epoch [56/100], Step [3100/4091], Loss: 671.2906\n",
      "Epoch [56/100], Step [3200/4091], Loss: 538.8559\n",
      "Epoch [56/100], Step [3300/4091], Loss: 806.0321\n",
      "Epoch [56/100], Step [3400/4091], Loss: 676.3730\n",
      "Epoch [56/100], Step [3500/4091], Loss: 556.5061\n",
      "Epoch [56/100], Step [3600/4091], Loss: 537.0966\n",
      "Epoch [56/100], Step [3700/4091], Loss: 575.9926\n",
      "Epoch [56/100], Step [3800/4091], Loss: 540.9194\n",
      "Epoch [56/100], Step [3900/4091], Loss: 652.4869\n",
      "Epoch [56/100], Step [4000/4091], Loss: 558.2694\n",
      "Epoch [57/100], Step [100/4091], Loss: 669.4072\n",
      "Epoch [57/100], Step [200/4091], Loss: 604.7974\n",
      "Epoch [57/100], Step [300/4091], Loss: 575.5104\n",
      "Epoch [57/100], Step [400/4091], Loss: 533.0893\n",
      "Epoch [57/100], Step [500/4091], Loss: 577.9126\n",
      "Epoch [57/100], Step [600/4091], Loss: 806.2618\n",
      "Epoch [57/100], Step [700/4091], Loss: 702.4478\n",
      "Epoch [57/100], Step [800/4091], Loss: 586.4405\n",
      "Epoch [57/100], Step [900/4091], Loss: 575.8104\n",
      "Epoch [57/100], Step [1000/4091], Loss: 696.4302\n",
      "Epoch [57/100], Step [1100/4091], Loss: 681.9209\n",
      "Epoch [57/100], Step [1200/4091], Loss: 532.7748\n",
      "Epoch [57/100], Step [1300/4091], Loss: 781.6709\n",
      "Epoch [57/100], Step [1400/4091], Loss: 800.9177\n",
      "Epoch [57/100], Step [1500/4091], Loss: 736.4965\n",
      "Epoch [57/100], Step [1600/4091], Loss: 602.3466\n",
      "Epoch [57/100], Step [1700/4091], Loss: 734.6730\n",
      "Epoch [57/100], Step [1800/4091], Loss: 838.6570\n",
      "Epoch [57/100], Step [1900/4091], Loss: 809.8834\n",
      "Epoch [57/100], Step [2000/4091], Loss: 543.0281\n",
      "Epoch [57/100], Step [2100/4091], Loss: 916.1491\n",
      "Epoch [57/100], Step [2200/4091], Loss: 917.6068\n",
      "Epoch [57/100], Step [2300/4091], Loss: 625.2474\n",
      "Epoch [57/100], Step [2400/4091], Loss: 523.3904\n",
      "Epoch [57/100], Step [2500/4091], Loss: 707.7609\n",
      "Epoch [57/100], Step [2600/4091], Loss: 601.1702\n",
      "Epoch [57/100], Step [2700/4091], Loss: 599.5331\n",
      "Epoch [57/100], Step [2800/4091], Loss: 748.8513\n",
      "Epoch [57/100], Step [2900/4091], Loss: 720.4206\n",
      "Epoch [57/100], Step [3000/4091], Loss: 624.7361\n",
      "Epoch [57/100], Step [3100/4091], Loss: 523.7690\n",
      "Epoch [57/100], Step [3200/4091], Loss: 665.0959\n",
      "Epoch [57/100], Step [3300/4091], Loss: 732.7059\n",
      "Epoch [57/100], Step [3400/4091], Loss: 717.1991\n",
      "Epoch [57/100], Step [3500/4091], Loss: 618.1086\n",
      "Epoch [57/100], Step [3600/4091], Loss: 848.7222\n",
      "Epoch [57/100], Step [3700/4091], Loss: 564.6887\n",
      "Epoch [57/100], Step [3800/4091], Loss: 613.1112\n",
      "Epoch [57/100], Step [3900/4091], Loss: 587.5628\n",
      "Epoch [57/100], Step [4000/4091], Loss: 635.0969\n",
      "Epoch [58/100], Step [100/4091], Loss: 571.0624\n",
      "Epoch [58/100], Step [200/4091], Loss: 801.5159\n",
      "Epoch [58/100], Step [300/4091], Loss: 569.8319\n",
      "Epoch [58/100], Step [400/4091], Loss: 617.6573\n",
      "Epoch [58/100], Step [500/4091], Loss: 483.5879\n",
      "Epoch [58/100], Step [600/4091], Loss: 819.4841\n",
      "Epoch [58/100], Step [700/4091], Loss: 411.4931\n",
      "Epoch [58/100], Step [800/4091], Loss: 769.8030\n",
      "Epoch [58/100], Step [900/4091], Loss: 787.3340\n",
      "Epoch [58/100], Step [1000/4091], Loss: 683.9911\n",
      "Epoch [58/100], Step [1100/4091], Loss: 589.6484\n",
      "Epoch [58/100], Step [1200/4091], Loss: 612.0891\n",
      "Epoch [58/100], Step [1300/4091], Loss: 629.1409\n",
      "Epoch [58/100], Step [1400/4091], Loss: 455.9827\n",
      "Epoch [58/100], Step [1500/4091], Loss: 492.4096\n",
      "Epoch [58/100], Step [1600/4091], Loss: 640.9189\n",
      "Epoch [58/100], Step [1700/4091], Loss: 976.8128\n",
      "Epoch [58/100], Step [1800/4091], Loss: 680.9964\n",
      "Epoch [58/100], Step [1900/4091], Loss: 637.1904\n",
      "Epoch [58/100], Step [2000/4091], Loss: 759.6526\n",
      "Epoch [58/100], Step [2100/4091], Loss: 659.9286\n",
      "Epoch [58/100], Step [2200/4091], Loss: 800.8511\n",
      "Epoch [58/100], Step [2300/4091], Loss: 607.7939\n",
      "Epoch [58/100], Step [2400/4091], Loss: 471.1872\n",
      "Epoch [58/100], Step [2500/4091], Loss: 494.4428\n",
      "Epoch [58/100], Step [2600/4091], Loss: 692.0676\n",
      "Epoch [58/100], Step [2700/4091], Loss: 594.6672\n",
      "Epoch [58/100], Step [2800/4091], Loss: 779.9431\n",
      "Epoch [58/100], Step [2900/4091], Loss: 622.3204\n",
      "Epoch [58/100], Step [3000/4091], Loss: 916.1873\n",
      "Epoch [58/100], Step [3100/4091], Loss: 658.6266\n",
      "Epoch [58/100], Step [3200/4091], Loss: 614.2092\n",
      "Epoch [58/100], Step [3300/4091], Loss: 561.2328\n",
      "Epoch [58/100], Step [3400/4091], Loss: 704.6942\n",
      "Epoch [58/100], Step [3500/4091], Loss: 742.0522\n",
      "Epoch [58/100], Step [3600/4091], Loss: 567.5182\n",
      "Epoch [58/100], Step [3700/4091], Loss: 591.7031\n",
      "Epoch [58/100], Step [3800/4091], Loss: 589.8978\n",
      "Epoch [58/100], Step [3900/4091], Loss: 503.8782\n",
      "Epoch [58/100], Step [4000/4091], Loss: 588.8943\n",
      "Epoch [59/100], Step [100/4091], Loss: 648.3829\n",
      "Epoch [59/100], Step [200/4091], Loss: 421.7919\n",
      "Epoch [59/100], Step [300/4091], Loss: 730.1182\n",
      "Epoch [59/100], Step [400/4091], Loss: 584.8416\n",
      "Epoch [59/100], Step [500/4091], Loss: 465.9365\n",
      "Epoch [59/100], Step [600/4091], Loss: 414.0861\n",
      "Epoch [59/100], Step [700/4091], Loss: 591.7969\n",
      "Epoch [59/100], Step [800/4091], Loss: 678.9279\n",
      "Epoch [59/100], Step [900/4091], Loss: 633.6505\n",
      "Epoch [59/100], Step [1000/4091], Loss: 677.6140\n",
      "Epoch [59/100], Step [1100/4091], Loss: 488.5485\n",
      "Epoch [59/100], Step [1200/4091], Loss: 504.8680\n",
      "Epoch [59/100], Step [1300/4091], Loss: 592.0363\n",
      "Epoch [59/100], Step [1400/4091], Loss: 654.4327\n",
      "Epoch [59/100], Step [1500/4091], Loss: 760.7607\n",
      "Epoch [59/100], Step [1600/4091], Loss: 436.5758\n",
      "Epoch [59/100], Step [1700/4091], Loss: 552.5978\n",
      "Epoch [59/100], Step [1800/4091], Loss: 540.3682\n",
      "Epoch [59/100], Step [1900/4091], Loss: 690.2026\n",
      "Epoch [59/100], Step [2000/4091], Loss: 451.7076\n",
      "Epoch [59/100], Step [2100/4091], Loss: 646.4797\n",
      "Epoch [59/100], Step [2200/4091], Loss: 450.1521\n",
      "Epoch [59/100], Step [2300/4091], Loss: 869.7635\n",
      "Epoch [59/100], Step [2400/4091], Loss: 649.7171\n",
      "Epoch [59/100], Step [2500/4091], Loss: 749.7927\n",
      "Epoch [59/100], Step [2600/4091], Loss: 640.7584\n",
      "Epoch [59/100], Step [2700/4091], Loss: 724.3662\n",
      "Epoch [59/100], Step [2800/4091], Loss: 604.1327\n",
      "Epoch [59/100], Step [2900/4091], Loss: 593.4238\n",
      "Epoch [59/100], Step [3000/4091], Loss: 660.6173\n",
      "Epoch [59/100], Step [3100/4091], Loss: 641.1042\n",
      "Epoch [59/100], Step [3200/4091], Loss: 550.3443\n",
      "Epoch [59/100], Step [3300/4091], Loss: 467.0417\n",
      "Epoch [59/100], Step [3400/4091], Loss: 635.3029\n",
      "Epoch [59/100], Step [3500/4091], Loss: 921.5692\n",
      "Epoch [59/100], Step [3600/4091], Loss: 804.3065\n",
      "Epoch [59/100], Step [3700/4091], Loss: 516.0907\n",
      "Epoch [59/100], Step [3800/4091], Loss: 613.5364\n",
      "Epoch [59/100], Step [3900/4091], Loss: 822.1378\n",
      "Epoch [59/100], Step [4000/4091], Loss: 743.7221\n",
      "Epoch [60/100], Step [100/4091], Loss: 570.7730\n",
      "Epoch [60/100], Step [200/4091], Loss: 655.0905\n",
      "Epoch [60/100], Step [300/4091], Loss: 681.2180\n",
      "Epoch [60/100], Step [400/4091], Loss: 758.0942\n",
      "Epoch [60/100], Step [500/4091], Loss: 443.7685\n",
      "Epoch [60/100], Step [600/4091], Loss: 830.6848\n",
      "Epoch [60/100], Step [700/4091], Loss: 948.2606\n",
      "Epoch [60/100], Step [800/4091], Loss: 457.1039\n",
      "Epoch [60/100], Step [900/4091], Loss: 521.7708\n",
      "Epoch [60/100], Step [1000/4091], Loss: 642.3088\n",
      "Epoch [60/100], Step [1100/4091], Loss: 908.6169\n",
      "Epoch [60/100], Step [1200/4091], Loss: 544.4099\n",
      "Epoch [60/100], Step [1300/4091], Loss: 577.1266\n",
      "Epoch [60/100], Step [1400/4091], Loss: 821.2515\n",
      "Epoch [60/100], Step [1500/4091], Loss: 625.6340\n",
      "Epoch [60/100], Step [1600/4091], Loss: 936.2566\n",
      "Epoch [60/100], Step [1700/4091], Loss: 966.6318\n",
      "Epoch [60/100], Step [1800/4091], Loss: 724.0073\n",
      "Epoch [60/100], Step [1900/4091], Loss: 514.3107\n",
      "Epoch [60/100], Step [2000/4091], Loss: 655.0330\n",
      "Epoch [60/100], Step [2100/4091], Loss: 861.0121\n",
      "Epoch [60/100], Step [2200/4091], Loss: 584.0026\n",
      "Epoch [60/100], Step [2300/4091], Loss: 709.6821\n",
      "Epoch [60/100], Step [2400/4091], Loss: 537.8528\n",
      "Epoch [60/100], Step [2500/4091], Loss: 760.1288\n",
      "Epoch [60/100], Step [2600/4091], Loss: 558.0605\n",
      "Epoch [60/100], Step [2700/4091], Loss: 693.1040\n",
      "Epoch [60/100], Step [2800/4091], Loss: 512.0001\n",
      "Epoch [60/100], Step [2900/4091], Loss: 602.6702\n",
      "Epoch [60/100], Step [3000/4091], Loss: 630.9366\n",
      "Epoch [60/100], Step [3100/4091], Loss: 569.5145\n",
      "Epoch [60/100], Step [3200/4091], Loss: 658.8435\n",
      "Epoch [60/100], Step [3300/4091], Loss: 714.7157\n",
      "Epoch [60/100], Step [3400/4091], Loss: 956.6541\n",
      "Epoch [60/100], Step [3500/4091], Loss: 519.9523\n",
      "Epoch [60/100], Step [3600/4091], Loss: 518.4587\n",
      "Epoch [60/100], Step [3700/4091], Loss: 601.7209\n",
      "Epoch [60/100], Step [3800/4091], Loss: 651.3245\n",
      "Epoch [60/100], Step [3900/4091], Loss: 763.5627\n",
      "Epoch [60/100], Step [4000/4091], Loss: 512.8606\n",
      "Epoch [61/100], Step [100/4091], Loss: 805.8459\n",
      "Epoch [61/100], Step [200/4091], Loss: 575.9884\n",
      "Epoch [61/100], Step [300/4091], Loss: 708.3804\n",
      "Epoch [61/100], Step [400/4091], Loss: 668.3149\n",
      "Epoch [61/100], Step [500/4091], Loss: 646.6965\n",
      "Epoch [61/100], Step [600/4091], Loss: 522.4730\n",
      "Epoch [61/100], Step [700/4091], Loss: 619.6075\n",
      "Epoch [61/100], Step [800/4091], Loss: 813.2652\n",
      "Epoch [61/100], Step [900/4091], Loss: 680.7029\n",
      "Epoch [61/100], Step [1000/4091], Loss: 538.9255\n",
      "Epoch [61/100], Step [1100/4091], Loss: 593.3705\n",
      "Epoch [61/100], Step [1200/4091], Loss: 888.6616\n",
      "Epoch [61/100], Step [1300/4091], Loss: 670.2686\n",
      "Epoch [61/100], Step [1400/4091], Loss: 592.7147\n",
      "Epoch [61/100], Step [1500/4091], Loss: 684.8859\n",
      "Epoch [61/100], Step [1600/4091], Loss: 847.1608\n",
      "Epoch [61/100], Step [1700/4091], Loss: 505.7505\n",
      "Epoch [61/100], Step [1800/4091], Loss: 589.0965\n",
      "Epoch [61/100], Step [1900/4091], Loss: 567.7455\n",
      "Epoch [61/100], Step [2000/4091], Loss: 793.7417\n",
      "Epoch [61/100], Step [2100/4091], Loss: 535.4340\n",
      "Epoch [61/100], Step [2200/4091], Loss: 941.1282\n",
      "Epoch [61/100], Step [2300/4091], Loss: 513.7961\n",
      "Epoch [61/100], Step [2400/4091], Loss: 695.8287\n",
      "Epoch [61/100], Step [2500/4091], Loss: 790.0372\n",
      "Epoch [61/100], Step [2600/4091], Loss: 683.4736\n",
      "Epoch [61/100], Step [2700/4091], Loss: 676.0850\n",
      "Epoch [61/100], Step [2800/4091], Loss: 650.7379\n",
      "Epoch [61/100], Step [2900/4091], Loss: 978.4163\n",
      "Epoch [61/100], Step [3000/4091], Loss: 725.7238\n",
      "Epoch [61/100], Step [3100/4091], Loss: 542.1642\n",
      "Epoch [61/100], Step [3200/4091], Loss: 719.1783\n",
      "Epoch [61/100], Step [3300/4091], Loss: 501.2991\n",
      "Epoch [61/100], Step [3400/4091], Loss: 863.5831\n",
      "Epoch [61/100], Step [3500/4091], Loss: 553.4825\n",
      "Epoch [61/100], Step [3600/4091], Loss: 628.2670\n",
      "Epoch [61/100], Step [3700/4091], Loss: 691.7767\n",
      "Epoch [61/100], Step [3800/4091], Loss: 789.7460\n",
      "Epoch [61/100], Step [3900/4091], Loss: 711.6872\n",
      "Epoch [61/100], Step [4000/4091], Loss: 762.8026\n",
      "Epoch [62/100], Step [100/4091], Loss: 518.3885\n",
      "Epoch [62/100], Step [200/4091], Loss: 691.4073\n",
      "Epoch [62/100], Step [300/4091], Loss: 635.3746\n",
      "Epoch [62/100], Step [400/4091], Loss: 679.0314\n",
      "Epoch [62/100], Step [500/4091], Loss: 649.2406\n",
      "Epoch [62/100], Step [600/4091], Loss: 631.4761\n",
      "Epoch [62/100], Step [700/4091], Loss: 634.5782\n",
      "Epoch [62/100], Step [800/4091], Loss: 657.7914\n",
      "Epoch [62/100], Step [900/4091], Loss: 634.1699\n",
      "Epoch [62/100], Step [1000/4091], Loss: 804.4455\n",
      "Epoch [62/100], Step [1100/4091], Loss: 605.3473\n",
      "Epoch [62/100], Step [1200/4091], Loss: 629.6359\n",
      "Epoch [62/100], Step [1300/4091], Loss: 603.6659\n",
      "Epoch [62/100], Step [1400/4091], Loss: 872.7549\n",
      "Epoch [62/100], Step [1500/4091], Loss: 707.4241\n",
      "Epoch [62/100], Step [1600/4091], Loss: 558.3483\n",
      "Epoch [62/100], Step [1700/4091], Loss: 706.5066\n",
      "Epoch [62/100], Step [1800/4091], Loss: 628.9129\n",
      "Epoch [62/100], Step [1900/4091], Loss: 446.0157\n",
      "Epoch [62/100], Step [2000/4091], Loss: 667.3875\n",
      "Epoch [62/100], Step [2100/4091], Loss: 555.4056\n",
      "Epoch [62/100], Step [2200/4091], Loss: 668.5441\n",
      "Epoch [62/100], Step [2300/4091], Loss: 785.2422\n",
      "Epoch [62/100], Step [2400/4091], Loss: 597.2091\n",
      "Epoch [62/100], Step [2500/4091], Loss: 436.0340\n",
      "Epoch [62/100], Step [2600/4091], Loss: 980.8937\n",
      "Epoch [62/100], Step [2700/4091], Loss: 714.2250\n",
      "Epoch [62/100], Step [2800/4091], Loss: 576.0973\n",
      "Epoch [62/100], Step [2900/4091], Loss: 837.5597\n",
      "Epoch [62/100], Step [3000/4091], Loss: 660.5023\n",
      "Epoch [62/100], Step [3100/4091], Loss: 750.7255\n",
      "Epoch [62/100], Step [3200/4091], Loss: 711.1643\n",
      "Epoch [62/100], Step [3300/4091], Loss: 787.8117\n",
      "Epoch [62/100], Step [3400/4091], Loss: 804.5580\n",
      "Epoch [62/100], Step [3500/4091], Loss: 655.7747\n",
      "Epoch [62/100], Step [3600/4091], Loss: 727.7933\n",
      "Epoch [62/100], Step [3700/4091], Loss: 767.2059\n",
      "Epoch [62/100], Step [3800/4091], Loss: 744.0283\n",
      "Epoch [62/100], Step [3900/4091], Loss: 791.3345\n",
      "Epoch [62/100], Step [4000/4091], Loss: 741.6569\n",
      "Epoch [63/100], Step [100/4091], Loss: 490.5490\n",
      "Epoch [63/100], Step [200/4091], Loss: 500.8751\n",
      "Epoch [63/100], Step [300/4091], Loss: 521.5766\n",
      "Epoch [63/100], Step [400/4091], Loss: 606.6074\n",
      "Epoch [63/100], Step [500/4091], Loss: 625.6115\n",
      "Epoch [63/100], Step [600/4091], Loss: 677.3108\n",
      "Epoch [63/100], Step [700/4091], Loss: 588.9824\n",
      "Epoch [63/100], Step [800/4091], Loss: 521.8596\n",
      "Epoch [63/100], Step [900/4091], Loss: 717.8132\n",
      "Epoch [63/100], Step [1000/4091], Loss: 590.5530\n",
      "Epoch [63/100], Step [1100/4091], Loss: 720.7047\n",
      "Epoch [63/100], Step [1200/4091], Loss: 825.7936\n",
      "Epoch [63/100], Step [1300/4091], Loss: 618.9285\n",
      "Epoch [63/100], Step [1400/4091], Loss: 575.2070\n",
      "Epoch [63/100], Step [1500/4091], Loss: 716.3015\n",
      "Epoch [63/100], Step [1600/4091], Loss: 691.8947\n",
      "Epoch [63/100], Step [1700/4091], Loss: 599.1306\n",
      "Epoch [63/100], Step [1800/4091], Loss: 735.2940\n",
      "Epoch [63/100], Step [1900/4091], Loss: 606.6807\n",
      "Epoch [63/100], Step [2000/4091], Loss: 516.7332\n",
      "Epoch [63/100], Step [2100/4091], Loss: 948.3135\n",
      "Epoch [63/100], Step [2200/4091], Loss: 725.1331\n",
      "Epoch [63/100], Step [2300/4091], Loss: 609.1996\n",
      "Epoch [63/100], Step [2400/4091], Loss: 644.6912\n",
      "Epoch [63/100], Step [2500/4091], Loss: 615.7692\n",
      "Epoch [63/100], Step [2600/4091], Loss: 756.8460\n",
      "Epoch [63/100], Step [2700/4091], Loss: 693.9169\n",
      "Epoch [63/100], Step [2800/4091], Loss: 575.5028\n",
      "Epoch [63/100], Step [2900/4091], Loss: 598.7113\n",
      "Epoch [63/100], Step [3000/4091], Loss: 534.3582\n",
      "Epoch [63/100], Step [3100/4091], Loss: 810.4858\n",
      "Epoch [63/100], Step [3200/4091], Loss: 700.7058\n",
      "Epoch [63/100], Step [3300/4091], Loss: 469.5792\n",
      "Epoch [63/100], Step [3400/4091], Loss: 493.5825\n",
      "Epoch [63/100], Step [3500/4091], Loss: 667.7634\n",
      "Epoch [63/100], Step [3600/4091], Loss: 779.7850\n",
      "Epoch [63/100], Step [3700/4091], Loss: 623.0940\n",
      "Epoch [63/100], Step [3800/4091], Loss: 664.1376\n",
      "Epoch [63/100], Step [3900/4091], Loss: 675.6651\n",
      "Epoch [63/100], Step [4000/4091], Loss: 891.3713\n",
      "Epoch [64/100], Step [100/4091], Loss: 491.6810\n",
      "Epoch [64/100], Step [200/4091], Loss: 593.7944\n",
      "Epoch [64/100], Step [300/4091], Loss: 615.8626\n",
      "Epoch [64/100], Step [400/4091], Loss: 630.3079\n",
      "Epoch [64/100], Step [500/4091], Loss: 696.6868\n",
      "Epoch [64/100], Step [600/4091], Loss: 748.3102\n",
      "Epoch [64/100], Step [700/4091], Loss: 739.4453\n",
      "Epoch [64/100], Step [800/4091], Loss: 731.2766\n",
      "Epoch [64/100], Step [900/4091], Loss: 715.4091\n",
      "Epoch [64/100], Step [1000/4091], Loss: 675.9024\n",
      "Epoch [64/100], Step [1100/4091], Loss: 746.9014\n",
      "Epoch [64/100], Step [1200/4091], Loss: 648.9210\n",
      "Epoch [64/100], Step [1300/4091], Loss: 952.3326\n",
      "Epoch [64/100], Step [1400/4091], Loss: 520.5270\n",
      "Epoch [64/100], Step [1500/4091], Loss: 666.8964\n",
      "Epoch [64/100], Step [1600/4091], Loss: 492.5944\n",
      "Epoch [64/100], Step [1700/4091], Loss: 743.0922\n",
      "Epoch [64/100], Step [1800/4091], Loss: 617.5450\n",
      "Epoch [64/100], Step [1900/4091], Loss: 770.0295\n",
      "Epoch [64/100], Step [2000/4091], Loss: 876.9766\n",
      "Epoch [64/100], Step [2100/4091], Loss: 716.4099\n",
      "Epoch [64/100], Step [2200/4091], Loss: 507.9399\n",
      "Epoch [64/100], Step [2300/4091], Loss: 491.4850\n",
      "Epoch [64/100], Step [2400/4091], Loss: 788.0076\n",
      "Epoch [64/100], Step [2500/4091], Loss: 762.9335\n",
      "Epoch [64/100], Step [2600/4091], Loss: 471.8993\n",
      "Epoch [64/100], Step [2700/4091], Loss: 649.6501\n",
      "Epoch [64/100], Step [2800/4091], Loss: 686.0182\n",
      "Epoch [64/100], Step [2900/4091], Loss: 484.7812\n",
      "Epoch [64/100], Step [3000/4091], Loss: 620.6547\n",
      "Epoch [64/100], Step [3100/4091], Loss: 745.1758\n",
      "Epoch [64/100], Step [3200/4091], Loss: 521.9247\n",
      "Epoch [64/100], Step [3300/4091], Loss: 610.9889\n",
      "Epoch [64/100], Step [3400/4091], Loss: 711.2815\n",
      "Epoch [64/100], Step [3500/4091], Loss: 763.4576\n",
      "Epoch [64/100], Step [3600/4091], Loss: 555.6863\n",
      "Epoch [64/100], Step [3700/4091], Loss: 896.6466\n",
      "Epoch [64/100], Step [3800/4091], Loss: 540.5025\n",
      "Epoch [64/100], Step [3900/4091], Loss: 517.2538\n",
      "Epoch [64/100], Step [4000/4091], Loss: 996.5082\n",
      "Epoch [65/100], Step [100/4091], Loss: 706.3601\n",
      "Epoch [65/100], Step [200/4091], Loss: 663.1552\n",
      "Epoch [65/100], Step [300/4091], Loss: 745.0317\n",
      "Epoch [65/100], Step [400/4091], Loss: 869.9343\n",
      "Epoch [65/100], Step [500/4091], Loss: 509.2620\n",
      "Epoch [65/100], Step [600/4091], Loss: 626.6622\n",
      "Epoch [65/100], Step [700/4091], Loss: 970.4535\n",
      "Epoch [65/100], Step [800/4091], Loss: 621.0944\n",
      "Epoch [65/100], Step [900/4091], Loss: 719.5596\n",
      "Epoch [65/100], Step [1000/4091], Loss: 442.6508\n",
      "Epoch [65/100], Step [1100/4091], Loss: 634.3263\n",
      "Epoch [65/100], Step [1200/4091], Loss: 834.7401\n",
      "Epoch [65/100], Step [1300/4091], Loss: 492.7711\n",
      "Epoch [65/100], Step [1400/4091], Loss: 816.4555\n",
      "Epoch [65/100], Step [1500/4091], Loss: 888.3859\n",
      "Epoch [65/100], Step [1600/4091], Loss: 887.3180\n",
      "Epoch [65/100], Step [1700/4091], Loss: 664.1098\n",
      "Epoch [65/100], Step [1800/4091], Loss: 794.2570\n",
      "Epoch [65/100], Step [1900/4091], Loss: 704.1263\n",
      "Epoch [65/100], Step [2000/4091], Loss: 580.4937\n",
      "Epoch [65/100], Step [2100/4091], Loss: 654.6892\n",
      "Epoch [65/100], Step [2200/4091], Loss: 648.4347\n",
      "Epoch [65/100], Step [2300/4091], Loss: 519.7596\n",
      "Epoch [65/100], Step [2400/4091], Loss: 471.8875\n",
      "Epoch [65/100], Step [2500/4091], Loss: 703.0453\n",
      "Epoch [65/100], Step [2600/4091], Loss: 529.5061\n",
      "Epoch [65/100], Step [2700/4091], Loss: 760.2798\n",
      "Epoch [65/100], Step [2800/4091], Loss: 513.2189\n",
      "Epoch [65/100], Step [2900/4091], Loss: 794.9255\n",
      "Epoch [65/100], Step [3000/4091], Loss: 949.6212\n",
      "Epoch [65/100], Step [3100/4091], Loss: 491.8447\n",
      "Epoch [65/100], Step [3200/4091], Loss: 442.7414\n",
      "Epoch [65/100], Step [3300/4091], Loss: 717.2485\n",
      "Epoch [65/100], Step [3400/4091], Loss: 738.8517\n",
      "Epoch [65/100], Step [3500/4091], Loss: 677.6690\n",
      "Epoch [65/100], Step [3600/4091], Loss: 785.3481\n",
      "Epoch [65/100], Step [3700/4091], Loss: 566.6322\n",
      "Epoch [65/100], Step [3800/4091], Loss: 747.5682\n",
      "Epoch [65/100], Step [3900/4091], Loss: 777.5725\n",
      "Epoch [65/100], Step [4000/4091], Loss: 582.6691\n",
      "Epoch [66/100], Step [100/4091], Loss: 554.7409\n",
      "Epoch [66/100], Step [200/4091], Loss: 725.4274\n",
      "Epoch [66/100], Step [300/4091], Loss: 742.5961\n",
      "Epoch [66/100], Step [400/4091], Loss: 559.3184\n",
      "Epoch [66/100], Step [500/4091], Loss: 727.0020\n",
      "Epoch [66/100], Step [600/4091], Loss: 729.6638\n",
      "Epoch [66/100], Step [700/4091], Loss: 606.7156\n",
      "Epoch [66/100], Step [800/4091], Loss: 763.8644\n",
      "Epoch [66/100], Step [900/4091], Loss: 608.7328\n",
      "Epoch [66/100], Step [1000/4091], Loss: 877.1813\n",
      "Epoch [66/100], Step [1100/4091], Loss: 691.0503\n",
      "Epoch [66/100], Step [1200/4091], Loss: 466.4538\n",
      "Epoch [66/100], Step [1300/4091], Loss: 502.8978\n",
      "Epoch [66/100], Step [1400/4091], Loss: 796.6135\n",
      "Epoch [66/100], Step [1500/4091], Loss: 674.2751\n",
      "Epoch [66/100], Step [1600/4091], Loss: 616.2501\n",
      "Epoch [66/100], Step [1700/4091], Loss: 595.5740\n",
      "Epoch [66/100], Step [1800/4091], Loss: 666.2203\n",
      "Epoch [66/100], Step [1900/4091], Loss: 705.9353\n",
      "Epoch [66/100], Step [2000/4091], Loss: 647.5707\n",
      "Epoch [66/100], Step [2100/4091], Loss: 627.1553\n",
      "Epoch [66/100], Step [2200/4091], Loss: 755.9071\n",
      "Epoch [66/100], Step [2300/4091], Loss: 532.9095\n",
      "Epoch [66/100], Step [2400/4091], Loss: 542.7570\n",
      "Epoch [66/100], Step [2500/4091], Loss: 697.1666\n",
      "Epoch [66/100], Step [2600/4091], Loss: 473.7576\n",
      "Epoch [66/100], Step [2700/4091], Loss: 628.8018\n",
      "Epoch [66/100], Step [2800/4091], Loss: 524.0493\n",
      "Epoch [66/100], Step [2900/4091], Loss: 755.3250\n",
      "Epoch [66/100], Step [3000/4091], Loss: 749.1873\n",
      "Epoch [66/100], Step [3100/4091], Loss: 828.0114\n",
      "Epoch [66/100], Step [3200/4091], Loss: 775.6439\n",
      "Epoch [66/100], Step [3300/4091], Loss: 793.7452\n",
      "Epoch [66/100], Step [3400/4091], Loss: 787.4801\n",
      "Epoch [66/100], Step [3500/4091], Loss: 548.8975\n",
      "Epoch [66/100], Step [3600/4091], Loss: 699.6917\n",
      "Epoch [66/100], Step [3700/4091], Loss: 637.8896\n",
      "Epoch [66/100], Step [3800/4091], Loss: 686.8732\n",
      "Epoch [66/100], Step [3900/4091], Loss: 563.9700\n",
      "Epoch [66/100], Step [4000/4091], Loss: 692.0690\n",
      "Epoch [67/100], Step [100/4091], Loss: 784.6409\n",
      "Epoch [67/100], Step [200/4091], Loss: 693.9107\n",
      "Epoch [67/100], Step [300/4091], Loss: 561.9213\n",
      "Epoch [67/100], Step [400/4091], Loss: 619.2225\n",
      "Epoch [67/100], Step [500/4091], Loss: 648.6395\n",
      "Epoch [67/100], Step [600/4091], Loss: 829.6821\n",
      "Epoch [67/100], Step [700/4091], Loss: 849.5355\n",
      "Epoch [67/100], Step [800/4091], Loss: 792.2599\n",
      "Epoch [67/100], Step [900/4091], Loss: 603.6310\n",
      "Epoch [67/100], Step [1000/4091], Loss: 787.2477\n",
      "Epoch [67/100], Step [1100/4091], Loss: 673.0930\n",
      "Epoch [67/100], Step [1200/4091], Loss: 879.0822\n",
      "Epoch [67/100], Step [1300/4091], Loss: 725.7819\n",
      "Epoch [67/100], Step [1400/4091], Loss: 1007.7033\n",
      "Epoch [67/100], Step [1500/4091], Loss: 698.5366\n",
      "Epoch [67/100], Step [1600/4091], Loss: 485.7162\n",
      "Epoch [67/100], Step [1700/4091], Loss: 581.3344\n",
      "Epoch [67/100], Step [1800/4091], Loss: 695.4643\n",
      "Epoch [67/100], Step [1900/4091], Loss: 912.6304\n",
      "Epoch [67/100], Step [2000/4091], Loss: 650.1741\n",
      "Epoch [67/100], Step [2100/4091], Loss: 863.9520\n",
      "Epoch [67/100], Step [2200/4091], Loss: 632.8285\n",
      "Epoch [67/100], Step [2300/4091], Loss: 605.0137\n",
      "Epoch [67/100], Step [2400/4091], Loss: 852.0143\n",
      "Epoch [67/100], Step [2500/4091], Loss: 502.7639\n",
      "Epoch [67/100], Step [2600/4091], Loss: 541.5256\n",
      "Epoch [67/100], Step [2700/4091], Loss: 563.4274\n",
      "Epoch [67/100], Step [2800/4091], Loss: 553.6226\n",
      "Epoch [67/100], Step [2900/4091], Loss: 703.4024\n",
      "Epoch [67/100], Step [3000/4091], Loss: 771.3539\n",
      "Epoch [67/100], Step [3100/4091], Loss: 729.9609\n",
      "Epoch [67/100], Step [3200/4091], Loss: 658.8116\n",
      "Epoch [67/100], Step [3300/4091], Loss: 560.4676\n",
      "Epoch [67/100], Step [3400/4091], Loss: 605.0783\n",
      "Epoch [67/100], Step [3500/4091], Loss: 766.7659\n",
      "Epoch [67/100], Step [3600/4091], Loss: 686.3989\n",
      "Epoch [67/100], Step [3700/4091], Loss: 808.5446\n",
      "Epoch [67/100], Step [3800/4091], Loss: 649.2211\n",
      "Epoch [67/100], Step [3900/4091], Loss: 652.7535\n",
      "Epoch [67/100], Step [4000/4091], Loss: 539.3149\n",
      "Epoch [68/100], Step [100/4091], Loss: 794.5614\n",
      "Epoch [68/100], Step [200/4091], Loss: 633.0088\n",
      "Epoch [68/100], Step [300/4091], Loss: 407.0748\n",
      "Epoch [68/100], Step [400/4091], Loss: 789.8313\n",
      "Epoch [68/100], Step [500/4091], Loss: 501.9634\n",
      "Epoch [68/100], Step [600/4091], Loss: 685.1559\n",
      "Epoch [68/100], Step [700/4091], Loss: 630.7340\n",
      "Epoch [68/100], Step [800/4091], Loss: 653.4699\n",
      "Epoch [68/100], Step [900/4091], Loss: 564.7260\n",
      "Epoch [68/100], Step [1000/4091], Loss: 662.2717\n",
      "Epoch [68/100], Step [1100/4091], Loss: 597.1484\n",
      "Epoch [68/100], Step [1200/4091], Loss: 700.0277\n",
      "Epoch [68/100], Step [1300/4091], Loss: 635.4887\n",
      "Epoch [68/100], Step [1400/4091], Loss: 596.2261\n",
      "Epoch [68/100], Step [1500/4091], Loss: 720.9283\n",
      "Epoch [68/100], Step [1600/4091], Loss: 602.6447\n",
      "Epoch [68/100], Step [1700/4091], Loss: 757.1854\n",
      "Epoch [68/100], Step [1800/4091], Loss: 774.3104\n",
      "Epoch [68/100], Step [1900/4091], Loss: 604.3120\n",
      "Epoch [68/100], Step [2000/4091], Loss: 543.7879\n",
      "Epoch [68/100], Step [2100/4091], Loss: 638.8400\n",
      "Epoch [68/100], Step [2200/4091], Loss: 789.8006\n",
      "Epoch [68/100], Step [2300/4091], Loss: 800.7141\n",
      "Epoch [68/100], Step [2400/4091], Loss: 557.4631\n",
      "Epoch [68/100], Step [2500/4091], Loss: 690.7358\n",
      "Epoch [68/100], Step [2600/4091], Loss: 534.9455\n",
      "Epoch [68/100], Step [2700/4091], Loss: 674.3911\n",
      "Epoch [68/100], Step [2800/4091], Loss: 595.6283\n",
      "Epoch [68/100], Step [2900/4091], Loss: 569.3931\n",
      "Epoch [68/100], Step [3000/4091], Loss: 429.5347\n",
      "Epoch [68/100], Step [3100/4091], Loss: 810.3502\n",
      "Epoch [68/100], Step [3200/4091], Loss: 708.5049\n",
      "Epoch [68/100], Step [3300/4091], Loss: 742.0902\n",
      "Epoch [68/100], Step [3400/4091], Loss: 566.9686\n",
      "Epoch [68/100], Step [3500/4091], Loss: 598.8361\n",
      "Epoch [68/100], Step [3600/4091], Loss: 954.5712\n",
      "Epoch [68/100], Step [3700/4091], Loss: 580.7694\n",
      "Epoch [68/100], Step [3800/4091], Loss: 746.1583\n",
      "Epoch [68/100], Step [3900/4091], Loss: 627.1033\n",
      "Epoch [68/100], Step [4000/4091], Loss: 629.9518\n",
      "Epoch [69/100], Step [100/4091], Loss: 662.4398\n",
      "Epoch [69/100], Step [200/4091], Loss: 673.8987\n",
      "Epoch [69/100], Step [300/4091], Loss: 799.4271\n",
      "Epoch [69/100], Step [400/4091], Loss: 511.3043\n",
      "Epoch [69/100], Step [500/4091], Loss: 609.9526\n",
      "Epoch [69/100], Step [600/4091], Loss: 675.8134\n",
      "Epoch [69/100], Step [700/4091], Loss: 832.2433\n",
      "Epoch [69/100], Step [800/4091], Loss: 752.2435\n",
      "Epoch [69/100], Step [900/4091], Loss: 685.0453\n",
      "Epoch [69/100], Step [1000/4091], Loss: 496.5269\n",
      "Epoch [69/100], Step [1100/4091], Loss: 587.6663\n",
      "Epoch [69/100], Step [1200/4091], Loss: 645.6118\n",
      "Epoch [69/100], Step [1300/4091], Loss: 714.8378\n",
      "Epoch [69/100], Step [1400/4091], Loss: 610.5432\n",
      "Epoch [69/100], Step [1500/4091], Loss: 565.2836\n",
      "Epoch [69/100], Step [1600/4091], Loss: 702.2789\n",
      "Epoch [69/100], Step [1700/4091], Loss: 907.4929\n",
      "Epoch [69/100], Step [1800/4091], Loss: 710.8066\n",
      "Epoch [69/100], Step [1900/4091], Loss: 521.7587\n",
      "Epoch [69/100], Step [2000/4091], Loss: 618.0585\n",
      "Epoch [69/100], Step [2100/4091], Loss: 691.6244\n",
      "Epoch [69/100], Step [2200/4091], Loss: 708.1821\n",
      "Epoch [69/100], Step [2300/4091], Loss: 703.9078\n",
      "Epoch [69/100], Step [2400/4091], Loss: 791.9545\n",
      "Epoch [69/100], Step [2500/4091], Loss: 838.6073\n",
      "Epoch [69/100], Step [2600/4091], Loss: 469.1110\n",
      "Epoch [69/100], Step [2700/4091], Loss: 670.4427\n",
      "Epoch [69/100], Step [2800/4091], Loss: 703.3829\n",
      "Epoch [69/100], Step [2900/4091], Loss: 701.7315\n",
      "Epoch [69/100], Step [3000/4091], Loss: 870.3409\n",
      "Epoch [69/100], Step [3100/4091], Loss: 787.1443\n",
      "Epoch [69/100], Step [3200/4091], Loss: 634.7381\n",
      "Epoch [69/100], Step [3300/4091], Loss: 644.8895\n",
      "Epoch [69/100], Step [3400/4091], Loss: 552.6435\n",
      "Epoch [69/100], Step [3500/4091], Loss: 830.8121\n",
      "Epoch [69/100], Step [3600/4091], Loss: 619.0367\n",
      "Epoch [69/100], Step [3700/4091], Loss: 769.8569\n",
      "Epoch [69/100], Step [3800/4091], Loss: 704.9360\n",
      "Epoch [69/100], Step [3900/4091], Loss: 642.3447\n",
      "Epoch [69/100], Step [4000/4091], Loss: 656.3376\n",
      "Epoch [70/100], Step [100/4091], Loss: 657.9590\n",
      "Epoch [70/100], Step [200/4091], Loss: 835.0131\n",
      "Epoch [70/100], Step [300/4091], Loss: 550.4887\n",
      "Epoch [70/100], Step [400/4091], Loss: 605.4067\n",
      "Epoch [70/100], Step [500/4091], Loss: 703.3394\n",
      "Epoch [70/100], Step [600/4091], Loss: 484.8483\n",
      "Epoch [70/100], Step [700/4091], Loss: 474.4708\n",
      "Epoch [70/100], Step [800/4091], Loss: 613.6707\n",
      "Epoch [70/100], Step [900/4091], Loss: 699.3478\n",
      "Epoch [70/100], Step [1000/4091], Loss: 719.2595\n",
      "Epoch [70/100], Step [1100/4091], Loss: 450.7063\n",
      "Epoch [70/100], Step [1200/4091], Loss: 614.5494\n",
      "Epoch [70/100], Step [1300/4091], Loss: 954.5103\n",
      "Epoch [70/100], Step [1400/4091], Loss: 760.2879\n",
      "Epoch [70/100], Step [1500/4091], Loss: 589.4578\n",
      "Epoch [70/100], Step [1600/4091], Loss: 598.5262\n",
      "Epoch [70/100], Step [1700/4091], Loss: 635.4012\n",
      "Epoch [70/100], Step [1800/4091], Loss: 708.5009\n",
      "Epoch [70/100], Step [1900/4091], Loss: 859.3248\n",
      "Epoch [70/100], Step [2000/4091], Loss: 631.6489\n",
      "Epoch [70/100], Step [2100/4091], Loss: 520.1039\n",
      "Epoch [70/100], Step [2200/4091], Loss: 724.4065\n",
      "Epoch [70/100], Step [2300/4091], Loss: 930.6351\n",
      "Epoch [70/100], Step [2400/4091], Loss: 603.5333\n",
      "Epoch [70/100], Step [2500/4091], Loss: 581.1307\n",
      "Epoch [70/100], Step [2600/4091], Loss: 530.5688\n",
      "Epoch [70/100], Step [2700/4091], Loss: 488.9435\n",
      "Epoch [70/100], Step [2800/4091], Loss: 600.1500\n",
      "Epoch [70/100], Step [2900/4091], Loss: 541.5203\n",
      "Epoch [70/100], Step [3000/4091], Loss: 691.1326\n",
      "Epoch [70/100], Step [3100/4091], Loss: 818.3984\n",
      "Epoch [70/100], Step [3200/4091], Loss: 619.8518\n",
      "Epoch [70/100], Step [3300/4091], Loss: 680.6624\n",
      "Epoch [70/100], Step [3400/4091], Loss: 741.6970\n",
      "Epoch [70/100], Step [3500/4091], Loss: 564.2310\n",
      "Epoch [70/100], Step [3600/4091], Loss: 658.2706\n",
      "Epoch [70/100], Step [3700/4091], Loss: 544.0264\n",
      "Epoch [70/100], Step [3800/4091], Loss: 521.7148\n",
      "Epoch [70/100], Step [3900/4091], Loss: 623.6757\n",
      "Epoch [70/100], Step [4000/4091], Loss: 699.0284\n",
      "Epoch [71/100], Step [100/4091], Loss: 549.2700\n",
      "Epoch [71/100], Step [200/4091], Loss: 681.6014\n",
      "Epoch [71/100], Step [300/4091], Loss: 778.9454\n",
      "Epoch [71/100], Step [400/4091], Loss: 684.9475\n",
      "Epoch [71/100], Step [500/4091], Loss: 563.4630\n",
      "Epoch [71/100], Step [600/4091], Loss: 704.5524\n",
      "Epoch [71/100], Step [700/4091], Loss: 822.6757\n",
      "Epoch [71/100], Step [800/4091], Loss: 537.6057\n",
      "Epoch [71/100], Step [900/4091], Loss: 736.9937\n",
      "Epoch [71/100], Step [1000/4091], Loss: 686.6436\n",
      "Epoch [71/100], Step [1100/4091], Loss: 718.6605\n",
      "Epoch [71/100], Step [1200/4091], Loss: 336.7329\n",
      "Epoch [71/100], Step [1300/4091], Loss: 751.5445\n",
      "Epoch [71/100], Step [1400/4091], Loss: 659.3480\n",
      "Epoch [71/100], Step [1500/4091], Loss: 665.9253\n",
      "Epoch [71/100], Step [1600/4091], Loss: 552.9483\n",
      "Epoch [71/100], Step [1700/4091], Loss: 729.8251\n",
      "Epoch [71/100], Step [1800/4091], Loss: 862.6097\n",
      "Epoch [71/100], Step [1900/4091], Loss: 629.3480\n",
      "Epoch [71/100], Step [2000/4091], Loss: 581.3710\n",
      "Epoch [71/100], Step [2100/4091], Loss: 460.9310\n",
      "Epoch [71/100], Step [2200/4091], Loss: 571.9135\n",
      "Epoch [71/100], Step [2300/4091], Loss: 734.0029\n",
      "Epoch [71/100], Step [2400/4091], Loss: 672.5425\n",
      "Epoch [71/100], Step [2500/4091], Loss: 548.2739\n",
      "Epoch [71/100], Step [2600/4091], Loss: 607.6721\n",
      "Epoch [71/100], Step [2700/4091], Loss: 607.9694\n",
      "Epoch [71/100], Step [2800/4091], Loss: 544.1384\n",
      "Epoch [71/100], Step [2900/4091], Loss: 713.1208\n",
      "Epoch [71/100], Step [3000/4091], Loss: 587.8009\n",
      "Epoch [71/100], Step [3100/4091], Loss: 712.3285\n",
      "Epoch [71/100], Step [3200/4091], Loss: 639.1829\n",
      "Epoch [71/100], Step [3300/4091], Loss: 578.9841\n",
      "Epoch [71/100], Step [3400/4091], Loss: 814.2220\n",
      "Epoch [71/100], Step [3500/4091], Loss: 728.2106\n",
      "Epoch [71/100], Step [3600/4091], Loss: 542.4998\n",
      "Epoch [71/100], Step [3700/4091], Loss: 752.4576\n",
      "Epoch [71/100], Step [3800/4091], Loss: 719.0621\n",
      "Epoch [71/100], Step [3900/4091], Loss: 566.8890\n",
      "Epoch [71/100], Step [4000/4091], Loss: 867.9630\n",
      "Epoch [72/100], Step [100/4091], Loss: 863.1196\n",
      "Epoch [72/100], Step [200/4091], Loss: 524.0349\n",
      "Epoch [72/100], Step [300/4091], Loss: 712.7862\n",
      "Epoch [72/100], Step [400/4091], Loss: 692.2742\n",
      "Epoch [72/100], Step [500/4091], Loss: 677.8054\n",
      "Epoch [72/100], Step [600/4091], Loss: 689.9914\n",
      "Epoch [72/100], Step [700/4091], Loss: 717.1483\n",
      "Epoch [72/100], Step [800/4091], Loss: 801.7484\n",
      "Epoch [72/100], Step [900/4091], Loss: 631.4954\n",
      "Epoch [72/100], Step [1000/4091], Loss: 727.2162\n",
      "Epoch [72/100], Step [1100/4091], Loss: 700.3550\n",
      "Epoch [72/100], Step [1200/4091], Loss: 701.5042\n",
      "Epoch [72/100], Step [1300/4091], Loss: 539.6157\n",
      "Epoch [72/100], Step [1400/4091], Loss: 725.7578\n",
      "Epoch [72/100], Step [1500/4091], Loss: 544.6174\n",
      "Epoch [72/100], Step [1600/4091], Loss: 501.3517\n",
      "Epoch [72/100], Step [1700/4091], Loss: 730.5016\n",
      "Epoch [72/100], Step [1800/4091], Loss: 622.7756\n",
      "Epoch [72/100], Step [1900/4091], Loss: 730.2159\n",
      "Epoch [72/100], Step [2000/4091], Loss: 645.0283\n",
      "Epoch [72/100], Step [2100/4091], Loss: 631.2689\n",
      "Epoch [72/100], Step [2200/4091], Loss: 633.7298\n",
      "Epoch [72/100], Step [2300/4091], Loss: 725.8452\n",
      "Epoch [72/100], Step [2400/4091], Loss: 616.3264\n",
      "Epoch [72/100], Step [2500/4091], Loss: 816.9810\n",
      "Epoch [72/100], Step [2600/4091], Loss: 839.5493\n",
      "Epoch [72/100], Step [2700/4091], Loss: 561.3240\n",
      "Epoch [72/100], Step [2800/4091], Loss: 752.6678\n",
      "Epoch [72/100], Step [2900/4091], Loss: 766.7253\n",
      "Epoch [72/100], Step [3000/4091], Loss: 799.9968\n",
      "Epoch [72/100], Step [3100/4091], Loss: 673.3320\n",
      "Epoch [72/100], Step [3200/4091], Loss: 652.1357\n",
      "Epoch [72/100], Step [3300/4091], Loss: 729.6280\n",
      "Epoch [72/100], Step [3400/4091], Loss: 749.2650\n",
      "Epoch [72/100], Step [3500/4091], Loss: 693.2384\n",
      "Epoch [72/100], Step [3600/4091], Loss: 744.6809\n",
      "Epoch [72/100], Step [3700/4091], Loss: 732.8453\n",
      "Epoch [72/100], Step [3800/4091], Loss: 588.8202\n",
      "Epoch [72/100], Step [3900/4091], Loss: 662.9092\n",
      "Epoch [72/100], Step [4000/4091], Loss: 627.5561\n",
      "Epoch [73/100], Step [100/4091], Loss: 604.2870\n",
      "Epoch [73/100], Step [200/4091], Loss: 823.1124\n",
      "Epoch [73/100], Step [300/4091], Loss: 671.2487\n",
      "Epoch [73/100], Step [400/4091], Loss: 549.6984\n",
      "Epoch [73/100], Step [500/4091], Loss: 708.6252\n",
      "Epoch [73/100], Step [600/4091], Loss: 543.6163\n",
      "Epoch [73/100], Step [700/4091], Loss: 565.3605\n",
      "Epoch [73/100], Step [800/4091], Loss: 763.3636\n",
      "Epoch [73/100], Step [900/4091], Loss: 499.6530\n",
      "Epoch [73/100], Step [1000/4091], Loss: 533.8217\n",
      "Epoch [73/100], Step [1100/4091], Loss: 587.2668\n",
      "Epoch [73/100], Step [1200/4091], Loss: 624.8839\n",
      "Epoch [73/100], Step [1300/4091], Loss: 697.6726\n",
      "Epoch [73/100], Step [1400/4091], Loss: 688.8613\n",
      "Epoch [73/100], Step [1500/4091], Loss: 588.7932\n",
      "Epoch [73/100], Step [1600/4091], Loss: 682.7444\n",
      "Epoch [73/100], Step [1700/4091], Loss: 620.2446\n",
      "Epoch [73/100], Step [1800/4091], Loss: 678.3388\n",
      "Epoch [73/100], Step [1900/4091], Loss: 491.5161\n",
      "Epoch [73/100], Step [2000/4091], Loss: 614.7642\n",
      "Epoch [73/100], Step [2100/4091], Loss: 655.2693\n",
      "Epoch [73/100], Step [2200/4091], Loss: 757.9792\n",
      "Epoch [73/100], Step [2300/4091], Loss: 689.2788\n",
      "Epoch [73/100], Step [2400/4091], Loss: 580.2384\n",
      "Epoch [73/100], Step [2500/4091], Loss: 563.0375\n",
      "Epoch [73/100], Step [2600/4091], Loss: 473.1682\n",
      "Epoch [73/100], Step [2700/4091], Loss: 566.5061\n",
      "Epoch [73/100], Step [2800/4091], Loss: 655.7522\n",
      "Epoch [73/100], Step [2900/4091], Loss: 784.3002\n",
      "Epoch [73/100], Step [3000/4091], Loss: 591.7073\n",
      "Epoch [73/100], Step [3100/4091], Loss: 670.3288\n",
      "Epoch [73/100], Step [3200/4091], Loss: 559.2181\n",
      "Epoch [73/100], Step [3300/4091], Loss: 801.4128\n",
      "Epoch [73/100], Step [3400/4091], Loss: 813.2721\n",
      "Epoch [73/100], Step [3500/4091], Loss: 959.0073\n",
      "Epoch [73/100], Step [3600/4091], Loss: 759.3443\n",
      "Epoch [73/100], Step [3700/4091], Loss: 810.0081\n",
      "Epoch [73/100], Step [3800/4091], Loss: 699.5892\n",
      "Epoch [73/100], Step [3900/4091], Loss: 1019.4774\n",
      "Epoch [73/100], Step [4000/4091], Loss: 664.2241\n",
      "Epoch [74/100], Step [100/4091], Loss: 717.4692\n",
      "Epoch [74/100], Step [200/4091], Loss: 875.0609\n",
      "Epoch [74/100], Step [300/4091], Loss: 558.5141\n",
      "Epoch [74/100], Step [400/4091], Loss: 943.3022\n",
      "Epoch [74/100], Step [500/4091], Loss: 757.5323\n",
      "Epoch [74/100], Step [600/4091], Loss: 745.4814\n",
      "Epoch [74/100], Step [700/4091], Loss: 534.5270\n",
      "Epoch [74/100], Step [800/4091], Loss: 856.7398\n",
      "Epoch [74/100], Step [900/4091], Loss: 919.0728\n",
      "Epoch [74/100], Step [1000/4091], Loss: 526.5771\n",
      "Epoch [74/100], Step [1100/4091], Loss: 569.4707\n",
      "Epoch [74/100], Step [1200/4091], Loss: 624.7427\n",
      "Epoch [74/100], Step [1300/4091], Loss: 667.5289\n",
      "Epoch [74/100], Step [1400/4091], Loss: 508.0674\n",
      "Epoch [74/100], Step [1500/4091], Loss: 733.5829\n",
      "Epoch [74/100], Step [1600/4091], Loss: 636.2327\n",
      "Epoch [74/100], Step [1700/4091], Loss: 620.2283\n",
      "Epoch [74/100], Step [1800/4091], Loss: 795.6038\n",
      "Epoch [74/100], Step [1900/4091], Loss: 731.0038\n",
      "Epoch [74/100], Step [2000/4091], Loss: 682.8874\n",
      "Epoch [74/100], Step [2100/4091], Loss: 822.0311\n",
      "Epoch [74/100], Step [2200/4091], Loss: 539.9766\n",
      "Epoch [74/100], Step [2300/4091], Loss: 699.4184\n",
      "Epoch [74/100], Step [2400/4091], Loss: 657.0278\n",
      "Epoch [74/100], Step [2500/4091], Loss: 666.0065\n",
      "Epoch [74/100], Step [2600/4091], Loss: 518.6921\n",
      "Epoch [74/100], Step [2700/4091], Loss: 736.2201\n",
      "Epoch [74/100], Step [2800/4091], Loss: 532.4617\n",
      "Epoch [74/100], Step [2900/4091], Loss: 572.9540\n",
      "Epoch [74/100], Step [3000/4091], Loss: 624.1085\n",
      "Epoch [74/100], Step [3100/4091], Loss: 615.1705\n",
      "Epoch [74/100], Step [3200/4091], Loss: 576.1082\n",
      "Epoch [74/100], Step [3300/4091], Loss: 593.0840\n",
      "Epoch [74/100], Step [3400/4091], Loss: 713.2653\n",
      "Epoch [74/100], Step [3500/4091], Loss: 554.4404\n",
      "Epoch [74/100], Step [3600/4091], Loss: 677.0045\n",
      "Epoch [74/100], Step [3700/4091], Loss: 642.4102\n",
      "Epoch [74/100], Step [3800/4091], Loss: 654.2042\n",
      "Epoch [74/100], Step [3900/4091], Loss: 578.5801\n",
      "Epoch [74/100], Step [4000/4091], Loss: 447.5182\n",
      "Epoch [75/100], Step [100/4091], Loss: 946.7642\n",
      "Epoch [75/100], Step [200/4091], Loss: 1023.5551\n",
      "Epoch [75/100], Step [300/4091], Loss: 585.9343\n",
      "Epoch [75/100], Step [400/4091], Loss: 884.5112\n",
      "Epoch [75/100], Step [500/4091], Loss: 552.3604\n",
      "Epoch [75/100], Step [600/4091], Loss: 891.0652\n",
      "Epoch [75/100], Step [700/4091], Loss: 525.3234\n",
      "Epoch [75/100], Step [800/4091], Loss: 651.9814\n",
      "Epoch [75/100], Step [900/4091], Loss: 738.5526\n",
      "Epoch [75/100], Step [1000/4091], Loss: 684.0092\n",
      "Epoch [75/100], Step [1100/4091], Loss: 756.6702\n",
      "Epoch [75/100], Step [1200/4091], Loss: 533.3826\n",
      "Epoch [75/100], Step [1300/4091], Loss: 713.2296\n",
      "Epoch [75/100], Step [1400/4091], Loss: 621.8439\n",
      "Epoch [75/100], Step [1500/4091], Loss: 494.9811\n",
      "Epoch [75/100], Step [1600/4091], Loss: 713.3731\n",
      "Epoch [75/100], Step [1700/4091], Loss: 630.3350\n",
      "Epoch [75/100], Step [1800/4091], Loss: 725.1796\n",
      "Epoch [75/100], Step [1900/4091], Loss: 678.0856\n",
      "Epoch [75/100], Step [2000/4091], Loss: 703.9204\n",
      "Epoch [75/100], Step [2100/4091], Loss: 920.0560\n",
      "Epoch [75/100], Step [2200/4091], Loss: 717.0139\n",
      "Epoch [75/100], Step [2300/4091], Loss: 711.4263\n",
      "Epoch [75/100], Step [2400/4091], Loss: 584.7744\n",
      "Epoch [75/100], Step [2500/4091], Loss: 446.3071\n",
      "Epoch [75/100], Step [2600/4091], Loss: 493.4672\n",
      "Epoch [75/100], Step [2700/4091], Loss: 988.6021\n",
      "Epoch [75/100], Step [2800/4091], Loss: 725.3298\n",
      "Epoch [75/100], Step [2900/4091], Loss: 762.3985\n",
      "Epoch [75/100], Step [3000/4091], Loss: 658.4894\n",
      "Epoch [75/100], Step [3100/4091], Loss: 626.0018\n",
      "Epoch [75/100], Step [3200/4091], Loss: 713.7706\n",
      "Epoch [75/100], Step [3300/4091], Loss: 729.1336\n",
      "Epoch [75/100], Step [3400/4091], Loss: 680.1096\n",
      "Epoch [75/100], Step [3500/4091], Loss: 773.8447\n",
      "Epoch [75/100], Step [3600/4091], Loss: 602.2493\n",
      "Epoch [75/100], Step [3700/4091], Loss: 789.2027\n",
      "Epoch [75/100], Step [3800/4091], Loss: 799.1638\n",
      "Epoch [75/100], Step [3900/4091], Loss: 808.5355\n",
      "Epoch [75/100], Step [4000/4091], Loss: 624.3731\n",
      "Epoch [76/100], Step [100/4091], Loss: 703.3466\n",
      "Epoch [76/100], Step [200/4091], Loss: 868.2384\n",
      "Epoch [76/100], Step [300/4091], Loss: 726.2542\n",
      "Epoch [76/100], Step [400/4091], Loss: 806.9691\n",
      "Epoch [76/100], Step [500/4091], Loss: 597.8185\n",
      "Epoch [76/100], Step [600/4091], Loss: 699.6494\n",
      "Epoch [76/100], Step [700/4091], Loss: 593.2941\n",
      "Epoch [76/100], Step [800/4091], Loss: 652.6315\n",
      "Epoch [76/100], Step [900/4091], Loss: 548.8309\n",
      "Epoch [76/100], Step [1000/4091], Loss: 609.7292\n",
      "Epoch [76/100], Step [1100/4091], Loss: 598.2357\n",
      "Epoch [76/100], Step [1200/4091], Loss: 570.8292\n",
      "Epoch [76/100], Step [1300/4091], Loss: 796.0996\n",
      "Epoch [76/100], Step [1400/4091], Loss: 634.4976\n",
      "Epoch [76/100], Step [1500/4091], Loss: 556.1581\n",
      "Epoch [76/100], Step [1600/4091], Loss: 637.1016\n",
      "Epoch [76/100], Step [1700/4091], Loss: 672.0118\n",
      "Epoch [76/100], Step [1800/4091], Loss: 553.3365\n",
      "Epoch [76/100], Step [1900/4091], Loss: 644.8887\n",
      "Epoch [76/100], Step [2000/4091], Loss: 678.4946\n",
      "Epoch [76/100], Step [2100/4091], Loss: 841.8564\n",
      "Epoch [76/100], Step [2200/4091], Loss: 698.8849\n",
      "Epoch [76/100], Step [2300/4091], Loss: 714.0771\n",
      "Epoch [76/100], Step [2400/4091], Loss: 710.1710\n",
      "Epoch [76/100], Step [2500/4091], Loss: 741.4791\n",
      "Epoch [76/100], Step [2600/4091], Loss: 616.5948\n",
      "Epoch [76/100], Step [2700/4091], Loss: 601.8423\n",
      "Epoch [76/100], Step [2800/4091], Loss: 668.5409\n",
      "Epoch [76/100], Step [2900/4091], Loss: 733.1827\n",
      "Epoch [76/100], Step [3000/4091], Loss: 427.6172\n",
      "Epoch [76/100], Step [3100/4091], Loss: 588.3675\n",
      "Epoch [76/100], Step [3200/4091], Loss: 514.2455\n",
      "Epoch [76/100], Step [3300/4091], Loss: 682.3361\n",
      "Epoch [76/100], Step [3400/4091], Loss: 799.8338\n",
      "Epoch [76/100], Step [3500/4091], Loss: 880.1112\n",
      "Epoch [76/100], Step [3600/4091], Loss: 527.9055\n",
      "Epoch [76/100], Step [3700/4091], Loss: 523.1519\n",
      "Epoch [76/100], Step [3800/4091], Loss: 625.7496\n",
      "Epoch [76/100], Step [3900/4091], Loss: 622.8730\n",
      "Epoch [76/100], Step [4000/4091], Loss: 659.4427\n",
      "Epoch [77/100], Step [100/4091], Loss: 604.6487\n",
      "Epoch [77/100], Step [200/4091], Loss: 778.8181\n",
      "Epoch [77/100], Step [300/4091], Loss: 462.6987\n",
      "Epoch [77/100], Step [400/4091], Loss: 821.7183\n",
      "Epoch [77/100], Step [500/4091], Loss: 600.5412\n",
      "Epoch [77/100], Step [600/4091], Loss: 548.0459\n",
      "Epoch [77/100], Step [700/4091], Loss: 749.0593\n",
      "Epoch [77/100], Step [800/4091], Loss: 826.6622\n",
      "Epoch [77/100], Step [900/4091], Loss: 584.5925\n",
      "Epoch [77/100], Step [1000/4091], Loss: 948.7417\n",
      "Epoch [77/100], Step [1100/4091], Loss: 719.9156\n",
      "Epoch [77/100], Step [1200/4091], Loss: 614.0579\n",
      "Epoch [77/100], Step [1300/4091], Loss: 932.6506\n",
      "Epoch [77/100], Step [1400/4091], Loss: 774.8929\n",
      "Epoch [77/100], Step [1500/4091], Loss: 820.2450\n",
      "Epoch [77/100], Step [1600/4091], Loss: 559.8123\n",
      "Epoch [77/100], Step [1700/4091], Loss: 583.4055\n",
      "Epoch [77/100], Step [1800/4091], Loss: 433.2404\n",
      "Epoch [77/100], Step [1900/4091], Loss: 779.0341\n",
      "Epoch [77/100], Step [2000/4091], Loss: 917.3986\n",
      "Epoch [77/100], Step [2100/4091], Loss: 648.2904\n",
      "Epoch [77/100], Step [2200/4091], Loss: 607.8319\n",
      "Epoch [77/100], Step [2300/4091], Loss: 549.5338\n",
      "Epoch [77/100], Step [2400/4091], Loss: 688.5927\n",
      "Epoch [77/100], Step [2500/4091], Loss: 644.7865\n",
      "Epoch [77/100], Step [2600/4091], Loss: 525.5947\n",
      "Epoch [77/100], Step [2700/4091], Loss: 631.5524\n",
      "Epoch [77/100], Step [2800/4091], Loss: 801.8166\n",
      "Epoch [77/100], Step [2900/4091], Loss: 1083.9561\n",
      "Epoch [77/100], Step [3000/4091], Loss: 631.1764\n",
      "Epoch [77/100], Step [3100/4091], Loss: 807.6879\n",
      "Epoch [77/100], Step [3200/4091], Loss: 677.2527\n",
      "Epoch [77/100], Step [3300/4091], Loss: 696.1268\n",
      "Epoch [77/100], Step [3400/4091], Loss: 733.7859\n",
      "Epoch [77/100], Step [3500/4091], Loss: 674.4347\n",
      "Epoch [77/100], Step [3600/4091], Loss: 982.6377\n",
      "Epoch [77/100], Step [3700/4091], Loss: 599.6760\n",
      "Epoch [77/100], Step [3800/4091], Loss: 572.2132\n",
      "Epoch [77/100], Step [3900/4091], Loss: 601.4829\n",
      "Epoch [77/100], Step [4000/4091], Loss: 614.3694\n",
      "Epoch [78/100], Step [100/4091], Loss: 736.1396\n",
      "Epoch [78/100], Step [200/4091], Loss: 531.7402\n",
      "Epoch [78/100], Step [300/4091], Loss: 657.0005\n",
      "Epoch [78/100], Step [400/4091], Loss: 610.9197\n",
      "Epoch [78/100], Step [500/4091], Loss: 769.6055\n",
      "Epoch [78/100], Step [600/4091], Loss: 956.4056\n",
      "Epoch [78/100], Step [700/4091], Loss: 674.4321\n",
      "Epoch [78/100], Step [800/4091], Loss: 637.5056\n",
      "Epoch [78/100], Step [900/4091], Loss: 531.2131\n",
      "Epoch [78/100], Step [1000/4091], Loss: 612.0422\n",
      "Epoch [78/100], Step [1100/4091], Loss: 590.2230\n",
      "Epoch [78/100], Step [1200/4091], Loss: 494.2546\n",
      "Epoch [78/100], Step [1300/4091], Loss: 446.6380\n",
      "Epoch [78/100], Step [1400/4091], Loss: 587.2134\n",
      "Epoch [78/100], Step [1500/4091], Loss: 666.4669\n",
      "Epoch [78/100], Step [1600/4091], Loss: 554.3395\n",
      "Epoch [78/100], Step [1700/4091], Loss: 486.7422\n",
      "Epoch [78/100], Step [1800/4091], Loss: 707.9662\n",
      "Epoch [78/100], Step [1900/4091], Loss: 603.2378\n",
      "Epoch [78/100], Step [2000/4091], Loss: 692.0860\n",
      "Epoch [78/100], Step [2100/4091], Loss: 591.3536\n",
      "Epoch [78/100], Step [2200/4091], Loss: 560.1744\n",
      "Epoch [78/100], Step [2300/4091], Loss: 623.0620\n",
      "Epoch [78/100], Step [2400/4091], Loss: 584.5138\n",
      "Epoch [78/100], Step [2500/4091], Loss: 825.6396\n",
      "Epoch [78/100], Step [2600/4091], Loss: 750.7009\n",
      "Epoch [78/100], Step [2700/4091], Loss: 900.7999\n",
      "Epoch [78/100], Step [2800/4091], Loss: 555.4615\n",
      "Epoch [78/100], Step [2900/4091], Loss: 493.8336\n",
      "Epoch [78/100], Step [3000/4091], Loss: 634.6392\n",
      "Epoch [78/100], Step [3100/4091], Loss: 517.2875\n",
      "Epoch [78/100], Step [3200/4091], Loss: 594.8344\n",
      "Epoch [78/100], Step [3300/4091], Loss: 1081.0745\n",
      "Epoch [78/100], Step [3400/4091], Loss: 689.1669\n",
      "Epoch [78/100], Step [3500/4091], Loss: 676.6979\n",
      "Epoch [78/100], Step [3600/4091], Loss: 635.8273\n",
      "Epoch [78/100], Step [3700/4091], Loss: 636.6832\n",
      "Epoch [78/100], Step [3800/4091], Loss: 510.8621\n",
      "Epoch [78/100], Step [3900/4091], Loss: 896.8162\n",
      "Epoch [78/100], Step [4000/4091], Loss: 773.3321\n",
      "Epoch [79/100], Step [100/4091], Loss: 749.0037\n",
      "Epoch [79/100], Step [200/4091], Loss: 687.3262\n",
      "Epoch [79/100], Step [300/4091], Loss: 528.6194\n",
      "Epoch [79/100], Step [400/4091], Loss: 807.5665\n",
      "Epoch [79/100], Step [500/4091], Loss: 596.8166\n",
      "Epoch [79/100], Step [600/4091], Loss: 738.9383\n",
      "Epoch [79/100], Step [700/4091], Loss: 682.7433\n",
      "Epoch [79/100], Step [800/4091], Loss: 719.9177\n",
      "Epoch [79/100], Step [900/4091], Loss: 552.4589\n",
      "Epoch [79/100], Step [1000/4091], Loss: 664.1771\n",
      "Epoch [79/100], Step [1100/4091], Loss: 488.8030\n",
      "Epoch [79/100], Step [1200/4091], Loss: 741.2742\n",
      "Epoch [79/100], Step [1300/4091], Loss: 531.8860\n",
      "Epoch [79/100], Step [1400/4091], Loss: 818.9473\n",
      "Epoch [79/100], Step [1500/4091], Loss: 586.7928\n",
      "Epoch [79/100], Step [1600/4091], Loss: 882.6021\n",
      "Epoch [79/100], Step [1700/4091], Loss: 489.8679\n",
      "Epoch [79/100], Step [1800/4091], Loss: 726.3902\n",
      "Epoch [79/100], Step [1900/4091], Loss: 525.9998\n",
      "Epoch [79/100], Step [2000/4091], Loss: 703.8674\n",
      "Epoch [79/100], Step [2100/4091], Loss: 644.6332\n",
      "Epoch [79/100], Step [2200/4091], Loss: 692.9518\n",
      "Epoch [79/100], Step [2300/4091], Loss: 719.5615\n",
      "Epoch [79/100], Step [2400/4091], Loss: 558.5756\n",
      "Epoch [79/100], Step [2500/4091], Loss: 421.7735\n",
      "Epoch [79/100], Step [2600/4091], Loss: 701.8197\n",
      "Epoch [79/100], Step [2700/4091], Loss: 418.5095\n",
      "Epoch [79/100], Step [2800/4091], Loss: 790.7963\n",
      "Epoch [79/100], Step [2900/4091], Loss: 539.4416\n",
      "Epoch [79/100], Step [3000/4091], Loss: 537.8769\n",
      "Epoch [79/100], Step [3100/4091], Loss: 555.0558\n",
      "Epoch [79/100], Step [3200/4091], Loss: 645.6174\n",
      "Epoch [79/100], Step [3300/4091], Loss: 766.5276\n",
      "Epoch [79/100], Step [3400/4091], Loss: 700.1648\n",
      "Epoch [79/100], Step [3500/4091], Loss: 941.4667\n",
      "Epoch [79/100], Step [3600/4091], Loss: 756.9741\n",
      "Epoch [79/100], Step [3700/4091], Loss: 612.8491\n",
      "Epoch [79/100], Step [3800/4091], Loss: 640.3405\n",
      "Epoch [79/100], Step [3900/4091], Loss: 458.8826\n",
      "Epoch [79/100], Step [4000/4091], Loss: 638.5704\n",
      "Epoch [80/100], Step [100/4091], Loss: 751.5116\n",
      "Epoch [80/100], Step [200/4091], Loss: 789.6071\n",
      "Epoch [80/100], Step [300/4091], Loss: 685.5230\n",
      "Epoch [80/100], Step [400/4091], Loss: 626.1021\n",
      "Epoch [80/100], Step [500/4091], Loss: 677.1731\n",
      "Epoch [80/100], Step [600/4091], Loss: 626.0034\n",
      "Epoch [80/100], Step [700/4091], Loss: 740.8396\n",
      "Epoch [80/100], Step [800/4091], Loss: 514.4657\n",
      "Epoch [80/100], Step [900/4091], Loss: 695.3740\n",
      "Epoch [80/100], Step [1000/4091], Loss: 420.8207\n",
      "Epoch [80/100], Step [1100/4091], Loss: 615.3884\n",
      "Epoch [80/100], Step [1200/4091], Loss: 664.5895\n",
      "Epoch [80/100], Step [1300/4091], Loss: 619.5751\n",
      "Epoch [80/100], Step [1400/4091], Loss: 554.0753\n",
      "Epoch [80/100], Step [1500/4091], Loss: 703.9066\n",
      "Epoch [80/100], Step [1600/4091], Loss: 928.2057\n",
      "Epoch [80/100], Step [1700/4091], Loss: 743.3662\n",
      "Epoch [80/100], Step [1800/4091], Loss: 449.7094\n",
      "Epoch [80/100], Step [1900/4091], Loss: 610.1415\n",
      "Epoch [80/100], Step [2000/4091], Loss: 832.6528\n",
      "Epoch [80/100], Step [2100/4091], Loss: 561.0927\n",
      "Epoch [80/100], Step [2200/4091], Loss: 754.1221\n",
      "Epoch [80/100], Step [2300/4091], Loss: 799.5493\n",
      "Epoch [80/100], Step [2400/4091], Loss: 523.2538\n",
      "Epoch [80/100], Step [2500/4091], Loss: 471.7371\n",
      "Epoch [80/100], Step [2600/4091], Loss: 733.7342\n",
      "Epoch [80/100], Step [2700/4091], Loss: 705.3392\n",
      "Epoch [80/100], Step [2800/4091], Loss: 663.4980\n",
      "Epoch [80/100], Step [2900/4091], Loss: 717.6649\n",
      "Epoch [80/100], Step [3000/4091], Loss: 669.5477\n",
      "Epoch [80/100], Step [3100/4091], Loss: 759.2423\n",
      "Epoch [80/100], Step [3200/4091], Loss: 658.5106\n",
      "Epoch [80/100], Step [3300/4091], Loss: 697.3823\n",
      "Epoch [80/100], Step [3400/4091], Loss: 522.1880\n",
      "Epoch [80/100], Step [3500/4091], Loss: 1028.1392\n",
      "Epoch [80/100], Step [3600/4091], Loss: 653.6000\n",
      "Epoch [80/100], Step [3700/4091], Loss: 769.1191\n",
      "Epoch [80/100], Step [3800/4091], Loss: 613.2719\n",
      "Epoch [80/100], Step [3900/4091], Loss: 629.0152\n",
      "Epoch [80/100], Step [4000/4091], Loss: 539.0717\n",
      "Epoch [81/100], Step [100/4091], Loss: 601.5929\n",
      "Epoch [81/100], Step [200/4091], Loss: 540.8397\n",
      "Epoch [81/100], Step [300/4091], Loss: 893.0850\n",
      "Epoch [81/100], Step [400/4091], Loss: 807.4819\n",
      "Epoch [81/100], Step [500/4091], Loss: 678.0381\n",
      "Epoch [81/100], Step [600/4091], Loss: 749.3552\n",
      "Epoch [81/100], Step [700/4091], Loss: 659.9715\n",
      "Epoch [81/100], Step [800/4091], Loss: 794.6287\n",
      "Epoch [81/100], Step [900/4091], Loss: 625.8901\n",
      "Epoch [81/100], Step [1000/4091], Loss: 563.3165\n",
      "Epoch [81/100], Step [1100/4091], Loss: 461.5567\n",
      "Epoch [81/100], Step [1200/4091], Loss: 457.8150\n",
      "Epoch [81/100], Step [1300/4091], Loss: 597.7912\n",
      "Epoch [81/100], Step [1400/4091], Loss: 938.7321\n",
      "Epoch [81/100], Step [1500/4091], Loss: 934.2916\n",
      "Epoch [81/100], Step [1600/4091], Loss: 665.1600\n",
      "Epoch [81/100], Step [1700/4091], Loss: 736.4057\n",
      "Epoch [81/100], Step [1800/4091], Loss: 635.1978\n",
      "Epoch [81/100], Step [1900/4091], Loss: 614.8978\n",
      "Epoch [81/100], Step [2000/4091], Loss: 617.1616\n",
      "Epoch [81/100], Step [2100/4091], Loss: 732.7114\n",
      "Epoch [81/100], Step [2200/4091], Loss: 718.2607\n",
      "Epoch [81/100], Step [2300/4091], Loss: 512.2701\n",
      "Epoch [81/100], Step [2400/4091], Loss: 845.0706\n",
      "Epoch [81/100], Step [2500/4091], Loss: 629.9557\n",
      "Epoch [81/100], Step [2600/4091], Loss: 563.4811\n",
      "Epoch [81/100], Step [2700/4091], Loss: 816.6088\n",
      "Epoch [81/100], Step [2800/4091], Loss: 680.5446\n",
      "Epoch [81/100], Step [2900/4091], Loss: 765.3366\n",
      "Epoch [81/100], Step [3000/4091], Loss: 733.4432\n",
      "Epoch [81/100], Step [3100/4091], Loss: 706.2371\n",
      "Epoch [81/100], Step [3200/4091], Loss: 755.7214\n",
      "Epoch [81/100], Step [3300/4091], Loss: 510.0834\n",
      "Epoch [81/100], Step [3400/4091], Loss: 662.7842\n",
      "Epoch [81/100], Step [3500/4091], Loss: 464.1737\n",
      "Epoch [81/100], Step [3600/4091], Loss: 625.5560\n",
      "Epoch [81/100], Step [3700/4091], Loss: 567.6217\n",
      "Epoch [81/100], Step [3800/4091], Loss: 634.2856\n",
      "Epoch [81/100], Step [3900/4091], Loss: 718.9079\n",
      "Epoch [81/100], Step [4000/4091], Loss: 711.9873\n",
      "Epoch [82/100], Step [100/4091], Loss: 434.3777\n",
      "Epoch [82/100], Step [200/4091], Loss: 568.8740\n",
      "Epoch [82/100], Step [300/4091], Loss: 599.2870\n",
      "Epoch [82/100], Step [400/4091], Loss: 584.1683\n",
      "Epoch [82/100], Step [500/4091], Loss: 700.0416\n",
      "Epoch [82/100], Step [600/4091], Loss: 681.2734\n",
      "Epoch [82/100], Step [700/4091], Loss: 513.0007\n",
      "Epoch [82/100], Step [800/4091], Loss: 708.5995\n",
      "Epoch [82/100], Step [900/4091], Loss: 657.8823\n",
      "Epoch [82/100], Step [1000/4091], Loss: 508.0005\n",
      "Epoch [82/100], Step [1100/4091], Loss: 598.6108\n",
      "Epoch [82/100], Step [1200/4091], Loss: 613.3287\n",
      "Epoch [82/100], Step [1300/4091], Loss: 611.6691\n",
      "Epoch [82/100], Step [1400/4091], Loss: 508.3970\n",
      "Epoch [82/100], Step [1500/4091], Loss: 562.3601\n",
      "Epoch [82/100], Step [1600/4091], Loss: 598.7338\n",
      "Epoch [82/100], Step [1700/4091], Loss: 538.8203\n",
      "Epoch [82/100], Step [1800/4091], Loss: 698.5938\n",
      "Epoch [82/100], Step [1900/4091], Loss: 485.6631\n",
      "Epoch [82/100], Step [2000/4091], Loss: 855.1522\n",
      "Epoch [82/100], Step [2100/4091], Loss: 840.5532\n",
      "Epoch [82/100], Step [2200/4091], Loss: 668.1243\n",
      "Epoch [82/100], Step [2300/4091], Loss: 722.3069\n",
      "Epoch [82/100], Step [2400/4091], Loss: 536.4841\n",
      "Epoch [82/100], Step [2500/4091], Loss: 655.0403\n",
      "Epoch [82/100], Step [2600/4091], Loss: 600.3073\n",
      "Epoch [82/100], Step [2700/4091], Loss: 616.0906\n",
      "Epoch [82/100], Step [2800/4091], Loss: 736.7649\n",
      "Epoch [82/100], Step [2900/4091], Loss: 529.4886\n",
      "Epoch [82/100], Step [3000/4091], Loss: 625.1348\n",
      "Epoch [82/100], Step [3100/4091], Loss: 700.5807\n",
      "Epoch [82/100], Step [3200/4091], Loss: 534.3655\n",
      "Epoch [82/100], Step [3300/4091], Loss: 667.1783\n",
      "Epoch [82/100], Step [3400/4091], Loss: 825.2125\n",
      "Epoch [82/100], Step [3500/4091], Loss: 438.5078\n",
      "Epoch [82/100], Step [3600/4091], Loss: 897.2548\n",
      "Epoch [82/100], Step [3700/4091], Loss: 688.0428\n",
      "Epoch [82/100], Step [3800/4091], Loss: 661.1200\n",
      "Epoch [82/100], Step [3900/4091], Loss: 582.5893\n",
      "Epoch [82/100], Step [4000/4091], Loss: 459.4763\n",
      "Epoch [83/100], Step [100/4091], Loss: 849.0101\n",
      "Epoch [83/100], Step [200/4091], Loss: 766.6626\n",
      "Epoch [83/100], Step [300/4091], Loss: 886.2972\n",
      "Epoch [83/100], Step [400/4091], Loss: 463.4575\n",
      "Epoch [83/100], Step [500/4091], Loss: 826.4225\n",
      "Epoch [83/100], Step [600/4091], Loss: 520.3215\n",
      "Epoch [83/100], Step [700/4091], Loss: 501.5989\n",
      "Epoch [83/100], Step [800/4091], Loss: 451.3969\n",
      "Epoch [83/100], Step [900/4091], Loss: 717.7875\n",
      "Epoch [83/100], Step [1000/4091], Loss: 715.2615\n",
      "Epoch [83/100], Step [1100/4091], Loss: 993.4096\n",
      "Epoch [83/100], Step [1200/4091], Loss: 780.8676\n",
      "Epoch [83/100], Step [1300/4091], Loss: 496.1231\n",
      "Epoch [83/100], Step [1400/4091], Loss: 531.0188\n",
      "Epoch [83/100], Step [1500/4091], Loss: 560.6860\n",
      "Epoch [83/100], Step [1600/4091], Loss: 966.5049\n",
      "Epoch [83/100], Step [1700/4091], Loss: 493.9453\n",
      "Epoch [83/100], Step [1800/4091], Loss: 526.0301\n",
      "Epoch [83/100], Step [1900/4091], Loss: 746.3911\n",
      "Epoch [83/100], Step [2000/4091], Loss: 676.3969\n",
      "Epoch [83/100], Step [2100/4091], Loss: 851.6827\n",
      "Epoch [83/100], Step [2200/4091], Loss: 489.2957\n",
      "Epoch [83/100], Step [2300/4091], Loss: 647.0573\n",
      "Epoch [83/100], Step [2400/4091], Loss: 594.3736\n",
      "Epoch [83/100], Step [2500/4091], Loss: 637.6674\n",
      "Epoch [83/100], Step [2600/4091], Loss: 553.5829\n",
      "Epoch [83/100], Step [2700/4091], Loss: 643.7366\n",
      "Epoch [83/100], Step [2800/4091], Loss: 553.1750\n",
      "Epoch [83/100], Step [2900/4091], Loss: 865.5685\n",
      "Epoch [83/100], Step [3000/4091], Loss: 713.3962\n",
      "Epoch [83/100], Step [3100/4091], Loss: 740.7512\n",
      "Epoch [83/100], Step [3200/4091], Loss: 663.4675\n",
      "Epoch [83/100], Step [3300/4091], Loss: 899.2085\n",
      "Epoch [83/100], Step [3400/4091], Loss: 482.9043\n",
      "Epoch [83/100], Step [3500/4091], Loss: 615.5849\n",
      "Epoch [83/100], Step [3600/4091], Loss: 749.2710\n",
      "Epoch [83/100], Step [3700/4091], Loss: 526.7244\n",
      "Epoch [83/100], Step [3800/4091], Loss: 585.0643\n",
      "Epoch [83/100], Step [3900/4091], Loss: 666.9902\n",
      "Epoch [83/100], Step [4000/4091], Loss: 836.3284\n",
      "Epoch [84/100], Step [100/4091], Loss: 565.4744\n",
      "Epoch [84/100], Step [200/4091], Loss: 809.5208\n",
      "Epoch [84/100], Step [300/4091], Loss: 595.7515\n",
      "Epoch [84/100], Step [400/4091], Loss: 705.1265\n",
      "Epoch [84/100], Step [500/4091], Loss: 720.4835\n",
      "Epoch [84/100], Step [600/4091], Loss: 829.8798\n",
      "Epoch [84/100], Step [700/4091], Loss: 673.9689\n",
      "Epoch [84/100], Step [800/4091], Loss: 560.8026\n",
      "Epoch [84/100], Step [900/4091], Loss: 508.1189\n",
      "Epoch [84/100], Step [1000/4091], Loss: 711.0745\n",
      "Epoch [84/100], Step [1100/4091], Loss: 568.0397\n",
      "Epoch [84/100], Step [1200/4091], Loss: 525.3184\n",
      "Epoch [84/100], Step [1300/4091], Loss: 534.5203\n",
      "Epoch [84/100], Step [1400/4091], Loss: 686.6723\n",
      "Epoch [84/100], Step [1500/4091], Loss: 846.5455\n",
      "Epoch [84/100], Step [1600/4091], Loss: 711.0511\n",
      "Epoch [84/100], Step [1700/4091], Loss: 709.8880\n",
      "Epoch [84/100], Step [1800/4091], Loss: 449.9500\n",
      "Epoch [84/100], Step [1900/4091], Loss: 649.4691\n",
      "Epoch [84/100], Step [2000/4091], Loss: 662.5406\n",
      "Epoch [84/100], Step [2100/4091], Loss: 884.2449\n",
      "Epoch [84/100], Step [2200/4091], Loss: 423.9897\n",
      "Epoch [84/100], Step [2300/4091], Loss: 749.4441\n",
      "Epoch [84/100], Step [2400/4091], Loss: 731.0636\n",
      "Epoch [84/100], Step [2500/4091], Loss: 866.9299\n",
      "Epoch [84/100], Step [2600/4091], Loss: 762.0552\n",
      "Epoch [84/100], Step [2700/4091], Loss: 981.4379\n",
      "Epoch [84/100], Step [2800/4091], Loss: 833.4393\n",
      "Epoch [84/100], Step [2900/4091], Loss: 674.2645\n",
      "Epoch [84/100], Step [3000/4091], Loss: 829.6809\n",
      "Epoch [84/100], Step [3100/4091], Loss: 783.2772\n",
      "Epoch [84/100], Step [3200/4091], Loss: 720.5397\n",
      "Epoch [84/100], Step [3300/4091], Loss: 675.8728\n",
      "Epoch [84/100], Step [3400/4091], Loss: 657.9099\n",
      "Epoch [84/100], Step [3500/4091], Loss: 665.9869\n",
      "Epoch [84/100], Step [3600/4091], Loss: 814.8765\n",
      "Epoch [84/100], Step [3700/4091], Loss: 726.4968\n",
      "Epoch [84/100], Step [3800/4091], Loss: 706.8436\n",
      "Epoch [84/100], Step [3900/4091], Loss: 860.0523\n",
      "Epoch [84/100], Step [4000/4091], Loss: 770.0648\n",
      "Epoch [85/100], Step [100/4091], Loss: 521.2258\n",
      "Epoch [85/100], Step [200/4091], Loss: 508.1898\n",
      "Epoch [85/100], Step [300/4091], Loss: 464.1920\n",
      "Epoch [85/100], Step [400/4091], Loss: 626.7043\n",
      "Epoch [85/100], Step [500/4091], Loss: 600.7407\n",
      "Epoch [85/100], Step [600/4091], Loss: 554.9210\n",
      "Epoch [85/100], Step [700/4091], Loss: 851.3765\n",
      "Epoch [85/100], Step [800/4091], Loss: 743.7337\n",
      "Epoch [85/100], Step [900/4091], Loss: 775.8683\n",
      "Epoch [85/100], Step [1000/4091], Loss: 843.7801\n",
      "Epoch [85/100], Step [1100/4091], Loss: 869.7777\n",
      "Epoch [85/100], Step [1200/4091], Loss: 758.4187\n",
      "Epoch [85/100], Step [1300/4091], Loss: 607.6357\n",
      "Epoch [85/100], Step [1400/4091], Loss: 642.8569\n",
      "Epoch [85/100], Step [1500/4091], Loss: 624.2113\n",
      "Epoch [85/100], Step [1600/4091], Loss: 716.8253\n",
      "Epoch [85/100], Step [1700/4091], Loss: 685.8652\n",
      "Epoch [85/100], Step [1800/4091], Loss: 538.3073\n",
      "Epoch [85/100], Step [1900/4091], Loss: 606.6708\n",
      "Epoch [85/100], Step [2000/4091], Loss: 466.3651\n",
      "Epoch [85/100], Step [2100/4091], Loss: 930.0275\n",
      "Epoch [85/100], Step [2200/4091], Loss: 678.2540\n",
      "Epoch [85/100], Step [2300/4091], Loss: 577.0810\n",
      "Epoch [85/100], Step [2400/4091], Loss: 567.5938\n",
      "Epoch [85/100], Step [2500/4091], Loss: 651.4659\n",
      "Epoch [85/100], Step [2600/4091], Loss: 581.9911\n",
      "Epoch [85/100], Step [2700/4091], Loss: 866.2650\n",
      "Epoch [85/100], Step [2800/4091], Loss: 661.5807\n",
      "Epoch [85/100], Step [2900/4091], Loss: 725.8196\n",
      "Epoch [85/100], Step [3000/4091], Loss: 746.1865\n",
      "Epoch [85/100], Step [3100/4091], Loss: 606.3687\n",
      "Epoch [85/100], Step [3200/4091], Loss: 728.9580\n",
      "Epoch [85/100], Step [3300/4091], Loss: 767.7473\n",
      "Epoch [85/100], Step [3400/4091], Loss: 552.9059\n",
      "Epoch [85/100], Step [3500/4091], Loss: 614.7758\n",
      "Epoch [85/100], Step [3600/4091], Loss: 714.0074\n",
      "Epoch [85/100], Step [3700/4091], Loss: 581.4523\n",
      "Epoch [85/100], Step [3800/4091], Loss: 855.5524\n",
      "Epoch [85/100], Step [3900/4091], Loss: 628.4644\n",
      "Epoch [85/100], Step [4000/4091], Loss: 635.2339\n",
      "Epoch [86/100], Step [100/4091], Loss: 537.6698\n",
      "Epoch [86/100], Step [200/4091], Loss: 737.6705\n",
      "Epoch [86/100], Step [300/4091], Loss: 560.6088\n",
      "Epoch [86/100], Step [400/4091], Loss: 737.2962\n",
      "Epoch [86/100], Step [500/4091], Loss: 665.1776\n",
      "Epoch [86/100], Step [600/4091], Loss: 543.3729\n",
      "Epoch [86/100], Step [700/4091], Loss: 546.3292\n",
      "Epoch [86/100], Step [800/4091], Loss: 651.6986\n",
      "Epoch [86/100], Step [900/4091], Loss: 771.6116\n",
      "Epoch [86/100], Step [1000/4091], Loss: 609.1503\n",
      "Epoch [86/100], Step [1100/4091], Loss: 783.4217\n",
      "Epoch [86/100], Step [1200/4091], Loss: 608.6764\n",
      "Epoch [86/100], Step [1300/4091], Loss: 403.1082\n",
      "Epoch [86/100], Step [1400/4091], Loss: 874.7778\n",
      "Epoch [86/100], Step [1500/4091], Loss: 584.7252\n",
      "Epoch [86/100], Step [1600/4091], Loss: 759.9372\n",
      "Epoch [86/100], Step [1700/4091], Loss: 517.1464\n",
      "Epoch [86/100], Step [1800/4091], Loss: 758.4189\n",
      "Epoch [86/100], Step [1900/4091], Loss: 590.8547\n",
      "Epoch [86/100], Step [2000/4091], Loss: 568.2584\n",
      "Epoch [86/100], Step [2100/4091], Loss: 853.6025\n",
      "Epoch [86/100], Step [2200/4091], Loss: 641.0457\n",
      "Epoch [86/100], Step [2300/4091], Loss: 547.0657\n",
      "Epoch [86/100], Step [2400/4091], Loss: 701.4235\n",
      "Epoch [86/100], Step [2500/4091], Loss: 578.0989\n",
      "Epoch [86/100], Step [2600/4091], Loss: 603.4324\n",
      "Epoch [86/100], Step [2700/4091], Loss: 509.2141\n",
      "Epoch [86/100], Step [2800/4091], Loss: 805.7945\n",
      "Epoch [86/100], Step [2900/4091], Loss: 730.2467\n",
      "Epoch [86/100], Step [3000/4091], Loss: 702.2330\n",
      "Epoch [86/100], Step [3100/4091], Loss: 738.6177\n",
      "Epoch [86/100], Step [3200/4091], Loss: 694.8065\n",
      "Epoch [86/100], Step [3300/4091], Loss: 546.8541\n",
      "Epoch [86/100], Step [3400/4091], Loss: 782.4169\n",
      "Epoch [86/100], Step [3500/4091], Loss: 698.2908\n",
      "Epoch [86/100], Step [3600/4091], Loss: 486.7936\n",
      "Epoch [86/100], Step [3700/4091], Loss: 762.5922\n",
      "Epoch [86/100], Step [3800/4091], Loss: 585.8702\n",
      "Epoch [86/100], Step [3900/4091], Loss: 792.4072\n",
      "Epoch [86/100], Step [4000/4091], Loss: 580.2288\n",
      "Epoch [87/100], Step [100/4091], Loss: 628.0626\n",
      "Epoch [87/100], Step [200/4091], Loss: 711.7312\n",
      "Epoch [87/100], Step [300/4091], Loss: 727.4554\n",
      "Epoch [87/100], Step [400/4091], Loss: 587.4154\n",
      "Epoch [87/100], Step [500/4091], Loss: 838.6617\n",
      "Epoch [87/100], Step [600/4091], Loss: 649.7223\n",
      "Epoch [87/100], Step [700/4091], Loss: 650.2693\n",
      "Epoch [87/100], Step [800/4091], Loss: 658.1304\n",
      "Epoch [87/100], Step [900/4091], Loss: 433.8473\n",
      "Epoch [87/100], Step [1000/4091], Loss: 814.2064\n",
      "Epoch [87/100], Step [1100/4091], Loss: 543.5547\n",
      "Epoch [87/100], Step [1200/4091], Loss: 676.5739\n",
      "Epoch [87/100], Step [1300/4091], Loss: 524.4888\n",
      "Epoch [87/100], Step [1400/4091], Loss: 611.4202\n",
      "Epoch [87/100], Step [1500/4091], Loss: 540.0847\n",
      "Epoch [87/100], Step [1600/4091], Loss: 526.7090\n",
      "Epoch [87/100], Step [1700/4091], Loss: 763.4971\n",
      "Epoch [87/100], Step [1800/4091], Loss: 723.3476\n",
      "Epoch [87/100], Step [1900/4091], Loss: 587.4157\n",
      "Epoch [87/100], Step [2000/4091], Loss: 617.0372\n",
      "Epoch [87/100], Step [2100/4091], Loss: 793.8270\n",
      "Epoch [87/100], Step [2200/4091], Loss: 749.0300\n",
      "Epoch [87/100], Step [2300/4091], Loss: 477.6749\n",
      "Epoch [87/100], Step [2400/4091], Loss: 643.5535\n",
      "Epoch [87/100], Step [2500/4091], Loss: 559.3099\n",
      "Epoch [87/100], Step [2600/4091], Loss: 470.4175\n",
      "Epoch [87/100], Step [2700/4091], Loss: 614.2969\n",
      "Epoch [87/100], Step [2800/4091], Loss: 823.1989\n",
      "Epoch [87/100], Step [2900/4091], Loss: 488.7150\n",
      "Epoch [87/100], Step [3000/4091], Loss: 403.8841\n",
      "Epoch [87/100], Step [3100/4091], Loss: 784.7487\n",
      "Epoch [87/100], Step [3200/4091], Loss: 582.9442\n",
      "Epoch [87/100], Step [3300/4091], Loss: 638.1536\n",
      "Epoch [87/100], Step [3400/4091], Loss: 533.3894\n",
      "Epoch [87/100], Step [3500/4091], Loss: 663.8163\n",
      "Epoch [87/100], Step [3600/4091], Loss: 642.2657\n",
      "Epoch [87/100], Step [3700/4091], Loss: 693.5557\n",
      "Epoch [87/100], Step [3800/4091], Loss: 629.8776\n",
      "Epoch [87/100], Step [3900/4091], Loss: 760.7112\n",
      "Epoch [87/100], Step [4000/4091], Loss: 739.2605\n",
      "Epoch [88/100], Step [100/4091], Loss: 720.9547\n",
      "Epoch [88/100], Step [200/4091], Loss: 596.4016\n",
      "Epoch [88/100], Step [300/4091], Loss: 740.4219\n",
      "Epoch [88/100], Step [400/4091], Loss: 659.5704\n",
      "Epoch [88/100], Step [500/4091], Loss: 678.8058\n",
      "Epoch [88/100], Step [600/4091], Loss: 573.6558\n",
      "Epoch [88/100], Step [700/4091], Loss: 604.2152\n",
      "Epoch [88/100], Step [800/4091], Loss: 510.5358\n",
      "Epoch [88/100], Step [900/4091], Loss: 522.3452\n",
      "Epoch [88/100], Step [1000/4091], Loss: 700.6019\n",
      "Epoch [88/100], Step [1100/4091], Loss: 553.6780\n",
      "Epoch [88/100], Step [1200/4091], Loss: 684.0773\n",
      "Epoch [88/100], Step [1300/4091], Loss: 724.2958\n",
      "Epoch [88/100], Step [1400/4091], Loss: 722.5281\n",
      "Epoch [88/100], Step [1500/4091], Loss: 453.0672\n",
      "Epoch [88/100], Step [1600/4091], Loss: 575.0856\n",
      "Epoch [88/100], Step [1700/4091], Loss: 655.1319\n",
      "Epoch [88/100], Step [1800/4091], Loss: 753.1835\n",
      "Epoch [88/100], Step [1900/4091], Loss: 811.0928\n",
      "Epoch [88/100], Step [2000/4091], Loss: 566.9286\n",
      "Epoch [88/100], Step [2100/4091], Loss: 683.5097\n",
      "Epoch [88/100], Step [2200/4091], Loss: 727.4540\n",
      "Epoch [88/100], Step [2300/4091], Loss: 679.0856\n",
      "Epoch [88/100], Step [2400/4091], Loss: 662.5203\n",
      "Epoch [88/100], Step [2500/4091], Loss: 631.8928\n",
      "Epoch [88/100], Step [2600/4091], Loss: 852.3588\n",
      "Epoch [88/100], Step [2700/4091], Loss: 665.3774\n",
      "Epoch [88/100], Step [2800/4091], Loss: 657.3814\n",
      "Epoch [88/100], Step [2900/4091], Loss: 639.8944\n",
      "Epoch [88/100], Step [3000/4091], Loss: 539.0692\n",
      "Epoch [88/100], Step [3100/4091], Loss: 724.3843\n",
      "Epoch [88/100], Step [3200/4091], Loss: 718.1002\n",
      "Epoch [88/100], Step [3300/4091], Loss: 946.5927\n",
      "Epoch [88/100], Step [3400/4091], Loss: 721.2413\n",
      "Epoch [88/100], Step [3500/4091], Loss: 665.4806\n",
      "Epoch [88/100], Step [3600/4091], Loss: 724.1627\n",
      "Epoch [88/100], Step [3700/4091], Loss: 678.0701\n",
      "Epoch [88/100], Step [3800/4091], Loss: 772.4888\n",
      "Epoch [88/100], Step [3900/4091], Loss: 686.7072\n",
      "Epoch [88/100], Step [4000/4091], Loss: 1018.3461\n",
      "Epoch [89/100], Step [100/4091], Loss: 505.5106\n",
      "Epoch [89/100], Step [200/4091], Loss: 780.8086\n",
      "Epoch [89/100], Step [300/4091], Loss: 684.3414\n",
      "Epoch [89/100], Step [400/4091], Loss: 629.7456\n",
      "Epoch [89/100], Step [500/4091], Loss: 766.3079\n",
      "Epoch [89/100], Step [600/4091], Loss: 959.5942\n",
      "Epoch [89/100], Step [700/4091], Loss: 889.3276\n",
      "Epoch [89/100], Step [800/4091], Loss: 901.4191\n",
      "Epoch [89/100], Step [900/4091], Loss: 836.4830\n",
      "Epoch [89/100], Step [1000/4091], Loss: 790.4246\n",
      "Epoch [89/100], Step [1100/4091], Loss: 439.0289\n",
      "Epoch [89/100], Step [1200/4091], Loss: 610.9046\n",
      "Epoch [89/100], Step [1300/4091], Loss: 688.4435\n",
      "Epoch [89/100], Step [1400/4091], Loss: 1023.6092\n",
      "Epoch [89/100], Step [1500/4091], Loss: 779.4845\n",
      "Epoch [89/100], Step [1600/4091], Loss: 608.4344\n",
      "Epoch [89/100], Step [1700/4091], Loss: 762.4549\n",
      "Epoch [89/100], Step [1800/4091], Loss: 758.0692\n",
      "Epoch [89/100], Step [1900/4091], Loss: 480.6165\n",
      "Epoch [89/100], Step [2000/4091], Loss: 610.7698\n",
      "Epoch [89/100], Step [2100/4091], Loss: 774.4852\n",
      "Epoch [89/100], Step [2200/4091], Loss: 795.2719\n",
      "Epoch [89/100], Step [2300/4091], Loss: 855.7548\n",
      "Epoch [89/100], Step [2400/4091], Loss: 715.0096\n",
      "Epoch [89/100], Step [2500/4091], Loss: 728.1113\n",
      "Epoch [89/100], Step [2600/4091], Loss: 495.1488\n",
      "Epoch [89/100], Step [2700/4091], Loss: 601.6017\n",
      "Epoch [89/100], Step [2800/4091], Loss: 786.6119\n",
      "Epoch [89/100], Step [2900/4091], Loss: 808.3667\n",
      "Epoch [89/100], Step [3000/4091], Loss: 581.7402\n",
      "Epoch [89/100], Step [3100/4091], Loss: 535.8042\n",
      "Epoch [89/100], Step [3200/4091], Loss: 622.5250\n",
      "Epoch [89/100], Step [3300/4091], Loss: 846.8727\n",
      "Epoch [89/100], Step [3400/4091], Loss: 864.6503\n",
      "Epoch [89/100], Step [3500/4091], Loss: 837.8630\n",
      "Epoch [89/100], Step [3600/4091], Loss: 689.0229\n",
      "Epoch [89/100], Step [3700/4091], Loss: 378.8618\n",
      "Epoch [89/100], Step [3800/4091], Loss: 564.0555\n",
      "Epoch [89/100], Step [3900/4091], Loss: 458.0029\n",
      "Epoch [89/100], Step [4000/4091], Loss: 615.8054\n",
      "Epoch [90/100], Step [100/4091], Loss: 808.1116\n",
      "Epoch [90/100], Step [200/4091], Loss: 721.7399\n",
      "Epoch [90/100], Step [300/4091], Loss: 810.1134\n",
      "Epoch [90/100], Step [400/4091], Loss: 673.9058\n",
      "Epoch [90/100], Step [500/4091], Loss: 689.7194\n",
      "Epoch [90/100], Step [600/4091], Loss: 851.0199\n",
      "Epoch [90/100], Step [700/4091], Loss: 580.7913\n",
      "Epoch [90/100], Step [800/4091], Loss: 843.8408\n",
      "Epoch [90/100], Step [900/4091], Loss: 626.2275\n",
      "Epoch [90/100], Step [1000/4091], Loss: 646.9633\n",
      "Epoch [90/100], Step [1100/4091], Loss: 856.4557\n",
      "Epoch [90/100], Step [1200/4091], Loss: 780.3100\n",
      "Epoch [90/100], Step [1300/4091], Loss: 733.6202\n",
      "Epoch [90/100], Step [1400/4091], Loss: 713.1729\n",
      "Epoch [90/100], Step [1500/4091], Loss: 727.5656\n",
      "Epoch [90/100], Step [1600/4091], Loss: 721.6318\n",
      "Epoch [90/100], Step [1700/4091], Loss: 727.7698\n",
      "Epoch [90/100], Step [1800/4091], Loss: 498.0691\n",
      "Epoch [90/100], Step [1900/4091], Loss: 502.9127\n",
      "Epoch [90/100], Step [2000/4091], Loss: 642.9529\n",
      "Epoch [90/100], Step [2100/4091], Loss: 527.4693\n",
      "Epoch [90/100], Step [2200/4091], Loss: 789.8950\n",
      "Epoch [90/100], Step [2300/4091], Loss: 635.4418\n",
      "Epoch [90/100], Step [2400/4091], Loss: 511.8491\n",
      "Epoch [90/100], Step [2500/4091], Loss: 746.3756\n",
      "Epoch [90/100], Step [2600/4091], Loss: 802.1156\n",
      "Epoch [90/100], Step [2700/4091], Loss: 452.0830\n",
      "Epoch [90/100], Step [2800/4091], Loss: 543.4102\n",
      "Epoch [90/100], Step [2900/4091], Loss: 501.5659\n",
      "Epoch [90/100], Step [3000/4091], Loss: 771.9960\n",
      "Epoch [90/100], Step [3100/4091], Loss: 629.4847\n",
      "Epoch [90/100], Step [3200/4091], Loss: 791.5630\n",
      "Epoch [90/100], Step [3300/4091], Loss: 824.1990\n",
      "Epoch [90/100], Step [3400/4091], Loss: 759.1122\n",
      "Epoch [90/100], Step [3500/4091], Loss: 526.4594\n",
      "Epoch [90/100], Step [3600/4091], Loss: 788.0186\n",
      "Epoch [90/100], Step [3700/4091], Loss: 658.8562\n",
      "Epoch [90/100], Step [3800/4091], Loss: 964.8852\n",
      "Epoch [90/100], Step [3900/4091], Loss: 607.8480\n",
      "Epoch [90/100], Step [4000/4091], Loss: 426.1787\n",
      "Epoch [91/100], Step [100/4091], Loss: 534.8983\n",
      "Epoch [91/100], Step [200/4091], Loss: 672.3740\n",
      "Epoch [91/100], Step [300/4091], Loss: 582.1585\n",
      "Epoch [91/100], Step [400/4091], Loss: 643.0370\n",
      "Epoch [91/100], Step [500/4091], Loss: 767.9636\n",
      "Epoch [91/100], Step [600/4091], Loss: 695.9266\n",
      "Epoch [91/100], Step [700/4091], Loss: 502.7665\n",
      "Epoch [91/100], Step [800/4091], Loss: 494.5357\n",
      "Epoch [91/100], Step [900/4091], Loss: 639.3383\n",
      "Epoch [91/100], Step [1000/4091], Loss: 621.1530\n",
      "Epoch [91/100], Step [1100/4091], Loss: 545.0515\n",
      "Epoch [91/100], Step [1200/4091], Loss: 446.5403\n",
      "Epoch [91/100], Step [1300/4091], Loss: 638.3417\n",
      "Epoch [91/100], Step [1400/4091], Loss: 783.6000\n",
      "Epoch [91/100], Step [1500/4091], Loss: 623.0063\n",
      "Epoch [91/100], Step [1600/4091], Loss: 509.3849\n",
      "Epoch [91/100], Step [1700/4091], Loss: 621.9572\n",
      "Epoch [91/100], Step [1800/4091], Loss: 592.6707\n",
      "Epoch [91/100], Step [1900/4091], Loss: 523.0173\n",
      "Epoch [91/100], Step [2000/4091], Loss: 596.7747\n",
      "Epoch [91/100], Step [2100/4091], Loss: 711.2455\n",
      "Epoch [91/100], Step [2200/4091], Loss: 623.1948\n",
      "Epoch [91/100], Step [2300/4091], Loss: 633.5540\n",
      "Epoch [91/100], Step [2400/4091], Loss: 727.7899\n",
      "Epoch [91/100], Step [2500/4091], Loss: 565.8387\n",
      "Epoch [91/100], Step [2600/4091], Loss: 469.6981\n",
      "Epoch [91/100], Step [2700/4091], Loss: 665.4149\n",
      "Epoch [91/100], Step [2800/4091], Loss: 499.4767\n",
      "Epoch [91/100], Step [2900/4091], Loss: 754.6107\n",
      "Epoch [91/100], Step [3000/4091], Loss: 655.0890\n",
      "Epoch [91/100], Step [3100/4091], Loss: 454.3175\n",
      "Epoch [91/100], Step [3200/4091], Loss: 857.9357\n",
      "Epoch [91/100], Step [3300/4091], Loss: 780.5813\n",
      "Epoch [91/100], Step [3400/4091], Loss: 768.7732\n",
      "Epoch [91/100], Step [3500/4091], Loss: 462.4144\n",
      "Epoch [91/100], Step [3600/4091], Loss: 764.8751\n",
      "Epoch [91/100], Step [3700/4091], Loss: 791.5859\n",
      "Epoch [91/100], Step [3800/4091], Loss: 747.1751\n",
      "Epoch [91/100], Step [3900/4091], Loss: 545.8619\n",
      "Epoch [91/100], Step [4000/4091], Loss: 847.6835\n",
      "Epoch [92/100], Step [100/4091], Loss: 543.8270\n",
      "Epoch [92/100], Step [200/4091], Loss: 610.9827\n",
      "Epoch [92/100], Step [300/4091], Loss: 607.0393\n",
      "Epoch [92/100], Step [400/4091], Loss: 590.7137\n",
      "Epoch [92/100], Step [500/4091], Loss: 600.2949\n",
      "Epoch [92/100], Step [600/4091], Loss: 582.7919\n",
      "Epoch [92/100], Step [700/4091], Loss: 401.8125\n",
      "Epoch [92/100], Step [800/4091], Loss: 426.7038\n",
      "Epoch [92/100], Step [900/4091], Loss: 540.9310\n",
      "Epoch [92/100], Step [1000/4091], Loss: 521.2031\n",
      "Epoch [92/100], Step [1100/4091], Loss: 596.9130\n",
      "Epoch [92/100], Step [1200/4091], Loss: 746.9175\n",
      "Epoch [92/100], Step [1300/4091], Loss: 569.9440\n",
      "Epoch [92/100], Step [1400/4091], Loss: 763.3217\n",
      "Epoch [92/100], Step [1500/4091], Loss: 360.5388\n",
      "Epoch [92/100], Step [1600/4091], Loss: 693.9464\n",
      "Epoch [92/100], Step [1700/4091], Loss: 703.4774\n",
      "Epoch [92/100], Step [1800/4091], Loss: 485.9734\n",
      "Epoch [92/100], Step [1900/4091], Loss: 616.7317\n",
      "Epoch [92/100], Step [2000/4091], Loss: 875.8038\n",
      "Epoch [92/100], Step [2100/4091], Loss: 816.9277\n",
      "Epoch [92/100], Step [2200/4091], Loss: 370.6954\n",
      "Epoch [92/100], Step [2300/4091], Loss: 1147.8264\n",
      "Epoch [92/100], Step [2400/4091], Loss: 880.7487\n",
      "Epoch [92/100], Step [2500/4091], Loss: 507.5176\n",
      "Epoch [92/100], Step [2600/4091], Loss: 861.8564\n",
      "Epoch [92/100], Step [2700/4091], Loss: 566.0883\n",
      "Epoch [92/100], Step [2800/4091], Loss: 619.6390\n",
      "Epoch [92/100], Step [2900/4091], Loss: 768.2481\n",
      "Epoch [92/100], Step [3000/4091], Loss: 608.7629\n",
      "Epoch [92/100], Step [3100/4091], Loss: 847.3860\n",
      "Epoch [92/100], Step [3200/4091], Loss: 662.2817\n",
      "Epoch [92/100], Step [3300/4091], Loss: 643.9611\n",
      "Epoch [92/100], Step [3400/4091], Loss: 723.3484\n",
      "Epoch [92/100], Step [3500/4091], Loss: 545.9224\n",
      "Epoch [92/100], Step [3600/4091], Loss: 574.4617\n",
      "Epoch [92/100], Step [3700/4091], Loss: 685.3624\n",
      "Epoch [92/100], Step [3800/4091], Loss: 724.8760\n",
      "Epoch [92/100], Step [3900/4091], Loss: 866.8192\n",
      "Epoch [92/100], Step [4000/4091], Loss: 735.1401\n",
      "Epoch [93/100], Step [100/4091], Loss: 696.3014\n",
      "Epoch [93/100], Step [200/4091], Loss: 682.8468\n",
      "Epoch [93/100], Step [300/4091], Loss: 674.7385\n",
      "Epoch [93/100], Step [400/4091], Loss: 718.9431\n",
      "Epoch [93/100], Step [500/4091], Loss: 801.3961\n",
      "Epoch [93/100], Step [600/4091], Loss: 578.7047\n",
      "Epoch [93/100], Step [700/4091], Loss: 651.6107\n",
      "Epoch [93/100], Step [800/4091], Loss: 496.3764\n",
      "Epoch [93/100], Step [900/4091], Loss: 575.2545\n",
      "Epoch [93/100], Step [1000/4091], Loss: 567.7022\n",
      "Epoch [93/100], Step [1100/4091], Loss: 639.7438\n",
      "Epoch [93/100], Step [1200/4091], Loss: 759.6976\n",
      "Epoch [93/100], Step [1300/4091], Loss: 756.9434\n",
      "Epoch [93/100], Step [1400/4091], Loss: 757.5510\n",
      "Epoch [93/100], Step [1500/4091], Loss: 573.6824\n",
      "Epoch [93/100], Step [1600/4091], Loss: 1054.0125\n",
      "Epoch [93/100], Step [1700/4091], Loss: 779.1184\n",
      "Epoch [93/100], Step [1800/4091], Loss: 619.6429\n",
      "Epoch [93/100], Step [1900/4091], Loss: 676.2084\n",
      "Epoch [93/100], Step [2000/4091], Loss: 595.5822\n",
      "Epoch [93/100], Step [2100/4091], Loss: 615.5945\n",
      "Epoch [93/100], Step [2200/4091], Loss: 917.7361\n",
      "Epoch [93/100], Step [2300/4091], Loss: 706.7086\n",
      "Epoch [93/100], Step [2400/4091], Loss: 557.9319\n",
      "Epoch [93/100], Step [2500/4091], Loss: 701.8050\n",
      "Epoch [93/100], Step [2600/4091], Loss: 624.8356\n",
      "Epoch [93/100], Step [2700/4091], Loss: 605.0382\n",
      "Epoch [93/100], Step [2800/4091], Loss: 666.9835\n",
      "Epoch [93/100], Step [2900/4091], Loss: 762.6001\n",
      "Epoch [93/100], Step [3000/4091], Loss: 674.5271\n",
      "Epoch [93/100], Step [3100/4091], Loss: 566.1042\n",
      "Epoch [93/100], Step [3200/4091], Loss: 890.1847\n",
      "Epoch [93/100], Step [3300/4091], Loss: 501.6354\n",
      "Epoch [93/100], Step [3400/4091], Loss: 709.0034\n",
      "Epoch [93/100], Step [3500/4091], Loss: 551.2878\n",
      "Epoch [93/100], Step [3600/4091], Loss: 651.5967\n",
      "Epoch [93/100], Step [3700/4091], Loss: 520.5320\n",
      "Epoch [93/100], Step [3800/4091], Loss: 485.6621\n",
      "Epoch [93/100], Step [3900/4091], Loss: 584.8282\n",
      "Epoch [93/100], Step [4000/4091], Loss: 550.3774\n",
      "Epoch [94/100], Step [100/4091], Loss: 534.0889\n",
      "Epoch [94/100], Step [200/4091], Loss: 532.9686\n",
      "Epoch [94/100], Step [300/4091], Loss: 475.5168\n",
      "Epoch [94/100], Step [400/4091], Loss: 507.8163\n",
      "Epoch [94/100], Step [500/4091], Loss: 669.6329\n",
      "Epoch [94/100], Step [600/4091], Loss: 743.0339\n",
      "Epoch [94/100], Step [700/4091], Loss: 586.3163\n",
      "Epoch [94/100], Step [800/4091], Loss: 719.8412\n",
      "Epoch [94/100], Step [900/4091], Loss: 662.4461\n",
      "Epoch [94/100], Step [1000/4091], Loss: 495.6726\n",
      "Epoch [94/100], Step [1100/4091], Loss: 729.1473\n",
      "Epoch [94/100], Step [1200/4091], Loss: 459.6448\n",
      "Epoch [94/100], Step [1300/4091], Loss: 618.9632\n",
      "Epoch [94/100], Step [1400/4091], Loss: 646.8463\n",
      "Epoch [94/100], Step [1500/4091], Loss: 601.7963\n",
      "Epoch [94/100], Step [1600/4091], Loss: 853.3666\n",
      "Epoch [94/100], Step [1700/4091], Loss: 594.5221\n",
      "Epoch [94/100], Step [1800/4091], Loss: 527.8362\n",
      "Epoch [94/100], Step [1900/4091], Loss: 712.4741\n",
      "Epoch [94/100], Step [2000/4091], Loss: 662.8588\n",
      "Epoch [94/100], Step [2100/4091], Loss: 491.2271\n",
      "Epoch [94/100], Step [2200/4091], Loss: 474.8605\n",
      "Epoch [94/100], Step [2300/4091], Loss: 583.9072\n",
      "Epoch [94/100], Step [2400/4091], Loss: 902.5372\n",
      "Epoch [94/100], Step [2500/4091], Loss: 753.9315\n",
      "Epoch [94/100], Step [2600/4091], Loss: 707.0837\n",
      "Epoch [94/100], Step [2700/4091], Loss: 729.7286\n",
      "Epoch [94/100], Step [2800/4091], Loss: 455.1921\n",
      "Epoch [94/100], Step [2900/4091], Loss: 788.4307\n",
      "Epoch [94/100], Step [3000/4091], Loss: 985.7615\n",
      "Epoch [94/100], Step [3100/4091], Loss: 719.5523\n",
      "Epoch [94/100], Step [3200/4091], Loss: 748.9951\n",
      "Epoch [94/100], Step [3300/4091], Loss: 693.9016\n",
      "Epoch [94/100], Step [3400/4091], Loss: 862.3212\n",
      "Epoch [94/100], Step [3500/4091], Loss: 572.1840\n",
      "Epoch [94/100], Step [3600/4091], Loss: 553.0207\n",
      "Epoch [94/100], Step [3700/4091], Loss: 727.3989\n",
      "Epoch [94/100], Step [3800/4091], Loss: 616.5785\n",
      "Epoch [94/100], Step [3900/4091], Loss: 514.1168\n",
      "Epoch [94/100], Step [4000/4091], Loss: 917.7322\n",
      "Epoch [95/100], Step [100/4091], Loss: 643.1353\n",
      "Epoch [95/100], Step [200/4091], Loss: 420.4135\n",
      "Epoch [95/100], Step [300/4091], Loss: 807.4374\n",
      "Epoch [95/100], Step [400/4091], Loss: 759.1602\n",
      "Epoch [95/100], Step [500/4091], Loss: 581.9962\n",
      "Epoch [95/100], Step [600/4091], Loss: 546.0588\n",
      "Epoch [95/100], Step [700/4091], Loss: 575.0726\n",
      "Epoch [95/100], Step [800/4091], Loss: 906.5333\n",
      "Epoch [95/100], Step [900/4091], Loss: 588.5718\n",
      "Epoch [95/100], Step [1000/4091], Loss: 844.3603\n",
      "Epoch [95/100], Step [1100/4091], Loss: 557.1324\n",
      "Epoch [95/100], Step [1200/4091], Loss: 655.3606\n",
      "Epoch [95/100], Step [1300/4091], Loss: 714.8278\n",
      "Epoch [95/100], Step [1400/4091], Loss: 857.4479\n",
      "Epoch [95/100], Step [1500/4091], Loss: 575.1688\n",
      "Epoch [95/100], Step [1600/4091], Loss: 537.9511\n",
      "Epoch [95/100], Step [1700/4091], Loss: 775.8087\n",
      "Epoch [95/100], Step [1800/4091], Loss: 628.7881\n",
      "Epoch [95/100], Step [1900/4091], Loss: 501.0204\n",
      "Epoch [95/100], Step [2000/4091], Loss: 836.6377\n",
      "Epoch [95/100], Step [2100/4091], Loss: 770.1819\n",
      "Epoch [95/100], Step [2200/4091], Loss: 697.5636\n",
      "Epoch [95/100], Step [2300/4091], Loss: 685.4955\n",
      "Epoch [95/100], Step [2400/4091], Loss: 725.3129\n",
      "Epoch [95/100], Step [2500/4091], Loss: 457.5271\n",
      "Epoch [95/100], Step [2600/4091], Loss: 629.8717\n",
      "Epoch [95/100], Step [2700/4091], Loss: 494.1367\n",
      "Epoch [95/100], Step [2800/4091], Loss: 422.5279\n",
      "Epoch [95/100], Step [2900/4091], Loss: 761.0084\n",
      "Epoch [95/100], Step [3000/4091], Loss: 468.9697\n",
      "Epoch [95/100], Step [3100/4091], Loss: 824.4305\n",
      "Epoch [95/100], Step [3200/4091], Loss: 870.7813\n",
      "Epoch [95/100], Step [3300/4091], Loss: 394.5406\n",
      "Epoch [95/100], Step [3400/4091], Loss: 534.8737\n",
      "Epoch [95/100], Step [3500/4091], Loss: 769.0000\n",
      "Epoch [95/100], Step [3600/4091], Loss: 683.2722\n",
      "Epoch [95/100], Step [3700/4091], Loss: 768.1873\n",
      "Epoch [95/100], Step [3800/4091], Loss: 450.7983\n",
      "Epoch [95/100], Step [3900/4091], Loss: 593.8284\n",
      "Epoch [95/100], Step [4000/4091], Loss: 598.1950\n",
      "Epoch [96/100], Step [100/4091], Loss: 567.6746\n",
      "Epoch [96/100], Step [200/4091], Loss: 719.0258\n",
      "Epoch [96/100], Step [300/4091], Loss: 653.8196\n",
      "Epoch [96/100], Step [400/4091], Loss: 532.2816\n",
      "Epoch [96/100], Step [500/4091], Loss: 705.7821\n",
      "Epoch [96/100], Step [600/4091], Loss: 685.7449\n",
      "Epoch [96/100], Step [700/4091], Loss: 757.9450\n",
      "Epoch [96/100], Step [800/4091], Loss: 1139.0015\n",
      "Epoch [96/100], Step [900/4091], Loss: 636.6833\n",
      "Epoch [96/100], Step [1000/4091], Loss: 685.9259\n",
      "Epoch [96/100], Step [1100/4091], Loss: 740.3398\n",
      "Epoch [96/100], Step [1200/4091], Loss: 500.4127\n",
      "Epoch [96/100], Step [1300/4091], Loss: 864.4105\n",
      "Epoch [96/100], Step [1400/4091], Loss: 455.4434\n",
      "Epoch [96/100], Step [1500/4091], Loss: 678.8442\n",
      "Epoch [96/100], Step [1600/4091], Loss: 583.5898\n",
      "Epoch [96/100], Step [1700/4091], Loss: 546.4119\n",
      "Epoch [96/100], Step [1800/4091], Loss: 559.7490\n",
      "Epoch [96/100], Step [1900/4091], Loss: 573.0812\n",
      "Epoch [96/100], Step [2000/4091], Loss: 544.1128\n",
      "Epoch [96/100], Step [2100/4091], Loss: 686.0164\n",
      "Epoch [96/100], Step [2200/4091], Loss: 558.6837\n",
      "Epoch [96/100], Step [2300/4091], Loss: 659.8801\n",
      "Epoch [96/100], Step [2400/4091], Loss: 862.1979\n",
      "Epoch [96/100], Step [2500/4091], Loss: 613.2938\n",
      "Epoch [96/100], Step [2600/4091], Loss: 780.3324\n",
      "Epoch [96/100], Step [2700/4091], Loss: 675.5921\n",
      "Epoch [96/100], Step [2800/4091], Loss: 583.7665\n",
      "Epoch [96/100], Step [2900/4091], Loss: 497.3077\n",
      "Epoch [96/100], Step [3000/4091], Loss: 651.7632\n",
      "Epoch [96/100], Step [3100/4091], Loss: 641.9169\n",
      "Epoch [96/100], Step [3200/4091], Loss: 632.3859\n",
      "Epoch [96/100], Step [3300/4091], Loss: 511.4438\n",
      "Epoch [96/100], Step [3400/4091], Loss: 715.3536\n",
      "Epoch [96/100], Step [3500/4091], Loss: 806.8403\n",
      "Epoch [96/100], Step [3600/4091], Loss: 821.4772\n",
      "Epoch [96/100], Step [3700/4091], Loss: 641.3273\n",
      "Epoch [96/100], Step [3800/4091], Loss: 835.1901\n",
      "Epoch [96/100], Step [3900/4091], Loss: 580.8138\n",
      "Epoch [96/100], Step [4000/4091], Loss: 745.7056\n",
      "Epoch [97/100], Step [100/4091], Loss: 664.6653\n",
      "Epoch [97/100], Step [200/4091], Loss: 588.6716\n",
      "Epoch [97/100], Step [300/4091], Loss: 527.6813\n",
      "Epoch [97/100], Step [400/4091], Loss: 569.6772\n",
      "Epoch [97/100], Step [500/4091], Loss: 697.5954\n",
      "Epoch [97/100], Step [600/4091], Loss: 751.5965\n",
      "Epoch [97/100], Step [700/4091], Loss: 435.2730\n",
      "Epoch [97/100], Step [800/4091], Loss: 765.9940\n",
      "Epoch [97/100], Step [900/4091], Loss: 836.3007\n",
      "Epoch [97/100], Step [1000/4091], Loss: 809.4125\n",
      "Epoch [97/100], Step [1100/4091], Loss: 770.6428\n",
      "Epoch [97/100], Step [1200/4091], Loss: 858.1455\n",
      "Epoch [97/100], Step [1300/4091], Loss: 539.5818\n",
      "Epoch [97/100], Step [1400/4091], Loss: 580.4084\n",
      "Epoch [97/100], Step [1500/4091], Loss: 743.5551\n",
      "Epoch [97/100], Step [1600/4091], Loss: 811.9482\n",
      "Epoch [97/100], Step [1700/4091], Loss: 690.4836\n",
      "Epoch [97/100], Step [1800/4091], Loss: 884.9189\n",
      "Epoch [97/100], Step [1900/4091], Loss: 640.4950\n",
      "Epoch [97/100], Step [2000/4091], Loss: 588.1353\n",
      "Epoch [97/100], Step [2100/4091], Loss: 915.2468\n",
      "Epoch [97/100], Step [2200/4091], Loss: 693.4881\n",
      "Epoch [97/100], Step [2300/4091], Loss: 445.2295\n",
      "Epoch [97/100], Step [2400/4091], Loss: 589.0132\n",
      "Epoch [97/100], Step [2500/4091], Loss: 743.6222\n",
      "Epoch [97/100], Step [2600/4091], Loss: 647.7246\n",
      "Epoch [97/100], Step [2700/4091], Loss: 867.9742\n",
      "Epoch [97/100], Step [2800/4091], Loss: 492.5282\n",
      "Epoch [97/100], Step [2900/4091], Loss: 435.7098\n",
      "Epoch [97/100], Step [3000/4091], Loss: 485.6742\n",
      "Epoch [97/100], Step [3100/4091], Loss: 763.2337\n",
      "Epoch [97/100], Step [3200/4091], Loss: 656.4474\n",
      "Epoch [97/100], Step [3300/4091], Loss: 648.4318\n",
      "Epoch [97/100], Step [3400/4091], Loss: 676.8855\n",
      "Epoch [97/100], Step [3500/4091], Loss: 601.8713\n",
      "Epoch [97/100], Step [3600/4091], Loss: 704.7083\n",
      "Epoch [97/100], Step [3700/4091], Loss: 633.9385\n",
      "Epoch [97/100], Step [3800/4091], Loss: 694.7822\n",
      "Epoch [97/100], Step [3900/4091], Loss: 627.0723\n",
      "Epoch [97/100], Step [4000/4091], Loss: 647.9172\n",
      "Epoch [98/100], Step [100/4091], Loss: 436.7936\n",
      "Epoch [98/100], Step [200/4091], Loss: 648.6144\n",
      "Epoch [98/100], Step [300/4091], Loss: 835.8574\n",
      "Epoch [98/100], Step [400/4091], Loss: 600.2349\n",
      "Epoch [98/100], Step [500/4091], Loss: 515.7635\n",
      "Epoch [98/100], Step [600/4091], Loss: 584.5584\n",
      "Epoch [98/100], Step [700/4091], Loss: 461.7504\n",
      "Epoch [98/100], Step [800/4091], Loss: 577.7600\n",
      "Epoch [98/100], Step [900/4091], Loss: 583.7705\n",
      "Epoch [98/100], Step [1000/4091], Loss: 849.8161\n",
      "Epoch [98/100], Step [1100/4091], Loss: 737.4749\n",
      "Epoch [98/100], Step [1200/4091], Loss: 730.7901\n",
      "Epoch [98/100], Step [1300/4091], Loss: 576.2494\n",
      "Epoch [98/100], Step [1400/4091], Loss: 703.9514\n",
      "Epoch [98/100], Step [1500/4091], Loss: 550.4614\n",
      "Epoch [98/100], Step [1600/4091], Loss: 766.8635\n",
      "Epoch [98/100], Step [1700/4091], Loss: 660.2127\n",
      "Epoch [98/100], Step [1800/4091], Loss: 622.7874\n",
      "Epoch [98/100], Step [1900/4091], Loss: 635.3176\n",
      "Epoch [98/100], Step [2000/4091], Loss: 621.9253\n",
      "Epoch [98/100], Step [2100/4091], Loss: 646.4312\n",
      "Epoch [98/100], Step [2200/4091], Loss: 755.9940\n",
      "Epoch [98/100], Step [2300/4091], Loss: 655.1985\n",
      "Epoch [98/100], Step [2400/4091], Loss: 572.4072\n",
      "Epoch [98/100], Step [2500/4091], Loss: 709.4251\n",
      "Epoch [98/100], Step [2600/4091], Loss: 635.4015\n",
      "Epoch [98/100], Step [2700/4091], Loss: 620.5950\n",
      "Epoch [98/100], Step [2800/4091], Loss: 550.1544\n",
      "Epoch [98/100], Step [2900/4091], Loss: 539.7704\n",
      "Epoch [98/100], Step [3000/4091], Loss: 707.9393\n",
      "Epoch [98/100], Step [3100/4091], Loss: 725.4529\n",
      "Epoch [98/100], Step [3200/4091], Loss: 581.4893\n",
      "Epoch [98/100], Step [3300/4091], Loss: 678.9227\n",
      "Epoch [98/100], Step [3400/4091], Loss: 624.1136\n",
      "Epoch [98/100], Step [3500/4091], Loss: 767.8511\n",
      "Epoch [98/100], Step [3600/4091], Loss: 531.7953\n",
      "Epoch [98/100], Step [3700/4091], Loss: 729.4663\n",
      "Epoch [98/100], Step [3800/4091], Loss: 707.3994\n",
      "Epoch [98/100], Step [3900/4091], Loss: 616.3793\n",
      "Epoch [98/100], Step [4000/4091], Loss: 610.1417\n",
      "Epoch [99/100], Step [100/4091], Loss: 755.6664\n",
      "Epoch [99/100], Step [200/4091], Loss: 630.3007\n",
      "Epoch [99/100], Step [300/4091], Loss: 733.2346\n",
      "Epoch [99/100], Step [400/4091], Loss: 474.5098\n",
      "Epoch [99/100], Step [500/4091], Loss: 803.9647\n",
      "Epoch [99/100], Step [600/4091], Loss: 713.6981\n",
      "Epoch [99/100], Step [700/4091], Loss: 586.2593\n",
      "Epoch [99/100], Step [800/4091], Loss: 611.1078\n",
      "Epoch [99/100], Step [900/4091], Loss: 674.3047\n",
      "Epoch [99/100], Step [1000/4091], Loss: 569.9108\n",
      "Epoch [99/100], Step [1100/4091], Loss: 651.9829\n",
      "Epoch [99/100], Step [1200/4091], Loss: 560.8297\n",
      "Epoch [99/100], Step [1300/4091], Loss: 888.2302\n",
      "Epoch [99/100], Step [1400/4091], Loss: 805.3253\n",
      "Epoch [99/100], Step [1500/4091], Loss: 812.0741\n",
      "Epoch [99/100], Step [1600/4091], Loss: 639.2374\n",
      "Epoch [99/100], Step [1700/4091], Loss: 631.3887\n",
      "Epoch [99/100], Step [1800/4091], Loss: 939.7349\n",
      "Epoch [99/100], Step [1900/4091], Loss: 628.5444\n",
      "Epoch [99/100], Step [2000/4091], Loss: 634.6884\n",
      "Epoch [99/100], Step [2100/4091], Loss: 675.5505\n",
      "Epoch [99/100], Step [2200/4091], Loss: 768.3964\n",
      "Epoch [99/100], Step [2300/4091], Loss: 563.1804\n",
      "Epoch [99/100], Step [2400/4091], Loss: 786.5696\n",
      "Epoch [99/100], Step [2500/4091], Loss: 671.6816\n",
      "Epoch [99/100], Step [2600/4091], Loss: 508.3354\n",
      "Epoch [99/100], Step [2700/4091], Loss: 392.9163\n",
      "Epoch [99/100], Step [2800/4091], Loss: 398.6353\n",
      "Epoch [99/100], Step [2900/4091], Loss: 463.5902\n",
      "Epoch [99/100], Step [3000/4091], Loss: 605.2975\n",
      "Epoch [99/100], Step [3100/4091], Loss: 534.3315\n",
      "Epoch [99/100], Step [3200/4091], Loss: 907.9819\n",
      "Epoch [99/100], Step [3300/4091], Loss: 462.7496\n",
      "Epoch [99/100], Step [3400/4091], Loss: 845.7955\n",
      "Epoch [99/100], Step [3500/4091], Loss: 574.1420\n",
      "Epoch [99/100], Step [3600/4091], Loss: 616.9322\n",
      "Epoch [99/100], Step [3700/4091], Loss: 573.0176\n",
      "Epoch [99/100], Step [3800/4091], Loss: 807.1474\n",
      "Epoch [99/100], Step [3900/4091], Loss: 772.7267\n",
      "Epoch [99/100], Step [4000/4091], Loss: 708.7800\n",
      "Epoch [100/100], Step [100/4091], Loss: 407.2813\n",
      "Epoch [100/100], Step [200/4091], Loss: 561.1238\n",
      "Epoch [100/100], Step [300/4091], Loss: 795.5476\n",
      "Epoch [100/100], Step [400/4091], Loss: 698.9825\n",
      "Epoch [100/100], Step [500/4091], Loss: 511.6152\n",
      "Epoch [100/100], Step [600/4091], Loss: 810.9976\n",
      "Epoch [100/100], Step [700/4091], Loss: 552.4489\n",
      "Epoch [100/100], Step [800/4091], Loss: 594.2958\n",
      "Epoch [100/100], Step [900/4091], Loss: 618.3809\n",
      "Epoch [100/100], Step [1000/4091], Loss: 542.8762\n",
      "Epoch [100/100], Step [1100/4091], Loss: 506.5925\n",
      "Epoch [100/100], Step [1200/4091], Loss: 448.6345\n",
      "Epoch [100/100], Step [1300/4091], Loss: 600.0655\n",
      "Epoch [100/100], Step [1400/4091], Loss: 652.0455\n",
      "Epoch [100/100], Step [1500/4091], Loss: 485.8073\n",
      "Epoch [100/100], Step [1600/4091], Loss: 684.1608\n",
      "Epoch [100/100], Step [1700/4091], Loss: 652.8170\n",
      "Epoch [100/100], Step [1800/4091], Loss: 781.5719\n",
      "Epoch [100/100], Step [1900/4091], Loss: 728.1827\n",
      "Epoch [100/100], Step [2000/4091], Loss: 826.1457\n",
      "Epoch [100/100], Step [2100/4091], Loss: 625.6255\n",
      "Epoch [100/100], Step [2200/4091], Loss: 942.6055\n",
      "Epoch [100/100], Step [2300/4091], Loss: 641.2064\n",
      "Epoch [100/100], Step [2400/4091], Loss: 741.4448\n",
      "Epoch [100/100], Step [2500/4091], Loss: 624.4315\n",
      "Epoch [100/100], Step [2600/4091], Loss: 911.9401\n",
      "Epoch [100/100], Step [2700/4091], Loss: 757.5947\n",
      "Epoch [100/100], Step [2800/4091], Loss: 771.1998\n",
      "Epoch [100/100], Step [2900/4091], Loss: 450.1063\n",
      "Epoch [100/100], Step [3000/4091], Loss: 815.1519\n",
      "Epoch [100/100], Step [3100/4091], Loss: 774.8893\n",
      "Epoch [100/100], Step [3200/4091], Loss: 835.5624\n",
      "Epoch [100/100], Step [3300/4091], Loss: 533.5131\n",
      "Epoch [100/100], Step [3400/4091], Loss: 531.3951\n",
      "Epoch [100/100], Step [3500/4091], Loss: 447.6084\n",
      "Epoch [100/100], Step [3600/4091], Loss: 711.9695\n",
      "Epoch [100/100], Step [3700/4091], Loss: 632.9207\n",
      "Epoch [100/100], Step [3800/4091], Loss: 575.5795\n",
      "Epoch [100/100], Step [3900/4091], Loss: 653.9866\n",
      "Epoch [100/100], Step [4000/4091], Loss: 598.3525\n"
     ]
    }
   ],
   "source": [
    "criteria = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.4, patience=4, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.float()  # Convert inputs to float\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criteria(outputs.squeeze(), labels.float())  # Convert labels to float\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Calculate validation loss\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs.float())\n",
    "            val_loss += criteria(outputs.squeeze(), labels.float()).item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 907331.1875\n",
      "Mean Absolute Error (MAE): 659.8949\n",
      "R-squared (R): -0.1118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Function to evaluate metrics\n",
    "def evaluate_metrics(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in data_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float()).squeeze()  # Model predictions\n",
    "            all_predictions.extend(outputs.numpy())  # Convert to NumPy\n",
    "            all_labels.extend(labels.float().numpy())  # Convert to NumPy\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    y_true = torch.tensor(all_labels).numpy()\n",
    "    y_pred = torch.tensor(all_predictions).numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "# Example: Evaluate on test set\n",
    "mse, mae, r2 = evaluate_metrics(model, test_loader)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
