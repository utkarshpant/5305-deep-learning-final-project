{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5305-Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Insurance Premium Prediction Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Premium Amount</th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Property Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>99990.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.074627</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5</td>\n",
       "      <td>308.0</td>\n",
       "      <td>2022-12-10 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2867.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.271335</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>694.0</td>\n",
       "      <td>4</td>\n",
       "      <td>517.0</td>\n",
       "      <td>2023-01-31 15:21:39.078837</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>30154.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.714909</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>652.0</td>\n",
       "      <td>8</td>\n",
       "      <td>849.0</td>\n",
       "      <td>2023-11-26 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>48371.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>25.346926</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>330.0</td>\n",
       "      <td>7</td>\n",
       "      <td>927.0</td>\n",
       "      <td>2023-02-27 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>54174.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>6.659499</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2020-11-25 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Annual Income Marital Status  Number of Dependents  \\\n",
       "0  56.0    Male        99990.0        Married                   1.0   \n",
       "1  46.0    Male         2867.0         Single                   1.0   \n",
       "2  32.0  Female        30154.0       Divorced                   3.0   \n",
       "3  60.0  Female        48371.0       Divorced                   0.0   \n",
       "4  25.0  Female        54174.0       Divorced                   0.0   \n",
       "\n",
       "  Education Level     Occupation  Health Score  Location    Policy Type  \\\n",
       "0        Master's            NaN     31.074627     Urban  Comprehensive   \n",
       "1      Bachelor's            NaN     50.271335     Urban  Comprehensive   \n",
       "2      Bachelor's            NaN     14.714909  Suburban  Comprehensive   \n",
       "3             PhD  Self-Employed     25.346926     Rural  Comprehensive   \n",
       "4     High School  Self-Employed      6.659499     Urban  Comprehensive   \n",
       "\n",
       "   Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \\\n",
       "0              NaN           13         320.0                   5   \n",
       "1              NaN            3         694.0                   4   \n",
       "2              2.0           16         652.0                   8   \n",
       "3              1.0           11         330.0                   7   \n",
       "4              NaN            9           NaN                   8   \n",
       "\n",
       "   Premium Amount           Policy Start Date Customer Feedback  \\\n",
       "0           308.0  2022-12-10 15:21:39.078837              Poor   \n",
       "1           517.0  2023-01-31 15:21:39.078837              Good   \n",
       "2           849.0  2023-11-26 15:21:39.078837              Poor   \n",
       "3           927.0  2023-02-27 15:21:39.078837              Poor   \n",
       "4           303.0  2020-11-25 15:21:39.078837              Poor   \n",
       "\n",
       "  Smoking Status Exercise Frequency Property Type  \n",
       "0            Yes              Daily         Condo  \n",
       "1            Yes            Monthly         House  \n",
       "2             No            Monthly         House  \n",
       "3             No             Rarely         Condo  \n",
       "4             No             Rarely         Condo  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                      True\n",
      "Gender                  False\n",
      "Annual Income            True\n",
      "Marital Status           True\n",
      "Number of Dependents     True\n",
      "Education Level         False\n",
      "Occupation               True\n",
      "Health Score             True\n",
      "Location                False\n",
      "Policy Type             False\n",
      "Previous Claims          True\n",
      "Vehicle Age             False\n",
      "Credit Score             True\n",
      "Insurance Duration      False\n",
      "Premium Amount           True\n",
      "Policy Start Date       False\n",
      "Customer Feedback        True\n",
      "Smoking Status          False\n",
      "Exercise Frequency      False\n",
      "Property Type           False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278860 entries, 0 to 278859\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Age                   274175 non-null  float64\n",
      " 1   Gender                278860 non-null  object \n",
      " 2   Annual Income         264905 non-null  float64\n",
      " 3   Marital Status        273841 non-null  object \n",
      " 4   Number of Dependents  250974 non-null  float64\n",
      " 5   Education Level       278860 non-null  object \n",
      " 6   Occupation            197572 non-null  object \n",
      " 7   Health Score          268263 non-null  float64\n",
      " 8   Location              278860 non-null  object \n",
      " 9   Policy Type           278860 non-null  object \n",
      " 10  Previous Claims       197572 non-null  float64\n",
      " 11  Vehicle Age           278860 non-null  int64  \n",
      " 12  Credit Score          250974 non-null  float64\n",
      " 13  Insurance Duration    278860 non-null  int64  \n",
      " 14  Premium Amount        277019 non-null  float64\n",
      " 15  Policy Start Date     278860 non-null  object \n",
      " 16  Customer Feedback     260511 non-null  object \n",
      " 17  Smoking Status        278860 non-null  object \n",
      " 18  Exercise Frequency    278860 non-null  object \n",
      " 19  Property Type         278860 non-null  object \n",
      "dtypes: float64(7), int64(2), object(11)\n",
      "memory usage: 42.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Column  Missing Values  % Missing\n",
      "0                    Age            4685   1.680055\n",
      "1                 Gender               0   0.000000\n",
      "2          Annual Income           13955   5.004303\n",
      "3         Marital Status            5019   1.799828\n",
      "4   Number of Dependents           27886  10.000000\n",
      "5        Education Level               0   0.000000\n",
      "6             Occupation           81288  29.150111\n",
      "7           Health Score           10597   3.800115\n",
      "8               Location               0   0.000000\n",
      "9            Policy Type               0   0.000000\n",
      "10       Previous Claims           81288  29.150111\n",
      "11           Vehicle Age               0   0.000000\n",
      "12          Credit Score           27886  10.000000\n",
      "13    Insurance Duration               0   0.000000\n",
      "14        Premium Amount            1841   0.660188\n",
      "15     Policy Start Date               0   0.000000\n",
      "16     Customer Feedback           18349   6.580004\n",
      "17        Smoking Status               0   0.000000\n",
      "18    Exercise Frequency               0   0.000000\n",
      "19         Property Type               0   0.000000\n"
     ]
    }
   ],
   "source": [
    "# Summarize the total missing values and their percentage\n",
    "missing_summary = df.isnull().sum().reset_index()\n",
    "missing_summary.columns = ['Column', 'Missing Values']\n",
    "missing_summary['% Missing'] = (missing_summary['Missing Values'] / len(df)) * 100\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a custom `InsuranceDataset` class that inherits the `Dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsuranceDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = pd.read_csv('./insurance_data_imputed.csv')\n",
    "        self.X = self.data.drop('premium_amount', axis=1)\n",
    "        self.y = self.data['premium_amount']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X.iloc[idx].values, dtype=torch.float32), torch.tensor(self.y.iloc[idx], dtype=torch.float32)\n",
    "\n",
    "dataset = InsuranceDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'annual_income', 'marital_status',\n",
       "       'number_of_dependents', 'education_level', 'health_score', 'location',\n",
       "       'policy_type', 'previous_claims', 'credit_score', 'insurance_duration',\n",
       "       'smoking_status', 'exercise_frequency', 'occupation_employed',\n",
       "       'occupation_self_employed', 'occupation_unemployed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward Neural Network with 2 hidden layers, with 64 and 32 neurons respectively\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(17, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.output(x)\n",
    "\n",
    "model = FeedForwardNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, testing and validation data\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = int(0.15 * len(dataset))\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/4091], Loss: 1048.6968\n",
      "Epoch [1/100], Step [200/4091], Loss: 647.5167\n",
      "Epoch [1/100], Step [300/4091], Loss: 520.4061\n",
      "Epoch [1/100], Step [400/4091], Loss: 701.0190\n",
      "Epoch [1/100], Step [500/4091], Loss: 524.4326\n",
      "Epoch [1/100], Step [600/4091], Loss: 782.1561\n",
      "Epoch [1/100], Step [700/4091], Loss: 781.2236\n",
      "Epoch [1/100], Step [800/4091], Loss: 568.8615\n",
      "Epoch [1/100], Step [900/4091], Loss: 587.7375\n",
      "Epoch [1/100], Step [1000/4091], Loss: 858.5614\n",
      "Epoch [1/100], Step [1100/4091], Loss: 858.4792\n",
      "Epoch [1/100], Step [1200/4091], Loss: 903.1886\n",
      "Epoch [1/100], Step [1300/4091], Loss: 627.6864\n",
      "Epoch [1/100], Step [1400/4091], Loss: 761.5317\n",
      "Epoch [1/100], Step [1500/4091], Loss: 584.5656\n",
      "Epoch [1/100], Step [1600/4091], Loss: 786.5484\n",
      "Epoch [1/100], Step [1700/4091], Loss: 797.1525\n",
      "Epoch [1/100], Step [1800/4091], Loss: 686.7686\n",
      "Epoch [1/100], Step [1900/4091], Loss: 793.7996\n",
      "Epoch [1/100], Step [2000/4091], Loss: 532.8842\n",
      "Epoch [1/100], Step [2100/4091], Loss: 490.3727\n",
      "Epoch [1/100], Step [2200/4091], Loss: 692.0322\n",
      "Epoch [1/100], Step [2300/4091], Loss: 511.7058\n",
      "Epoch [1/100], Step [2400/4091], Loss: 627.3030\n",
      "Epoch [1/100], Step [2500/4091], Loss: 707.7257\n",
      "Epoch [1/100], Step [2600/4091], Loss: 841.3851\n",
      "Epoch [1/100], Step [2700/4091], Loss: 815.7143\n",
      "Epoch [1/100], Step [2800/4091], Loss: 524.3680\n",
      "Epoch [1/100], Step [2900/4091], Loss: 763.6810\n",
      "Epoch [1/100], Step [3000/4091], Loss: 645.6993\n",
      "Epoch [1/100], Step [3100/4091], Loss: 661.6641\n",
      "Epoch [1/100], Step [3200/4091], Loss: 850.6441\n",
      "Epoch [1/100], Step [3300/4091], Loss: 607.5344\n",
      "Epoch [1/100], Step [3400/4091], Loss: 941.8683\n",
      "Epoch [1/100], Step [3500/4091], Loss: 478.2664\n",
      "Epoch [1/100], Step [3600/4091], Loss: 502.3690\n",
      "Epoch [1/100], Step [3700/4091], Loss: 918.0776\n",
      "Epoch [1/100], Step [3800/4091], Loss: 607.2021\n",
      "Epoch [1/100], Step [3900/4091], Loss: 651.7650\n",
      "Epoch [1/100], Step [4000/4091], Loss: 573.1814\n",
      "Epoch [2/100], Step [100/4091], Loss: 595.3096\n",
      "Epoch [2/100], Step [200/4091], Loss: 574.2874\n",
      "Epoch [2/100], Step [300/4091], Loss: 804.5325\n",
      "Epoch [2/100], Step [400/4091], Loss: 664.3951\n",
      "Epoch [2/100], Step [500/4091], Loss: 821.3672\n",
      "Epoch [2/100], Step [600/4091], Loss: 639.6978\n",
      "Epoch [2/100], Step [700/4091], Loss: 636.3428\n",
      "Epoch [2/100], Step [800/4091], Loss: 639.9191\n",
      "Epoch [2/100], Step [900/4091], Loss: 785.9158\n",
      "Epoch [2/100], Step [1000/4091], Loss: 451.8161\n",
      "Epoch [2/100], Step [1100/4091], Loss: 684.2563\n",
      "Epoch [2/100], Step [1200/4091], Loss: 436.1469\n",
      "Epoch [2/100], Step [1300/4091], Loss: 607.2501\n",
      "Epoch [2/100], Step [1400/4091], Loss: 819.8262\n",
      "Epoch [2/100], Step [1500/4091], Loss: 380.8974\n",
      "Epoch [2/100], Step [1600/4091], Loss: 822.3306\n",
      "Epoch [2/100], Step [1700/4091], Loss: 654.8647\n",
      "Epoch [2/100], Step [1800/4091], Loss: 412.4295\n",
      "Epoch [2/100], Step [1900/4091], Loss: 701.7248\n",
      "Epoch [2/100], Step [2000/4091], Loss: 643.3142\n",
      "Epoch [2/100], Step [2100/4091], Loss: 764.2473\n",
      "Epoch [2/100], Step [2200/4091], Loss: 956.8412\n",
      "Epoch [2/100], Step [2300/4091], Loss: 590.7684\n",
      "Epoch [2/100], Step [2400/4091], Loss: 587.6108\n",
      "Epoch [2/100], Step [2500/4091], Loss: 726.1407\n",
      "Epoch [2/100], Step [2600/4091], Loss: 599.6300\n",
      "Epoch [2/100], Step [2700/4091], Loss: 749.3388\n",
      "Epoch [2/100], Step [2800/4091], Loss: 621.6254\n",
      "Epoch [2/100], Step [2900/4091], Loss: 599.1457\n",
      "Epoch [2/100], Step [3000/4091], Loss: 570.9486\n",
      "Epoch [2/100], Step [3100/4091], Loss: 855.4908\n",
      "Epoch [2/100], Step [3200/4091], Loss: 737.1426\n",
      "Epoch [2/100], Step [3300/4091], Loss: 719.0575\n",
      "Epoch [2/100], Step [3400/4091], Loss: 607.4056\n",
      "Epoch [2/100], Step [3500/4091], Loss: 662.3062\n",
      "Epoch [2/100], Step [3600/4091], Loss: 676.6599\n",
      "Epoch [2/100], Step [3700/4091], Loss: 671.3870\n",
      "Epoch [2/100], Step [3800/4091], Loss: 724.9605\n",
      "Epoch [2/100], Step [3900/4091], Loss: 842.0066\n",
      "Epoch [2/100], Step [4000/4091], Loss: 623.1764\n",
      "Epoch [3/100], Step [100/4091], Loss: 763.7228\n",
      "Epoch [3/100], Step [200/4091], Loss: 601.8766\n",
      "Epoch [3/100], Step [300/4091], Loss: 487.7362\n",
      "Epoch [3/100], Step [400/4091], Loss: 462.4985\n",
      "Epoch [3/100], Step [500/4091], Loss: 920.2037\n",
      "Epoch [3/100], Step [600/4091], Loss: 684.6661\n",
      "Epoch [3/100], Step [700/4091], Loss: 561.5660\n",
      "Epoch [3/100], Step [800/4091], Loss: 604.6536\n",
      "Epoch [3/100], Step [900/4091], Loss: 659.8986\n",
      "Epoch [3/100], Step [1000/4091], Loss: 762.5124\n",
      "Epoch [3/100], Step [1100/4091], Loss: 718.6240\n",
      "Epoch [3/100], Step [1200/4091], Loss: 596.6882\n",
      "Epoch [3/100], Step [1300/4091], Loss: 681.1901\n",
      "Epoch [3/100], Step [1400/4091], Loss: 612.4614\n",
      "Epoch [3/100], Step [1500/4091], Loss: 735.2897\n",
      "Epoch [3/100], Step [1600/4091], Loss: 806.9371\n",
      "Epoch [3/100], Step [1700/4091], Loss: 573.4301\n",
      "Epoch [3/100], Step [1800/4091], Loss: 608.5391\n",
      "Epoch [3/100], Step [1900/4091], Loss: 640.8619\n",
      "Epoch [3/100], Step [2000/4091], Loss: 781.4990\n",
      "Epoch [3/100], Step [2100/4091], Loss: 719.4185\n",
      "Epoch [3/100], Step [2200/4091], Loss: 690.3126\n",
      "Epoch [3/100], Step [2300/4091], Loss: 608.0943\n",
      "Epoch [3/100], Step [2400/4091], Loss: 732.8351\n",
      "Epoch [3/100], Step [2500/4091], Loss: 598.8520\n",
      "Epoch [3/100], Step [2600/4091], Loss: 781.5985\n",
      "Epoch [3/100], Step [2700/4091], Loss: 919.6711\n",
      "Epoch [3/100], Step [2800/4091], Loss: 749.4164\n",
      "Epoch [3/100], Step [2900/4091], Loss: 850.0264\n",
      "Epoch [3/100], Step [3000/4091], Loss: 508.2113\n",
      "Epoch [3/100], Step [3100/4091], Loss: 962.3625\n",
      "Epoch [3/100], Step [3200/4091], Loss: 574.9429\n",
      "Epoch [3/100], Step [3300/4091], Loss: 750.0621\n",
      "Epoch [3/100], Step [3400/4091], Loss: 673.0622\n",
      "Epoch [3/100], Step [3500/4091], Loss: 931.6765\n",
      "Epoch [3/100], Step [3600/4091], Loss: 795.8865\n",
      "Epoch [3/100], Step [3700/4091], Loss: 686.0302\n",
      "Epoch [3/100], Step [3800/4091], Loss: 558.6116\n",
      "Epoch [3/100], Step [3900/4091], Loss: 676.7941\n",
      "Epoch [3/100], Step [4000/4091], Loss: 531.4550\n",
      "Epoch [4/100], Step [100/4091], Loss: 766.0248\n",
      "Epoch [4/100], Step [200/4091], Loss: 701.0685\n",
      "Epoch [4/100], Step [300/4091], Loss: 582.8813\n",
      "Epoch [4/100], Step [400/4091], Loss: 718.6858\n",
      "Epoch [4/100], Step [500/4091], Loss: 722.7000\n",
      "Epoch [4/100], Step [600/4091], Loss: 696.0410\n",
      "Epoch [4/100], Step [700/4091], Loss: 617.5694\n",
      "Epoch [4/100], Step [800/4091], Loss: 469.1585\n",
      "Epoch [4/100], Step [900/4091], Loss: 620.3081\n",
      "Epoch [4/100], Step [1000/4091], Loss: 786.8757\n",
      "Epoch [4/100], Step [1100/4091], Loss: 568.8354\n",
      "Epoch [4/100], Step [1200/4091], Loss: 754.0106\n",
      "Epoch [4/100], Step [1300/4091], Loss: 738.3366\n",
      "Epoch [4/100], Step [1400/4091], Loss: 561.6361\n",
      "Epoch [4/100], Step [1500/4091], Loss: 824.3704\n",
      "Epoch [4/100], Step [1600/4091], Loss: 717.1710\n",
      "Epoch [4/100], Step [1700/4091], Loss: 726.2301\n",
      "Epoch [4/100], Step [1800/4091], Loss: 594.3185\n",
      "Epoch [4/100], Step [1900/4091], Loss: 648.2569\n",
      "Epoch [4/100], Step [2000/4091], Loss: 735.5555\n",
      "Epoch [4/100], Step [2100/4091], Loss: 645.5745\n",
      "Epoch [4/100], Step [2200/4091], Loss: 646.9210\n",
      "Epoch [4/100], Step [2300/4091], Loss: 698.2018\n",
      "Epoch [4/100], Step [2400/4091], Loss: 771.2792\n",
      "Epoch [4/100], Step [2500/4091], Loss: 485.6399\n",
      "Epoch [4/100], Step [2600/4091], Loss: 716.7415\n",
      "Epoch [4/100], Step [2700/4091], Loss: 738.9032\n",
      "Epoch [4/100], Step [2800/4091], Loss: 837.4672\n",
      "Epoch [4/100], Step [2900/4091], Loss: 697.2117\n",
      "Epoch [4/100], Step [3000/4091], Loss: 473.6612\n",
      "Epoch [4/100], Step [3100/4091], Loss: 713.6032\n",
      "Epoch [4/100], Step [3200/4091], Loss: 586.7440\n",
      "Epoch [4/100], Step [3300/4091], Loss: 827.5817\n",
      "Epoch [4/100], Step [3400/4091], Loss: 581.1088\n",
      "Epoch [4/100], Step [3500/4091], Loss: 536.5469\n",
      "Epoch [4/100], Step [3600/4091], Loss: 559.1970\n",
      "Epoch [4/100], Step [3700/4091], Loss: 752.3917\n",
      "Epoch [4/100], Step [3800/4091], Loss: 804.1933\n",
      "Epoch [4/100], Step [3900/4091], Loss: 541.3937\n",
      "Epoch [4/100], Step [4000/4091], Loss: 606.7526\n",
      "Epoch [5/100], Step [100/4091], Loss: 660.9343\n",
      "Epoch [5/100], Step [200/4091], Loss: 723.8929\n",
      "Epoch [5/100], Step [300/4091], Loss: 813.9053\n",
      "Epoch [5/100], Step [400/4091], Loss: 604.8201\n",
      "Epoch [5/100], Step [500/4091], Loss: 605.3214\n",
      "Epoch [5/100], Step [600/4091], Loss: 847.5082\n",
      "Epoch [5/100], Step [700/4091], Loss: 645.4920\n",
      "Epoch [5/100], Step [800/4091], Loss: 652.4688\n",
      "Epoch [5/100], Step [900/4091], Loss: 604.1539\n",
      "Epoch [5/100], Step [1000/4091], Loss: 864.5831\n",
      "Epoch [5/100], Step [1100/4091], Loss: 847.2319\n",
      "Epoch [5/100], Step [1200/4091], Loss: 457.2941\n",
      "Epoch [5/100], Step [1300/4091], Loss: 700.7197\n",
      "Epoch [5/100], Step [1400/4091], Loss: 809.0593\n",
      "Epoch [5/100], Step [1500/4091], Loss: 801.4316\n",
      "Epoch [5/100], Step [1600/4091], Loss: 844.4362\n",
      "Epoch [5/100], Step [1700/4091], Loss: 601.3568\n",
      "Epoch [5/100], Step [1800/4091], Loss: 674.6741\n",
      "Epoch [5/100], Step [1900/4091], Loss: 797.5327\n",
      "Epoch [5/100], Step [2000/4091], Loss: 662.1196\n",
      "Epoch [5/100], Step [2100/4091], Loss: 657.1644\n",
      "Epoch [5/100], Step [2200/4091], Loss: 782.1578\n",
      "Epoch [5/100], Step [2300/4091], Loss: 843.9208\n",
      "Epoch [5/100], Step [2400/4091], Loss: 962.9688\n",
      "Epoch [5/100], Step [2500/4091], Loss: 602.0929\n",
      "Epoch [5/100], Step [2600/4091], Loss: 740.1290\n",
      "Epoch [5/100], Step [2700/4091], Loss: 857.2889\n",
      "Epoch [5/100], Step [2800/4091], Loss: 672.9185\n",
      "Epoch [5/100], Step [2900/4091], Loss: 654.1926\n",
      "Epoch [5/100], Step [3000/4091], Loss: 680.4235\n",
      "Epoch [5/100], Step [3100/4091], Loss: 633.8130\n",
      "Epoch [5/100], Step [3200/4091], Loss: 663.7978\n",
      "Epoch [5/100], Step [3300/4091], Loss: 617.7825\n",
      "Epoch [5/100], Step [3400/4091], Loss: 767.5410\n",
      "Epoch [5/100], Step [3500/4091], Loss: 850.6774\n",
      "Epoch [5/100], Step [3600/4091], Loss: 639.8159\n",
      "Epoch [5/100], Step [3700/4091], Loss: 657.4252\n",
      "Epoch [5/100], Step [3800/4091], Loss: 657.4419\n",
      "Epoch [5/100], Step [3900/4091], Loss: 568.0329\n",
      "Epoch [5/100], Step [4000/4091], Loss: 845.7711\n",
      "Epoch [6/100], Step [100/4091], Loss: 609.5516\n",
      "Epoch [6/100], Step [200/4091], Loss: 579.6658\n",
      "Epoch [6/100], Step [300/4091], Loss: 626.1281\n",
      "Epoch [6/100], Step [400/4091], Loss: 850.3593\n",
      "Epoch [6/100], Step [500/4091], Loss: 524.9892\n",
      "Epoch [6/100], Step [600/4091], Loss: 611.6760\n",
      "Epoch [6/100], Step [700/4091], Loss: 865.2032\n",
      "Epoch [6/100], Step [800/4091], Loss: 629.8691\n",
      "Epoch [6/100], Step [900/4091], Loss: 568.4947\n",
      "Epoch [6/100], Step [1000/4091], Loss: 801.5466\n",
      "Epoch [6/100], Step [1100/4091], Loss: 431.9320\n",
      "Epoch [6/100], Step [1200/4091], Loss: 569.9049\n",
      "Epoch [6/100], Step [1300/4091], Loss: 761.2501\n",
      "Epoch [6/100], Step [1400/4091], Loss: 635.9913\n",
      "Epoch [6/100], Step [1500/4091], Loss: 819.1097\n",
      "Epoch [6/100], Step [1600/4091], Loss: 672.1694\n",
      "Epoch [6/100], Step [1700/4091], Loss: 706.0931\n",
      "Epoch [6/100], Step [1800/4091], Loss: 646.0618\n",
      "Epoch [6/100], Step [1900/4091], Loss: 760.6056\n",
      "Epoch [6/100], Step [2000/4091], Loss: 583.6295\n",
      "Epoch [6/100], Step [2100/4091], Loss: 536.3313\n",
      "Epoch [6/100], Step [2200/4091], Loss: 631.1146\n",
      "Epoch [6/100], Step [2300/4091], Loss: 649.3735\n",
      "Epoch [6/100], Step [2400/4091], Loss: 644.5775\n",
      "Epoch [6/100], Step [2500/4091], Loss: 513.6691\n",
      "Epoch [6/100], Step [2600/4091], Loss: 653.9389\n",
      "Epoch [6/100], Step [2700/4091], Loss: 651.9054\n",
      "Epoch [6/100], Step [2800/4091], Loss: 918.7859\n",
      "Epoch [6/100], Step [2900/4091], Loss: 922.7230\n",
      "Epoch [6/100], Step [3000/4091], Loss: 579.5782\n",
      "Epoch [6/100], Step [3100/4091], Loss: 600.4368\n",
      "Epoch [6/100], Step [3200/4091], Loss: 642.4742\n",
      "Epoch [6/100], Step [3300/4091], Loss: 536.2791\n",
      "Epoch [6/100], Step [3400/4091], Loss: 908.8956\n",
      "Epoch [6/100], Step [3500/4091], Loss: 437.7015\n",
      "Epoch [6/100], Step [3600/4091], Loss: 712.3360\n",
      "Epoch [6/100], Step [3700/4091], Loss: 851.0203\n",
      "Epoch [6/100], Step [3800/4091], Loss: 431.1905\n",
      "Epoch [6/100], Step [3900/4091], Loss: 721.1990\n",
      "Epoch [6/100], Step [4000/4091], Loss: 534.9637\n",
      "Epoch [7/100], Step [100/4091], Loss: 949.7670\n",
      "Epoch [7/100], Step [200/4091], Loss: 739.0525\n",
      "Epoch [7/100], Step [300/4091], Loss: 586.8945\n",
      "Epoch [7/100], Step [400/4091], Loss: 750.9990\n",
      "Epoch [7/100], Step [500/4091], Loss: 626.5919\n",
      "Epoch [7/100], Step [600/4091], Loss: 815.9849\n",
      "Epoch [7/100], Step [700/4091], Loss: 593.3715\n",
      "Epoch [7/100], Step [800/4091], Loss: 801.3865\n",
      "Epoch [7/100], Step [900/4091], Loss: 548.6825\n",
      "Epoch [7/100], Step [1000/4091], Loss: 803.2718\n",
      "Epoch [7/100], Step [1100/4091], Loss: 617.7396\n",
      "Epoch [7/100], Step [1200/4091], Loss: 639.2549\n",
      "Epoch [7/100], Step [1300/4091], Loss: 553.4630\n",
      "Epoch [7/100], Step [1400/4091], Loss: 618.9205\n",
      "Epoch [7/100], Step [1500/4091], Loss: 771.7408\n",
      "Epoch [7/100], Step [1600/4091], Loss: 589.7239\n",
      "Epoch [7/100], Step [1700/4091], Loss: 786.6692\n",
      "Epoch [7/100], Step [1800/4091], Loss: 545.9848\n",
      "Epoch [7/100], Step [1900/4091], Loss: 835.6771\n",
      "Epoch [7/100], Step [2000/4091], Loss: 774.8945\n",
      "Epoch [7/100], Step [2100/4091], Loss: 652.4789\n",
      "Epoch [7/100], Step [2200/4091], Loss: 736.3642\n",
      "Epoch [7/100], Step [2300/4091], Loss: 507.5867\n",
      "Epoch [7/100], Step [2400/4091], Loss: 450.1608\n",
      "Epoch [7/100], Step [2500/4091], Loss: 728.5785\n",
      "Epoch [7/100], Step [2600/4091], Loss: 857.5298\n",
      "Epoch [7/100], Step [2700/4091], Loss: 689.1641\n",
      "Epoch [7/100], Step [2800/4091], Loss: 551.0277\n",
      "Epoch [7/100], Step [2900/4091], Loss: 647.2153\n",
      "Epoch [7/100], Step [3000/4091], Loss: 685.5522\n",
      "Epoch [7/100], Step [3100/4091], Loss: 756.3847\n",
      "Epoch [7/100], Step [3200/4091], Loss: 563.9675\n",
      "Epoch [7/100], Step [3300/4091], Loss: 682.4933\n",
      "Epoch [7/100], Step [3400/4091], Loss: 690.4076\n",
      "Epoch [7/100], Step [3500/4091], Loss: 730.5048\n",
      "Epoch [7/100], Step [3600/4091], Loss: 639.3055\n",
      "Epoch [7/100], Step [3700/4091], Loss: 866.3171\n",
      "Epoch [7/100], Step [3800/4091], Loss: 636.7011\n",
      "Epoch [7/100], Step [3900/4091], Loss: 661.8537\n",
      "Epoch [7/100], Step [4000/4091], Loss: 555.8558\n",
      "Epoch [8/100], Step [100/4091], Loss: 795.7080\n",
      "Epoch [8/100], Step [200/4091], Loss: 569.5755\n",
      "Epoch [8/100], Step [300/4091], Loss: 692.6458\n",
      "Epoch [8/100], Step [400/4091], Loss: 505.1661\n",
      "Epoch [8/100], Step [500/4091], Loss: 750.2642\n",
      "Epoch [8/100], Step [600/4091], Loss: 611.3361\n",
      "Epoch [8/100], Step [700/4091], Loss: 622.2677\n",
      "Epoch [8/100], Step [800/4091], Loss: 616.5393\n",
      "Epoch [8/100], Step [900/4091], Loss: 652.0453\n",
      "Epoch [8/100], Step [1000/4091], Loss: 560.7004\n",
      "Epoch [8/100], Step [1100/4091], Loss: 648.8408\n",
      "Epoch [8/100], Step [1200/4091], Loss: 795.9478\n",
      "Epoch [8/100], Step [1300/4091], Loss: 886.2637\n",
      "Epoch [8/100], Step [1400/4091], Loss: 610.7335\n",
      "Epoch [8/100], Step [1500/4091], Loss: 658.7080\n",
      "Epoch [8/100], Step [1600/4091], Loss: 600.8387\n",
      "Epoch [8/100], Step [1700/4091], Loss: 626.7429\n",
      "Epoch [8/100], Step [1800/4091], Loss: 706.6136\n",
      "Epoch [8/100], Step [1900/4091], Loss: 607.3029\n",
      "Epoch [8/100], Step [2000/4091], Loss: 556.8387\n",
      "Epoch [8/100], Step [2100/4091], Loss: 863.5593\n",
      "Epoch [8/100], Step [2200/4091], Loss: 1085.1785\n",
      "Epoch [8/100], Step [2300/4091], Loss: 910.6107\n",
      "Epoch [8/100], Step [2400/4091], Loss: 544.8374\n",
      "Epoch [8/100], Step [2500/4091], Loss: 637.9610\n",
      "Epoch [8/100], Step [2600/4091], Loss: 826.2772\n",
      "Epoch [8/100], Step [2700/4091], Loss: 789.9224\n",
      "Epoch [8/100], Step [2800/4091], Loss: 563.4788\n",
      "Epoch [8/100], Step [2900/4091], Loss: 701.9456\n",
      "Epoch [8/100], Step [3000/4091], Loss: 587.1499\n",
      "Epoch [8/100], Step [3100/4091], Loss: 624.8650\n",
      "Epoch [8/100], Step [3200/4091], Loss: 537.3265\n",
      "Epoch [8/100], Step [3300/4091], Loss: 652.4948\n",
      "Epoch [8/100], Step [3400/4091], Loss: 935.8029\n",
      "Epoch [8/100], Step [3500/4091], Loss: 547.7982\n",
      "Epoch [8/100], Step [3600/4091], Loss: 592.4429\n",
      "Epoch [8/100], Step [3700/4091], Loss: 696.8788\n",
      "Epoch [8/100], Step [3800/4091], Loss: 934.9187\n",
      "Epoch [8/100], Step [3900/4091], Loss: 624.8116\n",
      "Epoch [8/100], Step [4000/4091], Loss: 537.6704\n",
      "Epoch [9/100], Step [100/4091], Loss: 684.8820\n",
      "Epoch [9/100], Step [200/4091], Loss: 588.3426\n",
      "Epoch [9/100], Step [300/4091], Loss: 543.6091\n",
      "Epoch [9/100], Step [400/4091], Loss: 579.6895\n",
      "Epoch [9/100], Step [500/4091], Loss: 571.0836\n",
      "Epoch [9/100], Step [600/4091], Loss: 818.1824\n",
      "Epoch [9/100], Step [700/4091], Loss: 806.9783\n",
      "Epoch [9/100], Step [800/4091], Loss: 789.1744\n",
      "Epoch [9/100], Step [900/4091], Loss: 614.9525\n",
      "Epoch [9/100], Step [1000/4091], Loss: 510.5206\n",
      "Epoch [9/100], Step [1100/4091], Loss: 726.8813\n",
      "Epoch [9/100], Step [1200/4091], Loss: 747.5010\n",
      "Epoch [9/100], Step [1300/4091], Loss: 698.7288\n",
      "Epoch [9/100], Step [1400/4091], Loss: 761.6533\n",
      "Epoch [9/100], Step [1500/4091], Loss: 857.0540\n",
      "Epoch [9/100], Step [1600/4091], Loss: 820.4087\n",
      "Epoch [9/100], Step [1700/4091], Loss: 704.6281\n",
      "Epoch [9/100], Step [1800/4091], Loss: 619.9076\n",
      "Epoch [9/100], Step [1900/4091], Loss: 609.9723\n",
      "Epoch [9/100], Step [2000/4091], Loss: 735.4136\n",
      "Epoch [9/100], Step [2100/4091], Loss: 783.2536\n",
      "Epoch [9/100], Step [2200/4091], Loss: 570.5507\n",
      "Epoch [9/100], Step [2300/4091], Loss: 558.9289\n",
      "Epoch [9/100], Step [2400/4091], Loss: 611.4698\n",
      "Epoch [9/100], Step [2500/4091], Loss: 648.0397\n",
      "Epoch [9/100], Step [2600/4091], Loss: 601.8172\n",
      "Epoch [9/100], Step [2700/4091], Loss: 712.7593\n",
      "Epoch [9/100], Step [2800/4091], Loss: 794.3515\n",
      "Epoch [9/100], Step [2900/4091], Loss: 665.8929\n",
      "Epoch [9/100], Step [3000/4091], Loss: 538.9746\n",
      "Epoch [9/100], Step [3100/4091], Loss: 880.6128\n",
      "Epoch [9/100], Step [3200/4091], Loss: 796.6552\n",
      "Epoch [9/100], Step [3300/4091], Loss: 658.4484\n",
      "Epoch [9/100], Step [3400/4091], Loss: 739.3019\n",
      "Epoch [9/100], Step [3500/4091], Loss: 696.7523\n",
      "Epoch [9/100], Step [3600/4091], Loss: 773.4494\n",
      "Epoch [9/100], Step [3700/4091], Loss: 578.0321\n",
      "Epoch [9/100], Step [3800/4091], Loss: 533.6602\n",
      "Epoch [9/100], Step [3900/4091], Loss: 962.0523\n",
      "Epoch [9/100], Step [4000/4091], Loss: 857.5691\n",
      "Epoch [10/100], Step [100/4091], Loss: 782.6827\n",
      "Epoch [10/100], Step [200/4091], Loss: 543.2481\n",
      "Epoch [10/100], Step [300/4091], Loss: 619.1279\n",
      "Epoch [10/100], Step [400/4091], Loss: 854.8829\n",
      "Epoch [10/100], Step [500/4091], Loss: 559.6694\n",
      "Epoch [10/100], Step [600/4091], Loss: 603.7294\n",
      "Epoch [10/100], Step [700/4091], Loss: 669.3713\n",
      "Epoch [10/100], Step [800/4091], Loss: 630.0925\n",
      "Epoch [10/100], Step [900/4091], Loss: 930.9501\n",
      "Epoch [10/100], Step [1000/4091], Loss: 758.3387\n",
      "Epoch [10/100], Step [1100/4091], Loss: 732.7259\n",
      "Epoch [10/100], Step [1200/4091], Loss: 573.2026\n",
      "Epoch [10/100], Step [1300/4091], Loss: 733.3099\n",
      "Epoch [10/100], Step [1400/4091], Loss: 550.8961\n",
      "Epoch [10/100], Step [1500/4091], Loss: 523.5303\n",
      "Epoch [10/100], Step [1600/4091], Loss: 502.8714\n",
      "Epoch [10/100], Step [1700/4091], Loss: 592.0973\n",
      "Epoch [10/100], Step [1800/4091], Loss: 520.4684\n",
      "Epoch [10/100], Step [1900/4091], Loss: 824.1693\n",
      "Epoch [10/100], Step [2000/4091], Loss: 647.1675\n",
      "Epoch [10/100], Step [2100/4091], Loss: 843.1355\n",
      "Epoch [10/100], Step [2200/4091], Loss: 841.0182\n",
      "Epoch [10/100], Step [2300/4091], Loss: 501.3534\n",
      "Epoch [10/100], Step [2400/4091], Loss: 725.4099\n",
      "Epoch [10/100], Step [2500/4091], Loss: 736.1420\n",
      "Epoch [10/100], Step [2600/4091], Loss: 614.7900\n",
      "Epoch [10/100], Step [2700/4091], Loss: 808.1117\n",
      "Epoch [10/100], Step [2800/4091], Loss: 792.7295\n",
      "Epoch [10/100], Step [2900/4091], Loss: 625.8807\n",
      "Epoch [10/100], Step [3000/4091], Loss: 973.1270\n",
      "Epoch [10/100], Step [3100/4091], Loss: 456.4467\n",
      "Epoch [10/100], Step [3200/4091], Loss: 608.4470\n",
      "Epoch [10/100], Step [3300/4091], Loss: 719.1338\n",
      "Epoch [10/100], Step [3400/4091], Loss: 839.8114\n",
      "Epoch [10/100], Step [3500/4091], Loss: 516.2758\n",
      "Epoch [10/100], Step [3600/4091], Loss: 767.1444\n",
      "Epoch [10/100], Step [3700/4091], Loss: 635.1716\n",
      "Epoch [10/100], Step [3800/4091], Loss: 495.0204\n",
      "Epoch [10/100], Step [3900/4091], Loss: 754.5200\n",
      "Epoch [10/100], Step [4000/4091], Loss: 672.0769\n",
      "Epoch [11/100], Step [100/4091], Loss: 677.3391\n",
      "Epoch [11/100], Step [200/4091], Loss: 761.2593\n",
      "Epoch [11/100], Step [300/4091], Loss: 637.9521\n",
      "Epoch [11/100], Step [400/4091], Loss: 624.6044\n",
      "Epoch [11/100], Step [500/4091], Loss: 582.5652\n",
      "Epoch [11/100], Step [600/4091], Loss: 671.8217\n",
      "Epoch [11/100], Step [700/4091], Loss: 683.2662\n",
      "Epoch [11/100], Step [800/4091], Loss: 539.1475\n",
      "Epoch [11/100], Step [900/4091], Loss: 447.7664\n",
      "Epoch [11/100], Step [1000/4091], Loss: 736.2521\n",
      "Epoch [11/100], Step [1100/4091], Loss: 461.5708\n",
      "Epoch [11/100], Step [1200/4091], Loss: 805.9387\n",
      "Epoch [11/100], Step [1300/4091], Loss: 753.1779\n",
      "Epoch [11/100], Step [1400/4091], Loss: 616.8215\n",
      "Epoch [11/100], Step [1500/4091], Loss: 806.0792\n",
      "Epoch [11/100], Step [1600/4091], Loss: 978.5463\n",
      "Epoch [11/100], Step [1700/4091], Loss: 864.1619\n",
      "Epoch [11/100], Step [1800/4091], Loss: 570.5040\n",
      "Epoch [11/100], Step [1900/4091], Loss: 897.4014\n",
      "Epoch [11/100], Step [2000/4091], Loss: 664.7321\n",
      "Epoch [11/100], Step [2100/4091], Loss: 460.1566\n",
      "Epoch [11/100], Step [2200/4091], Loss: 539.9124\n",
      "Epoch [11/100], Step [2300/4091], Loss: 706.4279\n",
      "Epoch [11/100], Step [2400/4091], Loss: 685.8055\n",
      "Epoch [11/100], Step [2500/4091], Loss: 570.0624\n",
      "Epoch [11/100], Step [2600/4091], Loss: 585.4865\n",
      "Epoch [11/100], Step [2700/4091], Loss: 572.9072\n",
      "Epoch [11/100], Step [2800/4091], Loss: 740.7439\n",
      "Epoch [11/100], Step [2900/4091], Loss: 721.2917\n",
      "Epoch [11/100], Step [3000/4091], Loss: 661.3849\n",
      "Epoch [11/100], Step [3100/4091], Loss: 593.2155\n",
      "Epoch [11/100], Step [3200/4091], Loss: 568.4189\n",
      "Epoch [11/100], Step [3300/4091], Loss: 584.5735\n",
      "Epoch [11/100], Step [3400/4091], Loss: 828.2767\n",
      "Epoch [11/100], Step [3500/4091], Loss: 807.7955\n",
      "Epoch [11/100], Step [3600/4091], Loss: 484.7273\n",
      "Epoch [11/100], Step [3700/4091], Loss: 623.1506\n",
      "Epoch [11/100], Step [3800/4091], Loss: 694.4456\n",
      "Epoch [11/100], Step [3900/4091], Loss: 763.2330\n",
      "Epoch [11/100], Step [4000/4091], Loss: 704.0309\n",
      "Epoch [12/100], Step [100/4091], Loss: 520.3239\n",
      "Epoch [12/100], Step [200/4091], Loss: 568.8581\n",
      "Epoch [12/100], Step [300/4091], Loss: 470.4458\n",
      "Epoch [12/100], Step [400/4091], Loss: 786.6653\n",
      "Epoch [12/100], Step [500/4091], Loss: 615.6041\n",
      "Epoch [12/100], Step [600/4091], Loss: 628.5054\n",
      "Epoch [12/100], Step [700/4091], Loss: 813.8165\n",
      "Epoch [12/100], Step [800/4091], Loss: 725.7144\n",
      "Epoch [12/100], Step [900/4091], Loss: 859.7528\n",
      "Epoch [12/100], Step [1000/4091], Loss: 723.7090\n",
      "Epoch [12/100], Step [1100/4091], Loss: 711.8456\n",
      "Epoch [12/100], Step [1200/4091], Loss: 397.4447\n",
      "Epoch [12/100], Step [1300/4091], Loss: 768.3544\n",
      "Epoch [12/100], Step [1400/4091], Loss: 663.2231\n",
      "Epoch [12/100], Step [1500/4091], Loss: 611.7197\n",
      "Epoch [12/100], Step [1600/4091], Loss: 552.5486\n",
      "Epoch [12/100], Step [1700/4091], Loss: 739.0129\n",
      "Epoch [12/100], Step [1800/4091], Loss: 634.1085\n",
      "Epoch [12/100], Step [1900/4091], Loss: 526.8732\n",
      "Epoch [12/100], Step [2000/4091], Loss: 730.6598\n",
      "Epoch [12/100], Step [2100/4091], Loss: 709.7023\n",
      "Epoch [12/100], Step [2200/4091], Loss: 758.9973\n",
      "Epoch [12/100], Step [2300/4091], Loss: 601.9402\n",
      "Epoch [12/100], Step [2400/4091], Loss: 853.7556\n",
      "Epoch [12/100], Step [2500/4091], Loss: 400.4667\n",
      "Epoch [12/100], Step [2600/4091], Loss: 565.4440\n",
      "Epoch [12/100], Step [2700/4091], Loss: 726.1910\n",
      "Epoch [12/100], Step [2800/4091], Loss: 798.5587\n",
      "Epoch [12/100], Step [2900/4091], Loss: 671.3555\n",
      "Epoch [12/100], Step [3000/4091], Loss: 626.0554\n",
      "Epoch [12/100], Step [3100/4091], Loss: 630.0898\n",
      "Epoch [12/100], Step [3200/4091], Loss: 559.8688\n",
      "Epoch [12/100], Step [3300/4091], Loss: 782.4135\n",
      "Epoch [12/100], Step [3400/4091], Loss: 647.4785\n",
      "Epoch [12/100], Step [3500/4091], Loss: 776.9244\n",
      "Epoch [12/100], Step [3600/4091], Loss: 506.0287\n",
      "Epoch [12/100], Step [3700/4091], Loss: 633.2715\n",
      "Epoch [12/100], Step [3800/4091], Loss: 549.7977\n",
      "Epoch [12/100], Step [3900/4091], Loss: 590.1531\n",
      "Epoch [12/100], Step [4000/4091], Loss: 734.5654\n",
      "Epoch [13/100], Step [100/4091], Loss: 647.4968\n",
      "Epoch [13/100], Step [200/4091], Loss: 802.7952\n",
      "Epoch [13/100], Step [300/4091], Loss: 789.7051\n",
      "Epoch [13/100], Step [400/4091], Loss: 642.6248\n",
      "Epoch [13/100], Step [500/4091], Loss: 606.5834\n",
      "Epoch [13/100], Step [600/4091], Loss: 741.2087\n",
      "Epoch [13/100], Step [700/4091], Loss: 913.0593\n",
      "Epoch [13/100], Step [800/4091], Loss: 399.4062\n",
      "Epoch [13/100], Step [900/4091], Loss: 659.4432\n",
      "Epoch [13/100], Step [1000/4091], Loss: 730.9910\n",
      "Epoch [13/100], Step [1100/4091], Loss: 821.3156\n",
      "Epoch [13/100], Step [1200/4091], Loss: 781.6876\n",
      "Epoch [13/100], Step [1300/4091], Loss: 667.1907\n",
      "Epoch [13/100], Step [1400/4091], Loss: 583.6192\n",
      "Epoch [13/100], Step [1500/4091], Loss: 690.6640\n",
      "Epoch [13/100], Step [1600/4091], Loss: 527.0472\n",
      "Epoch [13/100], Step [1700/4091], Loss: 634.8600\n",
      "Epoch [13/100], Step [1800/4091], Loss: 458.4457\n",
      "Epoch [13/100], Step [1900/4091], Loss: 760.9210\n",
      "Epoch [13/100], Step [2000/4091], Loss: 804.2526\n",
      "Epoch [13/100], Step [2100/4091], Loss: 623.6694\n",
      "Epoch [13/100], Step [2200/4091], Loss: 710.4062\n",
      "Epoch [13/100], Step [2300/4091], Loss: 537.8042\n",
      "Epoch [13/100], Step [2400/4091], Loss: 560.4883\n",
      "Epoch [13/100], Step [2500/4091], Loss: 939.4467\n",
      "Epoch [13/100], Step [2600/4091], Loss: 765.5018\n",
      "Epoch [13/100], Step [2700/4091], Loss: 750.6808\n",
      "Epoch [13/100], Step [2800/4091], Loss: 620.3962\n",
      "Epoch [13/100], Step [2900/4091], Loss: 607.0964\n",
      "Epoch [13/100], Step [3000/4091], Loss: 581.9686\n",
      "Epoch [13/100], Step [3100/4091], Loss: 629.8578\n",
      "Epoch [13/100], Step [3200/4091], Loss: 723.4354\n",
      "Epoch [13/100], Step [3300/4091], Loss: 775.7929\n",
      "Epoch [13/100], Step [3400/4091], Loss: 514.6065\n",
      "Epoch [13/100], Step [3500/4091], Loss: 739.0591\n",
      "Epoch [13/100], Step [3600/4091], Loss: 572.4790\n",
      "Epoch [13/100], Step [3700/4091], Loss: 697.7789\n",
      "Epoch [13/100], Step [3800/4091], Loss: 662.3644\n",
      "Epoch [13/100], Step [3900/4091], Loss: 523.5384\n",
      "Epoch [13/100], Step [4000/4091], Loss: 907.6543\n",
      "Epoch [14/100], Step [100/4091], Loss: 574.2880\n",
      "Epoch [14/100], Step [200/4091], Loss: 1018.1743\n",
      "Epoch [14/100], Step [300/4091], Loss: 688.1496\n",
      "Epoch [14/100], Step [400/4091], Loss: 652.8035\n",
      "Epoch [14/100], Step [500/4091], Loss: 634.8324\n",
      "Epoch [14/100], Step [600/4091], Loss: 684.5931\n",
      "Epoch [14/100], Step [700/4091], Loss: 732.9059\n",
      "Epoch [14/100], Step [800/4091], Loss: 548.6422\n",
      "Epoch [14/100], Step [900/4091], Loss: 563.6055\n",
      "Epoch [14/100], Step [1000/4091], Loss: 793.6410\n",
      "Epoch [14/100], Step [1100/4091], Loss: 635.2962\n",
      "Epoch [14/100], Step [1200/4091], Loss: 688.8204\n",
      "Epoch [14/100], Step [1300/4091], Loss: 631.7783\n",
      "Epoch [14/100], Step [1400/4091], Loss: 599.2368\n",
      "Epoch [14/100], Step [1500/4091], Loss: 542.3237\n",
      "Epoch [14/100], Step [1600/4091], Loss: 514.8163\n",
      "Epoch [14/100], Step [1700/4091], Loss: 612.6512\n",
      "Epoch [14/100], Step [1800/4091], Loss: 594.4409\n",
      "Epoch [14/100], Step [1900/4091], Loss: 749.6633\n",
      "Epoch [14/100], Step [2000/4091], Loss: 607.0451\n",
      "Epoch [14/100], Step [2100/4091], Loss: 558.5576\n",
      "Epoch [14/100], Step [2200/4091], Loss: 700.2759\n",
      "Epoch [14/100], Step [2300/4091], Loss: 587.4839\n",
      "Epoch [14/100], Step [2400/4091], Loss: 707.3266\n",
      "Epoch [14/100], Step [2500/4091], Loss: 606.1741\n",
      "Epoch [14/100], Step [2600/4091], Loss: 710.0073\n",
      "Epoch [14/100], Step [2700/4091], Loss: 479.1320\n",
      "Epoch [14/100], Step [2800/4091], Loss: 837.4757\n",
      "Epoch [14/100], Step [2900/4091], Loss: 636.6111\n",
      "Epoch [14/100], Step [3000/4091], Loss: 631.8464\n",
      "Epoch [14/100], Step [3100/4091], Loss: 741.1406\n",
      "Epoch [14/100], Step [3200/4091], Loss: 706.8690\n",
      "Epoch [14/100], Step [3300/4091], Loss: 508.6657\n",
      "Epoch [14/100], Step [3400/4091], Loss: 663.1928\n",
      "Epoch [14/100], Step [3500/4091], Loss: 532.2139\n",
      "Epoch [14/100], Step [3600/4091], Loss: 696.5546\n",
      "Epoch [14/100], Step [3700/4091], Loss: 532.0757\n",
      "Epoch [14/100], Step [3800/4091], Loss: 609.8051\n",
      "Epoch [14/100], Step [3900/4091], Loss: 653.0974\n",
      "Epoch [14/100], Step [4000/4091], Loss: 933.4600\n",
      "Epoch [15/100], Step [100/4091], Loss: 654.4135\n",
      "Epoch [15/100], Step [200/4091], Loss: 802.5812\n",
      "Epoch [15/100], Step [300/4091], Loss: 995.6599\n",
      "Epoch [15/100], Step [400/4091], Loss: 945.8585\n",
      "Epoch [15/100], Step [500/4091], Loss: 605.3622\n",
      "Epoch [15/100], Step [600/4091], Loss: 630.5429\n",
      "Epoch [15/100], Step [700/4091], Loss: 499.1873\n",
      "Epoch [15/100], Step [800/4091], Loss: 618.0648\n",
      "Epoch [15/100], Step [900/4091], Loss: 629.4816\n",
      "Epoch [15/100], Step [1000/4091], Loss: 648.8677\n",
      "Epoch [15/100], Step [1100/4091], Loss: 851.0535\n",
      "Epoch [15/100], Step [1200/4091], Loss: 501.7295\n",
      "Epoch [15/100], Step [1300/4091], Loss: 533.9898\n",
      "Epoch [15/100], Step [1400/4091], Loss: 636.8530\n",
      "Epoch [15/100], Step [1500/4091], Loss: 631.5444\n",
      "Epoch [15/100], Step [1600/4091], Loss: 631.7012\n",
      "Epoch [15/100], Step [1700/4091], Loss: 502.3708\n",
      "Epoch [15/100], Step [1800/4091], Loss: 761.4313\n",
      "Epoch [15/100], Step [1900/4091], Loss: 471.9451\n",
      "Epoch [15/100], Step [2000/4091], Loss: 799.1682\n",
      "Epoch [15/100], Step [2100/4091], Loss: 871.8843\n",
      "Epoch [15/100], Step [2200/4091], Loss: 736.9751\n",
      "Epoch [15/100], Step [2300/4091], Loss: 666.3499\n",
      "Epoch [15/100], Step [2400/4091], Loss: 745.4210\n",
      "Epoch [15/100], Step [2500/4091], Loss: 693.6370\n",
      "Epoch [15/100], Step [2600/4091], Loss: 677.3596\n",
      "Epoch [15/100], Step [2700/4091], Loss: 682.4440\n",
      "Epoch [15/100], Step [2800/4091], Loss: 714.1479\n",
      "Epoch [15/100], Step [2900/4091], Loss: 622.6108\n",
      "Epoch [15/100], Step [3000/4091], Loss: 555.5904\n",
      "Epoch [15/100], Step [3100/4091], Loss: 1003.7236\n",
      "Epoch [15/100], Step [3200/4091], Loss: 490.2987\n",
      "Epoch [15/100], Step [3300/4091], Loss: 660.6779\n",
      "Epoch [15/100], Step [3400/4091], Loss: 580.4815\n",
      "Epoch [15/100], Step [3500/4091], Loss: 669.3089\n",
      "Epoch [15/100], Step [3600/4091], Loss: 791.1993\n",
      "Epoch [15/100], Step [3700/4091], Loss: 468.9628\n",
      "Epoch [15/100], Step [3800/4091], Loss: 676.4905\n",
      "Epoch [15/100], Step [3900/4091], Loss: 478.6978\n",
      "Epoch [15/100], Step [4000/4091], Loss: 642.0657\n",
      "Epoch [16/100], Step [100/4091], Loss: 543.1810\n",
      "Epoch [16/100], Step [200/4091], Loss: 826.8201\n",
      "Epoch [16/100], Step [300/4091], Loss: 639.1099\n",
      "Epoch [16/100], Step [400/4091], Loss: 483.1266\n",
      "Epoch [16/100], Step [500/4091], Loss: 876.3546\n",
      "Epoch [16/100], Step [600/4091], Loss: 651.5792\n",
      "Epoch [16/100], Step [700/4091], Loss: 594.5835\n",
      "Epoch [16/100], Step [800/4091], Loss: 915.4890\n",
      "Epoch [16/100], Step [900/4091], Loss: 841.3582\n",
      "Epoch [16/100], Step [1000/4091], Loss: 606.5938\n",
      "Epoch [16/100], Step [1100/4091], Loss: 622.9917\n",
      "Epoch [16/100], Step [1200/4091], Loss: 1015.4335\n",
      "Epoch [16/100], Step [1300/4091], Loss: 630.8066\n",
      "Epoch [16/100], Step [1400/4091], Loss: 873.3069\n",
      "Epoch [16/100], Step [1500/4091], Loss: 823.7705\n",
      "Epoch [16/100], Step [1600/4091], Loss: 918.9286\n",
      "Epoch [16/100], Step [1700/4091], Loss: 872.8583\n",
      "Epoch [16/100], Step [1800/4091], Loss: 702.6257\n",
      "Epoch [16/100], Step [1900/4091], Loss: 580.8774\n",
      "Epoch [16/100], Step [2000/4091], Loss: 658.1545\n",
      "Epoch [16/100], Step [2100/4091], Loss: 475.2162\n",
      "Epoch [16/100], Step [2200/4091], Loss: 643.8259\n",
      "Epoch [16/100], Step [2300/4091], Loss: 1166.7770\n",
      "Epoch [16/100], Step [2400/4091], Loss: 979.9525\n",
      "Epoch [16/100], Step [2500/4091], Loss: 543.9321\n",
      "Epoch [16/100], Step [2600/4091], Loss: 610.3728\n",
      "Epoch [16/100], Step [2700/4091], Loss: 545.5010\n",
      "Epoch [16/100], Step [2800/4091], Loss: 779.9323\n",
      "Epoch [16/100], Step [2900/4091], Loss: 679.1991\n",
      "Epoch [16/100], Step [3000/4091], Loss: 359.4794\n",
      "Epoch [16/100], Step [3100/4091], Loss: 648.8817\n",
      "Epoch [16/100], Step [3200/4091], Loss: 527.8547\n",
      "Epoch [16/100], Step [3300/4091], Loss: 801.1580\n",
      "Epoch [16/100], Step [3400/4091], Loss: 581.1809\n",
      "Epoch [16/100], Step [3500/4091], Loss: 595.4286\n",
      "Epoch [16/100], Step [3600/4091], Loss: 596.0667\n",
      "Epoch [16/100], Step [3700/4091], Loss: 550.1976\n",
      "Epoch [16/100], Step [3800/4091], Loss: 531.5786\n",
      "Epoch [16/100], Step [3900/4091], Loss: 763.4580\n",
      "Epoch [16/100], Step [4000/4091], Loss: 811.6760\n",
      "Epoch [17/100], Step [100/4091], Loss: 834.9083\n",
      "Epoch [17/100], Step [200/4091], Loss: 830.9413\n",
      "Epoch [17/100], Step [300/4091], Loss: 838.6222\n",
      "Epoch [17/100], Step [400/4091], Loss: 479.3486\n",
      "Epoch [17/100], Step [500/4091], Loss: 596.9657\n",
      "Epoch [17/100], Step [600/4091], Loss: 624.3729\n",
      "Epoch [17/100], Step [700/4091], Loss: 523.9170\n",
      "Epoch [17/100], Step [800/4091], Loss: 620.3336\n",
      "Epoch [17/100], Step [900/4091], Loss: 576.5163\n",
      "Epoch [17/100], Step [1000/4091], Loss: 802.0576\n",
      "Epoch [17/100], Step [1100/4091], Loss: 636.9420\n",
      "Epoch [17/100], Step [1200/4091], Loss: 821.1237\n",
      "Epoch [17/100], Step [1300/4091], Loss: 607.5209\n",
      "Epoch [17/100], Step [1400/4091], Loss: 708.8825\n",
      "Epoch [17/100], Step [1500/4091], Loss: 587.2852\n",
      "Epoch [17/100], Step [1600/4091], Loss: 500.2863\n",
      "Epoch [17/100], Step [1700/4091], Loss: 719.5388\n",
      "Epoch [17/100], Step [1800/4091], Loss: 762.8143\n",
      "Epoch [17/100], Step [1900/4091], Loss: 549.5032\n",
      "Epoch [17/100], Step [2000/4091], Loss: 669.7589\n",
      "Epoch [17/100], Step [2100/4091], Loss: 698.7120\n",
      "Epoch [17/100], Step [2200/4091], Loss: 658.6968\n",
      "Epoch [17/100], Step [2300/4091], Loss: 648.4819\n",
      "Epoch [17/100], Step [2400/4091], Loss: 612.5325\n",
      "Epoch [17/100], Step [2500/4091], Loss: 738.8167\n",
      "Epoch [17/100], Step [2600/4091], Loss: 567.5430\n",
      "Epoch [17/100], Step [2700/4091], Loss: 563.9008\n",
      "Epoch [17/100], Step [2800/4091], Loss: 1038.4000\n",
      "Epoch [17/100], Step [2900/4091], Loss: 745.7305\n",
      "Epoch [17/100], Step [3000/4091], Loss: 582.6486\n",
      "Epoch [17/100], Step [3100/4091], Loss: 614.3481\n",
      "Epoch [17/100], Step [3200/4091], Loss: 782.6503\n",
      "Epoch [17/100], Step [3300/4091], Loss: 502.3654\n",
      "Epoch [17/100], Step [3400/4091], Loss: 645.4545\n",
      "Epoch [17/100], Step [3500/4091], Loss: 537.2986\n",
      "Epoch [17/100], Step [3600/4091], Loss: 827.4460\n",
      "Epoch [17/100], Step [3700/4091], Loss: 742.1728\n",
      "Epoch [17/100], Step [3800/4091], Loss: 489.9352\n",
      "Epoch [17/100], Step [3900/4091], Loss: 815.0485\n",
      "Epoch [17/100], Step [4000/4091], Loss: 505.3722\n",
      "Epoch [18/100], Step [100/4091], Loss: 596.0558\n",
      "Epoch [18/100], Step [200/4091], Loss: 612.1260\n",
      "Epoch [18/100], Step [300/4091], Loss: 652.7550\n",
      "Epoch [18/100], Step [400/4091], Loss: 592.1536\n",
      "Epoch [18/100], Step [500/4091], Loss: 781.0726\n",
      "Epoch [18/100], Step [600/4091], Loss: 564.1180\n",
      "Epoch [18/100], Step [700/4091], Loss: 496.1043\n",
      "Epoch [18/100], Step [800/4091], Loss: 403.2943\n",
      "Epoch [18/100], Step [900/4091], Loss: 616.1580\n",
      "Epoch [18/100], Step [1000/4091], Loss: 565.7143\n",
      "Epoch [18/100], Step [1100/4091], Loss: 713.8957\n",
      "Epoch [18/100], Step [1200/4091], Loss: 734.4630\n",
      "Epoch [18/100], Step [1300/4091], Loss: 543.7228\n",
      "Epoch [18/100], Step [1400/4091], Loss: 569.5656\n",
      "Epoch [18/100], Step [1500/4091], Loss: 769.5482\n",
      "Epoch [18/100], Step [1600/4091], Loss: 869.4229\n",
      "Epoch [18/100], Step [1700/4091], Loss: 669.6619\n",
      "Epoch [18/100], Step [1800/4091], Loss: 737.2724\n",
      "Epoch [18/100], Step [1900/4091], Loss: 524.5001\n",
      "Epoch [18/100], Step [2000/4091], Loss: 636.8813\n",
      "Epoch [18/100], Step [2100/4091], Loss: 517.8932\n",
      "Epoch [18/100], Step [2200/4091], Loss: 543.8353\n",
      "Epoch [18/100], Step [2300/4091], Loss: 756.3931\n",
      "Epoch [18/100], Step [2400/4091], Loss: 563.0733\n",
      "Epoch [18/100], Step [2500/4091], Loss: 702.1011\n",
      "Epoch [18/100], Step [2600/4091], Loss: 837.4338\n",
      "Epoch [18/100], Step [2700/4091], Loss: 814.2173\n",
      "Epoch [18/100], Step [2800/4091], Loss: 911.3875\n",
      "Epoch [18/100], Step [2900/4091], Loss: 563.9261\n",
      "Epoch [18/100], Step [3000/4091], Loss: 729.7200\n",
      "Epoch [18/100], Step [3100/4091], Loss: 426.4299\n",
      "Epoch [18/100], Step [3200/4091], Loss: 708.0063\n",
      "Epoch [18/100], Step [3300/4091], Loss: 648.6631\n",
      "Epoch [18/100], Step [3400/4091], Loss: 622.4752\n",
      "Epoch [18/100], Step [3500/4091], Loss: 639.1948\n",
      "Epoch [18/100], Step [3600/4091], Loss: 808.2791\n",
      "Epoch [18/100], Step [3700/4091], Loss: 468.1583\n",
      "Epoch [18/100], Step [3800/4091], Loss: 640.2924\n",
      "Epoch [18/100], Step [3900/4091], Loss: 566.8825\n",
      "Epoch [18/100], Step [4000/4091], Loss: 794.9136\n",
      "Epoch [19/100], Step [100/4091], Loss: 707.9624\n",
      "Epoch [19/100], Step [200/4091], Loss: 401.9961\n",
      "Epoch [19/100], Step [300/4091], Loss: 551.2814\n",
      "Epoch [19/100], Step [400/4091], Loss: 657.8390\n",
      "Epoch [19/100], Step [500/4091], Loss: 627.4742\n",
      "Epoch [19/100], Step [600/4091], Loss: 711.4238\n",
      "Epoch [19/100], Step [700/4091], Loss: 738.7395\n",
      "Epoch [19/100], Step [800/4091], Loss: 669.5846\n",
      "Epoch [19/100], Step [900/4091], Loss: 401.3964\n",
      "Epoch [19/100], Step [1000/4091], Loss: 797.0701\n",
      "Epoch [19/100], Step [1100/4091], Loss: 578.8158\n",
      "Epoch [19/100], Step [1200/4091], Loss: 696.6890\n",
      "Epoch [19/100], Step [1300/4091], Loss: 520.9868\n",
      "Epoch [19/100], Step [1400/4091], Loss: 839.0415\n",
      "Epoch [19/100], Step [1500/4091], Loss: 581.5875\n",
      "Epoch [19/100], Step [1600/4091], Loss: 470.9799\n",
      "Epoch [19/100], Step [1700/4091], Loss: 777.6511\n",
      "Epoch [19/100], Step [1800/4091], Loss: 637.1453\n",
      "Epoch [19/100], Step [1900/4091], Loss: 606.1645\n",
      "Epoch [19/100], Step [2000/4091], Loss: 492.1895\n",
      "Epoch [19/100], Step [2100/4091], Loss: 755.4830\n",
      "Epoch [19/100], Step [2200/4091], Loss: 737.1005\n",
      "Epoch [19/100], Step [2300/4091], Loss: 883.3369\n",
      "Epoch [19/100], Step [2400/4091], Loss: 609.2112\n",
      "Epoch [19/100], Step [2500/4091], Loss: 690.2501\n",
      "Epoch [19/100], Step [2600/4091], Loss: 681.2986\n",
      "Epoch [19/100], Step [2700/4091], Loss: 551.9484\n",
      "Epoch [19/100], Step [2800/4091], Loss: 520.5881\n",
      "Epoch [19/100], Step [2900/4091], Loss: 483.4061\n",
      "Epoch [19/100], Step [3000/4091], Loss: 634.3267\n",
      "Epoch [19/100], Step [3100/4091], Loss: 439.2893\n",
      "Epoch [19/100], Step [3200/4091], Loss: 730.2979\n",
      "Epoch [19/100], Step [3300/4091], Loss: 651.5023\n",
      "Epoch [19/100], Step [3400/4091], Loss: 847.6766\n",
      "Epoch [19/100], Step [3500/4091], Loss: 889.8310\n",
      "Epoch [19/100], Step [3600/4091], Loss: 521.9210\n",
      "Epoch [19/100], Step [3700/4091], Loss: 460.5669\n",
      "Epoch [19/100], Step [3800/4091], Loss: 611.3889\n",
      "Epoch [19/100], Step [3900/4091], Loss: 605.2930\n",
      "Epoch [19/100], Step [4000/4091], Loss: 785.1057\n",
      "Epoch [20/100], Step [100/4091], Loss: 614.7180\n",
      "Epoch [20/100], Step [200/4091], Loss: 589.7681\n",
      "Epoch [20/100], Step [300/4091], Loss: 559.3869\n",
      "Epoch [20/100], Step [400/4091], Loss: 788.9868\n",
      "Epoch [20/100], Step [500/4091], Loss: 959.7284\n",
      "Epoch [20/100], Step [600/4091], Loss: 667.1688\n",
      "Epoch [20/100], Step [700/4091], Loss: 743.0591\n",
      "Epoch [20/100], Step [800/4091], Loss: 504.0928\n",
      "Epoch [20/100], Step [900/4091], Loss: 563.7673\n",
      "Epoch [20/100], Step [1000/4091], Loss: 722.8788\n",
      "Epoch [20/100], Step [1100/4091], Loss: 795.0724\n",
      "Epoch [20/100], Step [1200/4091], Loss: 925.4952\n",
      "Epoch [20/100], Step [1300/4091], Loss: 728.1688\n",
      "Epoch [20/100], Step [1400/4091], Loss: 693.1403\n",
      "Epoch [20/100], Step [1500/4091], Loss: 720.2075\n",
      "Epoch [20/100], Step [1600/4091], Loss: 707.3751\n",
      "Epoch [20/100], Step [1700/4091], Loss: 617.2733\n",
      "Epoch [20/100], Step [1800/4091], Loss: 743.4606\n",
      "Epoch [20/100], Step [1900/4091], Loss: 518.2874\n",
      "Epoch [20/100], Step [2000/4091], Loss: 779.0077\n",
      "Epoch [20/100], Step [2100/4091], Loss: 749.9683\n",
      "Epoch [20/100], Step [2200/4091], Loss: 679.2369\n",
      "Epoch [20/100], Step [2300/4091], Loss: 560.5809\n",
      "Epoch [20/100], Step [2400/4091], Loss: 587.9760\n",
      "Epoch [20/100], Step [2500/4091], Loss: 581.6475\n",
      "Epoch [20/100], Step [2600/4091], Loss: 500.2300\n",
      "Epoch [20/100], Step [2700/4091], Loss: 780.2512\n",
      "Epoch [20/100], Step [2800/4091], Loss: 580.5200\n",
      "Epoch [20/100], Step [2900/4091], Loss: 585.0154\n",
      "Epoch [20/100], Step [3000/4091], Loss: 682.0309\n",
      "Epoch [20/100], Step [3100/4091], Loss: 668.3336\n",
      "Epoch [20/100], Step [3200/4091], Loss: 725.4904\n",
      "Epoch [20/100], Step [3300/4091], Loss: 1072.6116\n",
      "Epoch [20/100], Step [3400/4091], Loss: 710.0308\n",
      "Epoch [20/100], Step [3500/4091], Loss: 723.4014\n",
      "Epoch [20/100], Step [3600/4091], Loss: 754.7983\n",
      "Epoch [20/100], Step [3700/4091], Loss: 511.6620\n",
      "Epoch [20/100], Step [3800/4091], Loss: 726.9942\n",
      "Epoch [20/100], Step [3900/4091], Loss: 810.0598\n",
      "Epoch [20/100], Step [4000/4091], Loss: 612.4460\n",
      "Epoch [21/100], Step [100/4091], Loss: 564.8910\n",
      "Epoch [21/100], Step [200/4091], Loss: 821.0043\n",
      "Epoch [21/100], Step [300/4091], Loss: 566.1133\n",
      "Epoch [21/100], Step [400/4091], Loss: 662.8931\n",
      "Epoch [21/100], Step [500/4091], Loss: 695.8544\n",
      "Epoch [21/100], Step [600/4091], Loss: 711.3889\n",
      "Epoch [21/100], Step [700/4091], Loss: 873.1616\n",
      "Epoch [21/100], Step [800/4091], Loss: 577.0133\n",
      "Epoch [21/100], Step [900/4091], Loss: 662.8096\n",
      "Epoch [21/100], Step [1000/4091], Loss: 572.4689\n",
      "Epoch [21/100], Step [1100/4091], Loss: 760.9312\n",
      "Epoch [21/100], Step [1200/4091], Loss: 520.4991\n",
      "Epoch [21/100], Step [1300/4091], Loss: 902.3767\n",
      "Epoch [21/100], Step [1400/4091], Loss: 662.9104\n",
      "Epoch [21/100], Step [1500/4091], Loss: 861.0330\n",
      "Epoch [21/100], Step [1600/4091], Loss: 710.3484\n",
      "Epoch [21/100], Step [1700/4091], Loss: 871.6342\n",
      "Epoch [21/100], Step [1800/4091], Loss: 719.6776\n",
      "Epoch [21/100], Step [1900/4091], Loss: 659.4043\n",
      "Epoch [21/100], Step [2000/4091], Loss: 594.2877\n",
      "Epoch [21/100], Step [2100/4091], Loss: 697.6353\n",
      "Epoch [21/100], Step [2200/4091], Loss: 744.1061\n",
      "Epoch [21/100], Step [2300/4091], Loss: 548.0576\n",
      "Epoch [21/100], Step [2400/4091], Loss: 630.7899\n",
      "Epoch [21/100], Step [2500/4091], Loss: 712.2649\n",
      "Epoch [21/100], Step [2600/4091], Loss: 843.4164\n",
      "Epoch [21/100], Step [2700/4091], Loss: 609.8298\n",
      "Epoch [21/100], Step [2800/4091], Loss: 638.9042\n",
      "Epoch [21/100], Step [2900/4091], Loss: 566.2576\n",
      "Epoch [21/100], Step [3000/4091], Loss: 784.2894\n",
      "Epoch [21/100], Step [3100/4091], Loss: 823.1854\n",
      "Epoch [21/100], Step [3200/4091], Loss: 612.4049\n",
      "Epoch [21/100], Step [3300/4091], Loss: 610.3917\n",
      "Epoch [21/100], Step [3400/4091], Loss: 716.1476\n",
      "Epoch [21/100], Step [3500/4091], Loss: 653.3317\n",
      "Epoch [21/100], Step [3600/4091], Loss: 794.9246\n",
      "Epoch [21/100], Step [3700/4091], Loss: 621.9941\n",
      "Epoch [21/100], Step [3800/4091], Loss: 612.7614\n",
      "Epoch [21/100], Step [3900/4091], Loss: 736.5735\n",
      "Epoch [21/100], Step [4000/4091], Loss: 669.3785\n",
      "Epoch [22/100], Step [100/4091], Loss: 364.0886\n",
      "Epoch [22/100], Step [200/4091], Loss: 642.2150\n",
      "Epoch [22/100], Step [300/4091], Loss: 642.3359\n",
      "Epoch [22/100], Step [400/4091], Loss: 488.6143\n",
      "Epoch [22/100], Step [500/4091], Loss: 581.7750\n",
      "Epoch [22/100], Step [600/4091], Loss: 653.4587\n",
      "Epoch [22/100], Step [700/4091], Loss: 932.2154\n",
      "Epoch [22/100], Step [800/4091], Loss: 753.6141\n",
      "Epoch [22/100], Step [900/4091], Loss: 807.3792\n",
      "Epoch [22/100], Step [1000/4091], Loss: 446.3910\n",
      "Epoch [22/100], Step [1100/4091], Loss: 503.7177\n",
      "Epoch [22/100], Step [1200/4091], Loss: 736.5236\n",
      "Epoch [22/100], Step [1300/4091], Loss: 581.5927\n",
      "Epoch [22/100], Step [1400/4091], Loss: 566.5848\n",
      "Epoch [22/100], Step [1500/4091], Loss: 711.7662\n",
      "Epoch [22/100], Step [1600/4091], Loss: 685.2672\n",
      "Epoch [22/100], Step [1700/4091], Loss: 625.6345\n",
      "Epoch [22/100], Step [1800/4091], Loss: 672.5967\n",
      "Epoch [22/100], Step [1900/4091], Loss: 700.6829\n",
      "Epoch [22/100], Step [2000/4091], Loss: 676.6038\n",
      "Epoch [22/100], Step [2100/4091], Loss: 782.3699\n",
      "Epoch [22/100], Step [2200/4091], Loss: 663.0361\n",
      "Epoch [22/100], Step [2300/4091], Loss: 455.4069\n",
      "Epoch [22/100], Step [2400/4091], Loss: 547.7742\n",
      "Epoch [22/100], Step [2500/4091], Loss: 777.9116\n",
      "Epoch [22/100], Step [2600/4091], Loss: 695.1027\n",
      "Epoch [22/100], Step [2700/4091], Loss: 867.2159\n",
      "Epoch [22/100], Step [2800/4091], Loss: 563.3848\n",
      "Epoch [22/100], Step [2900/4091], Loss: 771.2757\n",
      "Epoch [22/100], Step [3000/4091], Loss: 533.4340\n",
      "Epoch [22/100], Step [3100/4091], Loss: 573.3412\n",
      "Epoch [22/100], Step [3200/4091], Loss: 573.8661\n",
      "Epoch [22/100], Step [3300/4091], Loss: 638.2308\n",
      "Epoch [22/100], Step [3400/4091], Loss: 869.8716\n",
      "Epoch [22/100], Step [3500/4091], Loss: 763.5707\n",
      "Epoch [22/100], Step [3600/4091], Loss: 787.6221\n",
      "Epoch [22/100], Step [3700/4091], Loss: 461.2191\n",
      "Epoch [22/100], Step [3800/4091], Loss: 595.0859\n",
      "Epoch [22/100], Step [3900/4091], Loss: 501.6600\n",
      "Epoch [22/100], Step [4000/4091], Loss: 783.6306\n",
      "Epoch [23/100], Step [100/4091], Loss: 724.8791\n",
      "Epoch [23/100], Step [200/4091], Loss: 648.4785\n",
      "Epoch [23/100], Step [300/4091], Loss: 601.1441\n",
      "Epoch [23/100], Step [400/4091], Loss: 567.8665\n",
      "Epoch [23/100], Step [500/4091], Loss: 867.6080\n",
      "Epoch [23/100], Step [600/4091], Loss: 844.4629\n",
      "Epoch [23/100], Step [700/4091], Loss: 666.6507\n",
      "Epoch [23/100], Step [800/4091], Loss: 457.5744\n",
      "Epoch [23/100], Step [900/4091], Loss: 612.6891\n",
      "Epoch [23/100], Step [1000/4091], Loss: 587.6198\n",
      "Epoch [23/100], Step [1100/4091], Loss: 715.2137\n",
      "Epoch [23/100], Step [1200/4091], Loss: 687.6597\n",
      "Epoch [23/100], Step [1300/4091], Loss: 769.3828\n",
      "Epoch [23/100], Step [1400/4091], Loss: 748.4014\n",
      "Epoch [23/100], Step [1500/4091], Loss: 518.0733\n",
      "Epoch [23/100], Step [1600/4091], Loss: 700.7588\n",
      "Epoch [23/100], Step [1700/4091], Loss: 474.8505\n",
      "Epoch [23/100], Step [1800/4091], Loss: 741.7513\n",
      "Epoch [23/100], Step [1900/4091], Loss: 455.5274\n",
      "Epoch [23/100], Step [2000/4091], Loss: 554.5330\n",
      "Epoch [23/100], Step [2100/4091], Loss: 1056.4351\n",
      "Epoch [23/100], Step [2200/4091], Loss: 524.1495\n",
      "Epoch [23/100], Step [2300/4091], Loss: 814.6225\n",
      "Epoch [23/100], Step [2400/4091], Loss: 525.9874\n",
      "Epoch [23/100], Step [2500/4091], Loss: 777.6262\n",
      "Epoch [23/100], Step [2600/4091], Loss: 657.7965\n",
      "Epoch [23/100], Step [2700/4091], Loss: 621.7765\n",
      "Epoch [23/100], Step [2800/4091], Loss: 489.9377\n",
      "Epoch [23/100], Step [2900/4091], Loss: 646.3961\n",
      "Epoch [23/100], Step [3000/4091], Loss: 713.2265\n",
      "Epoch [23/100], Step [3100/4091], Loss: 627.1447\n",
      "Epoch [23/100], Step [3200/4091], Loss: 561.8108\n",
      "Epoch [23/100], Step [3300/4091], Loss: 603.8184\n",
      "Epoch [23/100], Step [3400/4091], Loss: 497.7914\n",
      "Epoch [23/100], Step [3500/4091], Loss: 551.8092\n",
      "Epoch [23/100], Step [3600/4091], Loss: 774.8885\n",
      "Epoch [23/100], Step [3700/4091], Loss: 637.3563\n",
      "Epoch [23/100], Step [3800/4091], Loss: 716.0343\n",
      "Epoch [23/100], Step [3900/4091], Loss: 854.6730\n",
      "Epoch [23/100], Step [4000/4091], Loss: 566.4581\n",
      "Epoch [24/100], Step [100/4091], Loss: 621.3010\n",
      "Epoch [24/100], Step [200/4091], Loss: 576.9894\n",
      "Epoch [24/100], Step [300/4091], Loss: 894.1068\n",
      "Epoch [24/100], Step [400/4091], Loss: 604.4116\n",
      "Epoch [24/100], Step [500/4091], Loss: 525.4547\n",
      "Epoch [24/100], Step [600/4091], Loss: 541.4993\n",
      "Epoch [24/100], Step [700/4091], Loss: 684.2557\n",
      "Epoch [24/100], Step [800/4091], Loss: 872.8126\n",
      "Epoch [24/100], Step [900/4091], Loss: 797.8215\n",
      "Epoch [24/100], Step [1000/4091], Loss: 587.7201\n",
      "Epoch [24/100], Step [1100/4091], Loss: 497.7992\n",
      "Epoch [24/100], Step [1200/4091], Loss: 848.6145\n",
      "Epoch [24/100], Step [1300/4091], Loss: 863.4863\n",
      "Epoch [24/100], Step [1400/4091], Loss: 871.3218\n",
      "Epoch [24/100], Step [1500/4091], Loss: 953.6040\n",
      "Epoch [24/100], Step [1600/4091], Loss: 665.4631\n",
      "Epoch [24/100], Step [1700/4091], Loss: 745.4263\n",
      "Epoch [24/100], Step [1800/4091], Loss: 630.5254\n",
      "Epoch [24/100], Step [1900/4091], Loss: 736.2225\n",
      "Epoch [24/100], Step [2000/4091], Loss: 436.3455\n",
      "Epoch [24/100], Step [2100/4091], Loss: 573.6763\n",
      "Epoch [24/100], Step [2200/4091], Loss: 836.3223\n",
      "Epoch [24/100], Step [2300/4091], Loss: 795.0372\n",
      "Epoch [24/100], Step [2400/4091], Loss: 792.5664\n",
      "Epoch [24/100], Step [2500/4091], Loss: 994.8702\n",
      "Epoch [24/100], Step [2600/4091], Loss: 580.2193\n",
      "Epoch [24/100], Step [2700/4091], Loss: 741.8908\n",
      "Epoch [24/100], Step [2800/4091], Loss: 498.9088\n",
      "Epoch [24/100], Step [2900/4091], Loss: 553.5643\n",
      "Epoch [24/100], Step [3000/4091], Loss: 517.0018\n",
      "Epoch [24/100], Step [3100/4091], Loss: 726.8580\n",
      "Epoch [24/100], Step [3200/4091], Loss: 727.6796\n",
      "Epoch [24/100], Step [3300/4091], Loss: 642.7643\n",
      "Epoch [24/100], Step [3400/4091], Loss: 782.0046\n",
      "Epoch [24/100], Step [3500/4091], Loss: 545.7841\n",
      "Epoch [24/100], Step [3600/4091], Loss: 849.6939\n",
      "Epoch [24/100], Step [3700/4091], Loss: 490.0329\n",
      "Epoch [24/100], Step [3800/4091], Loss: 685.2878\n",
      "Epoch [24/100], Step [3900/4091], Loss: 559.3485\n",
      "Epoch [24/100], Step [4000/4091], Loss: 524.4636\n",
      "Epoch [25/100], Step [100/4091], Loss: 608.0252\n",
      "Epoch [25/100], Step [200/4091], Loss: 587.9398\n",
      "Epoch [25/100], Step [300/4091], Loss: 615.8100\n",
      "Epoch [25/100], Step [400/4091], Loss: 730.8110\n",
      "Epoch [25/100], Step [500/4091], Loss: 723.7528\n",
      "Epoch [25/100], Step [600/4091], Loss: 788.6162\n",
      "Epoch [25/100], Step [700/4091], Loss: 542.9573\n",
      "Epoch [25/100], Step [800/4091], Loss: 475.5124\n",
      "Epoch [25/100], Step [900/4091], Loss: 582.4235\n",
      "Epoch [25/100], Step [1000/4091], Loss: 574.5657\n",
      "Epoch [25/100], Step [1100/4091], Loss: 659.2348\n",
      "Epoch [25/100], Step [1200/4091], Loss: 575.1046\n",
      "Epoch [25/100], Step [1300/4091], Loss: 767.3331\n",
      "Epoch [25/100], Step [1400/4091], Loss: 678.6277\n",
      "Epoch [25/100], Step [1500/4091], Loss: 692.4556\n",
      "Epoch [25/100], Step [1600/4091], Loss: 656.8256\n",
      "Epoch [25/100], Step [1700/4091], Loss: 638.4963\n",
      "Epoch [25/100], Step [1800/4091], Loss: 555.6599\n",
      "Epoch [25/100], Step [1900/4091], Loss: 726.7862\n",
      "Epoch [25/100], Step [2000/4091], Loss: 853.8362\n",
      "Epoch [25/100], Step [2100/4091], Loss: 716.5439\n",
      "Epoch [25/100], Step [2200/4091], Loss: 757.7062\n",
      "Epoch [25/100], Step [2300/4091], Loss: 756.9623\n",
      "Epoch [25/100], Step [2400/4091], Loss: 513.2214\n",
      "Epoch [25/100], Step [2500/4091], Loss: 775.5810\n",
      "Epoch [25/100], Step [2600/4091], Loss: 661.3514\n",
      "Epoch [25/100], Step [2700/4091], Loss: 529.4232\n",
      "Epoch [25/100], Step [2800/4091], Loss: 760.2261\n",
      "Epoch [25/100], Step [2900/4091], Loss: 553.2903\n",
      "Epoch [25/100], Step [3000/4091], Loss: 569.5108\n",
      "Epoch [25/100], Step [3100/4091], Loss: 641.6255\n",
      "Epoch [25/100], Step [3200/4091], Loss: 565.3587\n",
      "Epoch [25/100], Step [3300/4091], Loss: 792.5382\n",
      "Epoch [25/100], Step [3400/4091], Loss: 656.6270\n",
      "Epoch [25/100], Step [3500/4091], Loss: 579.6039\n",
      "Epoch [25/100], Step [3600/4091], Loss: 489.5193\n",
      "Epoch [25/100], Step [3700/4091], Loss: 747.4532\n",
      "Epoch [25/100], Step [3800/4091], Loss: 501.2033\n",
      "Epoch [25/100], Step [3900/4091], Loss: 701.7284\n",
      "Epoch [25/100], Step [4000/4091], Loss: 742.8824\n",
      "Epoch [26/100], Step [100/4091], Loss: 625.7991\n",
      "Epoch [26/100], Step [200/4091], Loss: 536.2961\n",
      "Epoch [26/100], Step [300/4091], Loss: 448.7791\n",
      "Epoch [26/100], Step [400/4091], Loss: 659.8679\n",
      "Epoch [26/100], Step [500/4091], Loss: 701.6236\n",
      "Epoch [26/100], Step [600/4091], Loss: 540.3305\n",
      "Epoch [26/100], Step [700/4091], Loss: 841.4999\n",
      "Epoch [26/100], Step [800/4091], Loss: 472.9736\n",
      "Epoch [26/100], Step [900/4091], Loss: 467.7357\n",
      "Epoch [26/100], Step [1000/4091], Loss: 529.4722\n",
      "Epoch [26/100], Step [1100/4091], Loss: 633.7382\n",
      "Epoch [26/100], Step [1200/4091], Loss: 627.6871\n",
      "Epoch [26/100], Step [1300/4091], Loss: 501.6106\n",
      "Epoch [26/100], Step [1400/4091], Loss: 709.4053\n",
      "Epoch [26/100], Step [1500/4091], Loss: 557.9111\n",
      "Epoch [26/100], Step [1600/4091], Loss: 732.1178\n",
      "Epoch [26/100], Step [1700/4091], Loss: 563.9030\n",
      "Epoch [26/100], Step [1800/4091], Loss: 752.9111\n",
      "Epoch [26/100], Step [1900/4091], Loss: 689.5357\n",
      "Epoch [26/100], Step [2000/4091], Loss: 1072.3953\n",
      "Epoch [26/100], Step [2100/4091], Loss: 680.9342\n",
      "Epoch [26/100], Step [2200/4091], Loss: 768.3833\n",
      "Epoch [26/100], Step [2300/4091], Loss: 489.5643\n",
      "Epoch [26/100], Step [2400/4091], Loss: 852.2325\n",
      "Epoch [26/100], Step [2500/4091], Loss: 415.2994\n",
      "Epoch [26/100], Step [2600/4091], Loss: 663.2552\n",
      "Epoch [26/100], Step [2700/4091], Loss: 542.6653\n",
      "Epoch [26/100], Step [2800/4091], Loss: 669.9434\n",
      "Epoch [26/100], Step [2900/4091], Loss: 595.1521\n",
      "Epoch [26/100], Step [3000/4091], Loss: 635.4258\n",
      "Epoch [26/100], Step [3100/4091], Loss: 940.4651\n",
      "Epoch [26/100], Step [3200/4091], Loss: 821.4919\n",
      "Epoch [26/100], Step [3300/4091], Loss: 1015.1659\n",
      "Epoch [26/100], Step [3400/4091], Loss: 470.9611\n",
      "Epoch [26/100], Step [3500/4091], Loss: 584.8464\n",
      "Epoch [26/100], Step [3600/4091], Loss: 410.5640\n",
      "Epoch [26/100], Step [3700/4091], Loss: 570.6365\n",
      "Epoch [26/100], Step [3800/4091], Loss: 905.2452\n",
      "Epoch [26/100], Step [3900/4091], Loss: 475.2313\n",
      "Epoch [26/100], Step [4000/4091], Loss: 760.9698\n",
      "Epoch [27/100], Step [100/4091], Loss: 711.3062\n",
      "Epoch [27/100], Step [200/4091], Loss: 670.0722\n",
      "Epoch [27/100], Step [300/4091], Loss: 897.6500\n",
      "Epoch [27/100], Step [400/4091], Loss: 872.2233\n",
      "Epoch [27/100], Step [500/4091], Loss: 608.1666\n",
      "Epoch [27/100], Step [600/4091], Loss: 695.1064\n",
      "Epoch [27/100], Step [700/4091], Loss: 570.3059\n",
      "Epoch [27/100], Step [800/4091], Loss: 969.0945\n",
      "Epoch [27/100], Step [900/4091], Loss: 585.0974\n",
      "Epoch [27/100], Step [1000/4091], Loss: 559.3458\n",
      "Epoch [27/100], Step [1100/4091], Loss: 905.4781\n",
      "Epoch [27/100], Step [1200/4091], Loss: 478.4195\n",
      "Epoch [27/100], Step [1300/4091], Loss: 506.8342\n",
      "Epoch [27/100], Step [1400/4091], Loss: 780.8538\n",
      "Epoch [27/100], Step [1500/4091], Loss: 621.5110\n",
      "Epoch [27/100], Step [1600/4091], Loss: 632.9357\n",
      "Epoch [27/100], Step [1700/4091], Loss: 717.2913\n",
      "Epoch [27/100], Step [1800/4091], Loss: 675.0385\n",
      "Epoch [27/100], Step [1900/4091], Loss: 822.1271\n",
      "Epoch [27/100], Step [2000/4091], Loss: 632.5854\n",
      "Epoch [27/100], Step [2100/4091], Loss: 558.0364\n",
      "Epoch [27/100], Step [2200/4091], Loss: 621.4606\n",
      "Epoch [27/100], Step [2300/4091], Loss: 572.6096\n",
      "Epoch [27/100], Step [2400/4091], Loss: 566.6094\n",
      "Epoch [27/100], Step [2500/4091], Loss: 653.0289\n",
      "Epoch [27/100], Step [2600/4091], Loss: 727.7651\n",
      "Epoch [27/100], Step [2700/4091], Loss: 555.0677\n",
      "Epoch [27/100], Step [2800/4091], Loss: 959.7424\n",
      "Epoch [27/100], Step [2900/4091], Loss: 674.0674\n",
      "Epoch [27/100], Step [3000/4091], Loss: 645.5438\n",
      "Epoch [27/100], Step [3100/4091], Loss: 542.5937\n",
      "Epoch [27/100], Step [3200/4091], Loss: 604.2153\n",
      "Epoch [27/100], Step [3300/4091], Loss: 827.0542\n",
      "Epoch [27/100], Step [3400/4091], Loss: 658.8320\n",
      "Epoch [27/100], Step [3500/4091], Loss: 760.2767\n",
      "Epoch [27/100], Step [3600/4091], Loss: 716.3553\n",
      "Epoch [27/100], Step [3700/4091], Loss: 702.9603\n",
      "Epoch [27/100], Step [3800/4091], Loss: 594.1777\n",
      "Epoch [27/100], Step [3900/4091], Loss: 680.4871\n",
      "Epoch [27/100], Step [4000/4091], Loss: 555.0815\n",
      "Epoch [28/100], Step [100/4091], Loss: 842.0699\n",
      "Epoch [28/100], Step [200/4091], Loss: 822.2344\n",
      "Epoch [28/100], Step [300/4091], Loss: 733.2339\n",
      "Epoch [28/100], Step [400/4091], Loss: 594.3205\n",
      "Epoch [28/100], Step [500/4091], Loss: 544.1212\n",
      "Epoch [28/100], Step [600/4091], Loss: 590.6661\n",
      "Epoch [28/100], Step [700/4091], Loss: 532.0731\n",
      "Epoch [28/100], Step [800/4091], Loss: 581.6473\n",
      "Epoch [28/100], Step [900/4091], Loss: 565.3900\n",
      "Epoch [28/100], Step [1000/4091], Loss: 623.3336\n",
      "Epoch [28/100], Step [1100/4091], Loss: 650.6239\n",
      "Epoch [28/100], Step [1200/4091], Loss: 569.4438\n",
      "Epoch [28/100], Step [1300/4091], Loss: 638.6514\n",
      "Epoch [28/100], Step [1400/4091], Loss: 811.2852\n",
      "Epoch [28/100], Step [1500/4091], Loss: 611.2614\n",
      "Epoch [28/100], Step [1600/4091], Loss: 463.0703\n",
      "Epoch [28/100], Step [1700/4091], Loss: 576.0735\n",
      "Epoch [28/100], Step [1800/4091], Loss: 676.8460\n",
      "Epoch [28/100], Step [1900/4091], Loss: 740.1738\n",
      "Epoch [28/100], Step [2000/4091], Loss: 729.8854\n",
      "Epoch [28/100], Step [2100/4091], Loss: 564.7574\n",
      "Epoch [28/100], Step [2200/4091], Loss: 772.4280\n",
      "Epoch [28/100], Step [2300/4091], Loss: 787.9906\n",
      "Epoch [28/100], Step [2400/4091], Loss: 615.5387\n",
      "Epoch [28/100], Step [2500/4091], Loss: 574.7241\n",
      "Epoch [28/100], Step [2600/4091], Loss: 566.4601\n",
      "Epoch [28/100], Step [2700/4091], Loss: 771.6166\n",
      "Epoch [28/100], Step [2800/4091], Loss: 724.4959\n",
      "Epoch [28/100], Step [2900/4091], Loss: 869.9001\n",
      "Epoch [28/100], Step [3000/4091], Loss: 733.8505\n",
      "Epoch [28/100], Step [3100/4091], Loss: 743.1541\n",
      "Epoch [28/100], Step [3200/4091], Loss: 676.0503\n",
      "Epoch [28/100], Step [3300/4091], Loss: 793.3757\n",
      "Epoch [28/100], Step [3400/4091], Loss: 694.9708\n",
      "Epoch [28/100], Step [3500/4091], Loss: 850.4186\n",
      "Epoch [28/100], Step [3600/4091], Loss: 808.6754\n",
      "Epoch [28/100], Step [3700/4091], Loss: 802.0680\n",
      "Epoch [28/100], Step [3800/4091], Loss: 806.1069\n",
      "Epoch [28/100], Step [3900/4091], Loss: 886.0466\n",
      "Epoch [28/100], Step [4000/4091], Loss: 794.1376\n",
      "Epoch [29/100], Step [100/4091], Loss: 772.6039\n",
      "Epoch [29/100], Step [200/4091], Loss: 770.5444\n",
      "Epoch [29/100], Step [300/4091], Loss: 584.2864\n",
      "Epoch [29/100], Step [400/4091], Loss: 480.3114\n",
      "Epoch [29/100], Step [500/4091], Loss: 891.7410\n",
      "Epoch [29/100], Step [600/4091], Loss: 694.3479\n",
      "Epoch [29/100], Step [700/4091], Loss: 513.3741\n",
      "Epoch [29/100], Step [800/4091], Loss: 672.2847\n",
      "Epoch [29/100], Step [900/4091], Loss: 834.5710\n",
      "Epoch [29/100], Step [1000/4091], Loss: 639.2522\n",
      "Epoch [29/100], Step [1100/4091], Loss: 865.3546\n",
      "Epoch [29/100], Step [1200/4091], Loss: 600.7396\n",
      "Epoch [29/100], Step [1300/4091], Loss: 693.8633\n",
      "Epoch [29/100], Step [1400/4091], Loss: 576.8546\n",
      "Epoch [29/100], Step [1500/4091], Loss: 579.4966\n",
      "Epoch [29/100], Step [1600/4091], Loss: 489.6733\n",
      "Epoch [29/100], Step [1700/4091], Loss: 799.6021\n",
      "Epoch [29/100], Step [1800/4091], Loss: 748.9359\n",
      "Epoch [29/100], Step [1900/4091], Loss: 863.6605\n",
      "Epoch [29/100], Step [2000/4091], Loss: 465.9117\n",
      "Epoch [29/100], Step [2100/4091], Loss: 615.7914\n",
      "Epoch [29/100], Step [2200/4091], Loss: 470.0933\n",
      "Epoch [29/100], Step [2300/4091], Loss: 597.9608\n",
      "Epoch [29/100], Step [2400/4091], Loss: 667.5634\n",
      "Epoch [29/100], Step [2500/4091], Loss: 617.2961\n",
      "Epoch [29/100], Step [2600/4091], Loss: 634.4262\n",
      "Epoch [29/100], Step [2700/4091], Loss: 685.0781\n",
      "Epoch [29/100], Step [2800/4091], Loss: 665.8903\n",
      "Epoch [29/100], Step [2900/4091], Loss: 596.6456\n",
      "Epoch [29/100], Step [3000/4091], Loss: 837.4376\n",
      "Epoch [29/100], Step [3100/4091], Loss: 688.0065\n",
      "Epoch [29/100], Step [3200/4091], Loss: 639.5616\n",
      "Epoch [29/100], Step [3300/4091], Loss: 584.0784\n",
      "Epoch [29/100], Step [3400/4091], Loss: 643.4928\n",
      "Epoch [29/100], Step [3500/4091], Loss: 629.1249\n",
      "Epoch [29/100], Step [3600/4091], Loss: 554.8846\n",
      "Epoch [29/100], Step [3700/4091], Loss: 611.6490\n",
      "Epoch [29/100], Step [3800/4091], Loss: 601.4521\n",
      "Epoch [29/100], Step [3900/4091], Loss: 766.1998\n",
      "Epoch [29/100], Step [4000/4091], Loss: 728.3629\n",
      "Epoch [30/100], Step [100/4091], Loss: 690.4309\n",
      "Epoch [30/100], Step [200/4091], Loss: 880.3561\n",
      "Epoch [30/100], Step [300/4091], Loss: 478.6549\n",
      "Epoch [30/100], Step [400/4091], Loss: 629.3453\n",
      "Epoch [30/100], Step [500/4091], Loss: 548.8486\n",
      "Epoch [30/100], Step [600/4091], Loss: 441.4958\n",
      "Epoch [30/100], Step [700/4091], Loss: 833.0293\n",
      "Epoch [30/100], Step [800/4091], Loss: 536.1772\n",
      "Epoch [30/100], Step [900/4091], Loss: 607.9823\n",
      "Epoch [30/100], Step [1000/4091], Loss: 700.4727\n",
      "Epoch [30/100], Step [1100/4091], Loss: 492.0533\n",
      "Epoch [30/100], Step [1200/4091], Loss: 728.5244\n",
      "Epoch [30/100], Step [1300/4091], Loss: 634.0783\n",
      "Epoch [30/100], Step [1400/4091], Loss: 678.4047\n",
      "Epoch [30/100], Step [1500/4091], Loss: 794.9770\n",
      "Epoch [30/100], Step [1600/4091], Loss: 601.4776\n",
      "Epoch [30/100], Step [1700/4091], Loss: 643.9691\n",
      "Epoch [30/100], Step [1800/4091], Loss: 644.6779\n",
      "Epoch [30/100], Step [1900/4091], Loss: 792.2072\n",
      "Epoch [30/100], Step [2000/4091], Loss: 701.1055\n",
      "Epoch [30/100], Step [2100/4091], Loss: 635.9286\n",
      "Epoch [30/100], Step [2200/4091], Loss: 600.2343\n",
      "Epoch [30/100], Step [2300/4091], Loss: 1002.5760\n",
      "Epoch [30/100], Step [2400/4091], Loss: 844.5481\n",
      "Epoch [30/100], Step [2500/4091], Loss: 804.6342\n",
      "Epoch [30/100], Step [2600/4091], Loss: 541.6600\n",
      "Epoch [30/100], Step [2700/4091], Loss: 451.0542\n",
      "Epoch [30/100], Step [2800/4091], Loss: 763.6503\n",
      "Epoch [30/100], Step [2900/4091], Loss: 423.9207\n",
      "Epoch [30/100], Step [3000/4091], Loss: 576.8496\n",
      "Epoch [30/100], Step [3100/4091], Loss: 667.8288\n",
      "Epoch [30/100], Step [3200/4091], Loss: 826.0463\n",
      "Epoch [30/100], Step [3300/4091], Loss: 729.8738\n",
      "Epoch [30/100], Step [3400/4091], Loss: 547.3718\n",
      "Epoch [30/100], Step [3500/4091], Loss: 519.8716\n",
      "Epoch [30/100], Step [3600/4091], Loss: 841.1787\n",
      "Epoch [30/100], Step [3700/4091], Loss: 688.5353\n",
      "Epoch [30/100], Step [3800/4091], Loss: 655.6842\n",
      "Epoch [30/100], Step [3900/4091], Loss: 797.2458\n",
      "Epoch [30/100], Step [4000/4091], Loss: 540.8062\n",
      "Epoch [31/100], Step [100/4091], Loss: 853.0172\n",
      "Epoch [31/100], Step [200/4091], Loss: 754.0784\n",
      "Epoch [31/100], Step [300/4091], Loss: 520.1418\n",
      "Epoch [31/100], Step [400/4091], Loss: 685.5077\n",
      "Epoch [31/100], Step [500/4091], Loss: 720.8653\n",
      "Epoch [31/100], Step [600/4091], Loss: 596.1169\n",
      "Epoch [31/100], Step [700/4091], Loss: 679.8576\n",
      "Epoch [31/100], Step [800/4091], Loss: 612.9768\n",
      "Epoch [31/100], Step [900/4091], Loss: 624.8946\n",
      "Epoch [31/100], Step [1000/4091], Loss: 688.4092\n",
      "Epoch [31/100], Step [1100/4091], Loss: 574.9342\n",
      "Epoch [31/100], Step [1200/4091], Loss: 503.4130\n",
      "Epoch [31/100], Step [1300/4091], Loss: 853.9624\n",
      "Epoch [31/100], Step [1400/4091], Loss: 1006.7572\n",
      "Epoch [31/100], Step [1500/4091], Loss: 988.5063\n",
      "Epoch [31/100], Step [1600/4091], Loss: 498.5086\n",
      "Epoch [31/100], Step [1700/4091], Loss: 684.5584\n",
      "Epoch [31/100], Step [1800/4091], Loss: 692.1782\n",
      "Epoch [31/100], Step [1900/4091], Loss: 795.7443\n",
      "Epoch [31/100], Step [2000/4091], Loss: 478.7024\n",
      "Epoch [31/100], Step [2100/4091], Loss: 510.4556\n",
      "Epoch [31/100], Step [2200/4091], Loss: 811.8381\n",
      "Epoch [31/100], Step [2300/4091], Loss: 798.9038\n",
      "Epoch [31/100], Step [2400/4091], Loss: 739.4164\n",
      "Epoch [31/100], Step [2500/4091], Loss: 585.3788\n",
      "Epoch [31/100], Step [2600/4091], Loss: 678.8994\n",
      "Epoch [31/100], Step [2700/4091], Loss: 861.5900\n",
      "Epoch [31/100], Step [2800/4091], Loss: 455.1872\n",
      "Epoch [31/100], Step [2900/4091], Loss: 559.7039\n",
      "Epoch [31/100], Step [3000/4091], Loss: 702.1857\n",
      "Epoch [31/100], Step [3100/4091], Loss: 754.5722\n",
      "Epoch [31/100], Step [3200/4091], Loss: 597.6595\n",
      "Epoch [31/100], Step [3300/4091], Loss: 653.8255\n",
      "Epoch [31/100], Step [3400/4091], Loss: 844.1429\n",
      "Epoch [31/100], Step [3500/4091], Loss: 661.0427\n",
      "Epoch [31/100], Step [3600/4091], Loss: 630.6587\n",
      "Epoch [31/100], Step [3700/4091], Loss: 473.0540\n",
      "Epoch [31/100], Step [3800/4091], Loss: 570.3403\n",
      "Epoch [31/100], Step [3900/4091], Loss: 498.9638\n",
      "Epoch [31/100], Step [4000/4091], Loss: 630.5410\n",
      "Epoch [32/100], Step [100/4091], Loss: 596.1567\n",
      "Epoch [32/100], Step [200/4091], Loss: 668.3652\n",
      "Epoch [32/100], Step [300/4091], Loss: 670.9247\n",
      "Epoch [32/100], Step [400/4091], Loss: 727.9631\n",
      "Epoch [32/100], Step [500/4091], Loss: 572.6641\n",
      "Epoch [32/100], Step [600/4091], Loss: 636.8523\n",
      "Epoch [32/100], Step [700/4091], Loss: 553.8372\n",
      "Epoch [32/100], Step [800/4091], Loss: 520.9841\n",
      "Epoch [32/100], Step [900/4091], Loss: 453.8583\n",
      "Epoch [32/100], Step [1000/4091], Loss: 858.0693\n",
      "Epoch [32/100], Step [1100/4091], Loss: 427.8351\n",
      "Epoch [32/100], Step [1200/4091], Loss: 520.3427\n",
      "Epoch [32/100], Step [1300/4091], Loss: 900.6329\n",
      "Epoch [32/100], Step [1400/4091], Loss: 657.1199\n",
      "Epoch [32/100], Step [1500/4091], Loss: 624.4945\n",
      "Epoch [32/100], Step [1600/4091], Loss: 578.5708\n",
      "Epoch [32/100], Step [1700/4091], Loss: 732.3364\n",
      "Epoch [32/100], Step [1800/4091], Loss: 780.6913\n",
      "Epoch [32/100], Step [1900/4091], Loss: 700.0759\n",
      "Epoch [32/100], Step [2000/4091], Loss: 596.1919\n",
      "Epoch [32/100], Step [2100/4091], Loss: 737.6199\n",
      "Epoch [32/100], Step [2200/4091], Loss: 590.1913\n",
      "Epoch [32/100], Step [2300/4091], Loss: 643.1514\n",
      "Epoch [32/100], Step [2400/4091], Loss: 631.0765\n",
      "Epoch [32/100], Step [2500/4091], Loss: 651.0160\n",
      "Epoch [32/100], Step [2600/4091], Loss: 740.3737\n",
      "Epoch [32/100], Step [2700/4091], Loss: 617.2394\n",
      "Epoch [32/100], Step [2800/4091], Loss: 699.5471\n",
      "Epoch [32/100], Step [2900/4091], Loss: 380.1362\n",
      "Epoch [32/100], Step [3000/4091], Loss: 626.8885\n",
      "Epoch [32/100], Step [3100/4091], Loss: 559.8453\n",
      "Epoch [32/100], Step [3200/4091], Loss: 795.8794\n",
      "Epoch [32/100], Step [3300/4091], Loss: 742.7258\n",
      "Epoch [32/100], Step [3400/4091], Loss: 559.9861\n",
      "Epoch [32/100], Step [3500/4091], Loss: 575.1860\n",
      "Epoch [32/100], Step [3600/4091], Loss: 853.1151\n",
      "Epoch [32/100], Step [3700/4091], Loss: 549.8798\n",
      "Epoch [32/100], Step [3800/4091], Loss: 691.6642\n",
      "Epoch [32/100], Step [3900/4091], Loss: 810.1490\n",
      "Epoch [32/100], Step [4000/4091], Loss: 526.4044\n",
      "Epoch [33/100], Step [100/4091], Loss: 668.5461\n",
      "Epoch [33/100], Step [200/4091], Loss: 912.9822\n",
      "Epoch [33/100], Step [300/4091], Loss: 616.1554\n",
      "Epoch [33/100], Step [400/4091], Loss: 570.6776\n",
      "Epoch [33/100], Step [500/4091], Loss: 623.2029\n",
      "Epoch [33/100], Step [600/4091], Loss: 555.5083\n",
      "Epoch [33/100], Step [700/4091], Loss: 475.4114\n",
      "Epoch [33/100], Step [800/4091], Loss: 796.2113\n",
      "Epoch [33/100], Step [900/4091], Loss: 533.7925\n",
      "Epoch [33/100], Step [1000/4091], Loss: 700.5352\n",
      "Epoch [33/100], Step [1100/4091], Loss: 751.4156\n",
      "Epoch [33/100], Step [1200/4091], Loss: 692.2640\n",
      "Epoch [33/100], Step [1300/4091], Loss: 498.8309\n",
      "Epoch [33/100], Step [1400/4091], Loss: 715.6998\n",
      "Epoch [33/100], Step [1500/4091], Loss: 613.3707\n",
      "Epoch [33/100], Step [1600/4091], Loss: 804.7186\n",
      "Epoch [33/100], Step [1700/4091], Loss: 806.2572\n",
      "Epoch [33/100], Step [1800/4091], Loss: 723.4977\n",
      "Epoch [33/100], Step [1900/4091], Loss: 602.7048\n",
      "Epoch [33/100], Step [2000/4091], Loss: 746.4198\n",
      "Epoch [33/100], Step [2100/4091], Loss: 844.3867\n",
      "Epoch [33/100], Step [2200/4091], Loss: 602.5165\n",
      "Epoch [33/100], Step [2300/4091], Loss: 560.1331\n",
      "Epoch [33/100], Step [2400/4091], Loss: 767.3461\n",
      "Epoch [33/100], Step [2500/4091], Loss: 404.2419\n",
      "Epoch [33/100], Step [2600/4091], Loss: 851.5499\n",
      "Epoch [33/100], Step [2700/4091], Loss: 446.2293\n",
      "Epoch [33/100], Step [2800/4091], Loss: 451.4646\n",
      "Epoch [33/100], Step [2900/4091], Loss: 568.4294\n",
      "Epoch [33/100], Step [3000/4091], Loss: 607.6846\n",
      "Epoch [33/100], Step [3100/4091], Loss: 554.7042\n",
      "Epoch [33/100], Step [3200/4091], Loss: 666.8933\n",
      "Epoch [33/100], Step [3300/4091], Loss: 672.8348\n",
      "Epoch [33/100], Step [3400/4091], Loss: 486.5662\n",
      "Epoch [33/100], Step [3500/4091], Loss: 628.2177\n",
      "Epoch [33/100], Step [3600/4091], Loss: 715.2089\n",
      "Epoch [33/100], Step [3700/4091], Loss: 666.0808\n",
      "Epoch [33/100], Step [3800/4091], Loss: 871.3124\n",
      "Epoch [33/100], Step [3900/4091], Loss: 787.0085\n",
      "Epoch [33/100], Step [4000/4091], Loss: 712.9523\n",
      "Epoch [34/100], Step [100/4091], Loss: 723.8550\n",
      "Epoch [34/100], Step [200/4091], Loss: 694.4420\n",
      "Epoch [34/100], Step [300/4091], Loss: 550.2639\n",
      "Epoch [34/100], Step [400/4091], Loss: 766.8940\n",
      "Epoch [34/100], Step [500/4091], Loss: 735.8086\n",
      "Epoch [34/100], Step [600/4091], Loss: 756.2736\n",
      "Epoch [34/100], Step [700/4091], Loss: 480.0020\n",
      "Epoch [34/100], Step [800/4091], Loss: 971.0620\n",
      "Epoch [34/100], Step [900/4091], Loss: 841.0256\n",
      "Epoch [34/100], Step [1000/4091], Loss: 753.2639\n",
      "Epoch [34/100], Step [1100/4091], Loss: 845.9415\n",
      "Epoch [34/100], Step [1200/4091], Loss: 482.0615\n",
      "Epoch [34/100], Step [1300/4091], Loss: 646.1646\n",
      "Epoch [34/100], Step [1400/4091], Loss: 717.0224\n",
      "Epoch [34/100], Step [1500/4091], Loss: 443.5172\n",
      "Epoch [34/100], Step [1600/4091], Loss: 835.9458\n",
      "Epoch [34/100], Step [1700/4091], Loss: 523.2218\n",
      "Epoch [34/100], Step [1800/4091], Loss: 595.6064\n",
      "Epoch [34/100], Step [1900/4091], Loss: 553.2268\n",
      "Epoch [34/100], Step [2000/4091], Loss: 623.1102\n",
      "Epoch [34/100], Step [2100/4091], Loss: 637.9641\n",
      "Epoch [34/100], Step [2200/4091], Loss: 569.6385\n",
      "Epoch [34/100], Step [2300/4091], Loss: 727.1968\n",
      "Epoch [34/100], Step [2400/4091], Loss: 608.1418\n",
      "Epoch [34/100], Step [2500/4091], Loss: 449.6738\n",
      "Epoch [34/100], Step [2600/4091], Loss: 447.3484\n",
      "Epoch [34/100], Step [2700/4091], Loss: 666.7943\n",
      "Epoch [34/100], Step [2800/4091], Loss: 791.3930\n",
      "Epoch [34/100], Step [2900/4091], Loss: 556.7538\n",
      "Epoch [34/100], Step [3000/4091], Loss: 713.9500\n",
      "Epoch [34/100], Step [3100/4091], Loss: 792.6840\n",
      "Epoch [34/100], Step [3200/4091], Loss: 563.3616\n",
      "Epoch [34/100], Step [3300/4091], Loss: 672.8065\n",
      "Epoch [34/100], Step [3400/4091], Loss: 721.1353\n",
      "Epoch [34/100], Step [3500/4091], Loss: 615.3529\n",
      "Epoch [34/100], Step [3600/4091], Loss: 700.0120\n",
      "Epoch [34/100], Step [3700/4091], Loss: 811.0886\n",
      "Epoch [34/100], Step [3800/4091], Loss: 658.2586\n",
      "Epoch [34/100], Step [3900/4091], Loss: 846.5462\n",
      "Epoch [34/100], Step [4000/4091], Loss: 586.9531\n",
      "Epoch [35/100], Step [100/4091], Loss: 524.3480\n",
      "Epoch [35/100], Step [200/4091], Loss: 490.0869\n",
      "Epoch [35/100], Step [300/4091], Loss: 732.0612\n",
      "Epoch [35/100], Step [400/4091], Loss: 500.6225\n",
      "Epoch [35/100], Step [500/4091], Loss: 611.2739\n",
      "Epoch [35/100], Step [600/4091], Loss: 594.5904\n",
      "Epoch [35/100], Step [700/4091], Loss: 617.3948\n",
      "Epoch [35/100], Step [800/4091], Loss: 740.0545\n",
      "Epoch [35/100], Step [900/4091], Loss: 675.4064\n",
      "Epoch [35/100], Step [1000/4091], Loss: 495.1510\n",
      "Epoch [35/100], Step [1100/4091], Loss: 547.0997\n",
      "Epoch [35/100], Step [1200/4091], Loss: 577.2372\n",
      "Epoch [35/100], Step [1300/4091], Loss: 690.1068\n",
      "Epoch [35/100], Step [1400/4091], Loss: 448.1194\n",
      "Epoch [35/100], Step [1500/4091], Loss: 533.3827\n",
      "Epoch [35/100], Step [1600/4091], Loss: 488.9824\n",
      "Epoch [35/100], Step [1700/4091], Loss: 505.7918\n",
      "Epoch [35/100], Step [1800/4091], Loss: 611.3967\n",
      "Epoch [35/100], Step [1900/4091], Loss: 505.5882\n",
      "Epoch [35/100], Step [2000/4091], Loss: 755.2452\n",
      "Epoch [35/100], Step [2100/4091], Loss: 539.3315\n",
      "Epoch [35/100], Step [2200/4091], Loss: 607.8179\n",
      "Epoch [35/100], Step [2300/4091], Loss: 694.3907\n",
      "Epoch [35/100], Step [2400/4091], Loss: 591.6379\n",
      "Epoch [35/100], Step [2500/4091], Loss: 628.8239\n",
      "Epoch [35/100], Step [2600/4091], Loss: 472.0700\n",
      "Epoch [35/100], Step [2700/4091], Loss: 785.5988\n",
      "Epoch [35/100], Step [2800/4091], Loss: 660.6975\n",
      "Epoch [35/100], Step [2900/4091], Loss: 537.1888\n",
      "Epoch [35/100], Step [3000/4091], Loss: 796.4000\n",
      "Epoch [35/100], Step [3100/4091], Loss: 923.0716\n",
      "Epoch [35/100], Step [3200/4091], Loss: 606.3024\n",
      "Epoch [35/100], Step [3300/4091], Loss: 663.5667\n",
      "Epoch [35/100], Step [3400/4091], Loss: 449.3490\n",
      "Epoch [35/100], Step [3500/4091], Loss: 458.6021\n",
      "Epoch [35/100], Step [3600/4091], Loss: 583.0570\n",
      "Epoch [35/100], Step [3700/4091], Loss: 778.7903\n",
      "Epoch [35/100], Step [3800/4091], Loss: 534.5300\n",
      "Epoch [35/100], Step [3900/4091], Loss: 534.7543\n",
      "Epoch [35/100], Step [4000/4091], Loss: 715.1805\n",
      "Epoch [36/100], Step [100/4091], Loss: 900.0834\n",
      "Epoch [36/100], Step [200/4091], Loss: 536.2458\n",
      "Epoch [36/100], Step [300/4091], Loss: 623.4308\n",
      "Epoch [36/100], Step [400/4091], Loss: 560.4115\n",
      "Epoch [36/100], Step [500/4091], Loss: 700.6185\n",
      "Epoch [36/100], Step [600/4091], Loss: 673.5601\n",
      "Epoch [36/100], Step [700/4091], Loss: 750.1986\n",
      "Epoch [36/100], Step [800/4091], Loss: 481.6248\n",
      "Epoch [36/100], Step [900/4091], Loss: 616.3969\n",
      "Epoch [36/100], Step [1000/4091], Loss: 628.4532\n",
      "Epoch [36/100], Step [1100/4091], Loss: 683.4729\n",
      "Epoch [36/100], Step [1200/4091], Loss: 693.3804\n",
      "Epoch [36/100], Step [1300/4091], Loss: 667.6378\n",
      "Epoch [36/100], Step [1400/4091], Loss: 653.2523\n",
      "Epoch [36/100], Step [1500/4091], Loss: 789.8171\n",
      "Epoch [36/100], Step [1600/4091], Loss: 631.2239\n",
      "Epoch [36/100], Step [1700/4091], Loss: 522.5632\n",
      "Epoch [36/100], Step [1800/4091], Loss: 733.9229\n",
      "Epoch [36/100], Step [1900/4091], Loss: 771.5800\n",
      "Epoch [36/100], Step [2000/4091], Loss: 736.0938\n",
      "Epoch [36/100], Step [2100/4091], Loss: 783.9973\n",
      "Epoch [36/100], Step [2200/4091], Loss: 750.9236\n",
      "Epoch [36/100], Step [2300/4091], Loss: 883.4111\n",
      "Epoch [36/100], Step [2400/4091], Loss: 745.2753\n",
      "Epoch [36/100], Step [2500/4091], Loss: 583.2067\n",
      "Epoch [36/100], Step [2600/4091], Loss: 846.6252\n",
      "Epoch [36/100], Step [2700/4091], Loss: 704.1924\n",
      "Epoch [36/100], Step [2800/4091], Loss: 630.0234\n",
      "Epoch [36/100], Step [2900/4091], Loss: 477.6498\n",
      "Epoch [36/100], Step [3000/4091], Loss: 725.2771\n",
      "Epoch [36/100], Step [3100/4091], Loss: 766.0449\n",
      "Epoch [36/100], Step [3200/4091], Loss: 769.4062\n",
      "Epoch [36/100], Step [3300/4091], Loss: 888.0349\n",
      "Epoch [36/100], Step [3400/4091], Loss: 690.3624\n",
      "Epoch [36/100], Step [3500/4091], Loss: 698.2724\n",
      "Epoch [36/100], Step [3600/4091], Loss: 642.6722\n",
      "Epoch [36/100], Step [3700/4091], Loss: 556.5098\n",
      "Epoch [36/100], Step [3800/4091], Loss: 699.4048\n",
      "Epoch [36/100], Step [3900/4091], Loss: 625.1581\n",
      "Epoch [36/100], Step [4000/4091], Loss: 781.3237\n",
      "Epoch [37/100], Step [100/4091], Loss: 613.3751\n",
      "Epoch [37/100], Step [200/4091], Loss: 677.4492\n",
      "Epoch [37/100], Step [300/4091], Loss: 792.4136\n",
      "Epoch [37/100], Step [400/4091], Loss: 723.6548\n",
      "Epoch [37/100], Step [500/4091], Loss: 645.8397\n",
      "Epoch [37/100], Step [600/4091], Loss: 711.0859\n",
      "Epoch [37/100], Step [700/4091], Loss: 610.4559\n",
      "Epoch [37/100], Step [800/4091], Loss: 801.5370\n",
      "Epoch [37/100], Step [900/4091], Loss: 598.0328\n",
      "Epoch [37/100], Step [1000/4091], Loss: 636.1057\n",
      "Epoch [37/100], Step [1100/4091], Loss: 618.7725\n",
      "Epoch [37/100], Step [1200/4091], Loss: 728.6299\n",
      "Epoch [37/100], Step [1300/4091], Loss: 520.9382\n",
      "Epoch [37/100], Step [1400/4091], Loss: 494.9458\n",
      "Epoch [37/100], Step [1500/4091], Loss: 761.0541\n",
      "Epoch [37/100], Step [1600/4091], Loss: 640.6118\n",
      "Epoch [37/100], Step [1700/4091], Loss: 560.6002\n",
      "Epoch [37/100], Step [1800/4091], Loss: 769.6058\n",
      "Epoch [37/100], Step [1900/4091], Loss: 614.7277\n",
      "Epoch [37/100], Step [2000/4091], Loss: 724.8599\n",
      "Epoch [37/100], Step [2100/4091], Loss: 739.2379\n",
      "Epoch [37/100], Step [2200/4091], Loss: 784.8153\n",
      "Epoch [37/100], Step [2300/4091], Loss: 617.3419\n",
      "Epoch [37/100], Step [2400/4091], Loss: 876.2874\n",
      "Epoch [37/100], Step [2500/4091], Loss: 619.5654\n",
      "Epoch [37/100], Step [2600/4091], Loss: 573.5268\n",
      "Epoch [37/100], Step [2700/4091], Loss: 524.4556\n",
      "Epoch [37/100], Step [2800/4091], Loss: 601.9611\n",
      "Epoch [37/100], Step [2900/4091], Loss: 549.3226\n",
      "Epoch [37/100], Step [3000/4091], Loss: 526.5662\n",
      "Epoch [37/100], Step [3100/4091], Loss: 496.1202\n",
      "Epoch [37/100], Step [3200/4091], Loss: 738.8659\n",
      "Epoch [37/100], Step [3300/4091], Loss: 542.1400\n",
      "Epoch [37/100], Step [3400/4091], Loss: 825.1719\n",
      "Epoch [37/100], Step [3500/4091], Loss: 476.5943\n",
      "Epoch [37/100], Step [3600/4091], Loss: 767.3918\n",
      "Epoch [37/100], Step [3700/4091], Loss: 524.2802\n",
      "Epoch [37/100], Step [3800/4091], Loss: 679.2246\n",
      "Epoch [37/100], Step [3900/4091], Loss: 660.1409\n",
      "Epoch [37/100], Step [4000/4091], Loss: 609.5529\n",
      "Epoch [38/100], Step [100/4091], Loss: 663.8377\n",
      "Epoch [38/100], Step [200/4091], Loss: 627.0862\n",
      "Epoch [38/100], Step [300/4091], Loss: 724.6227\n",
      "Epoch [38/100], Step [400/4091], Loss: 403.8946\n",
      "Epoch [38/100], Step [500/4091], Loss: 516.5232\n",
      "Epoch [38/100], Step [600/4091], Loss: 721.4247\n",
      "Epoch [38/100], Step [700/4091], Loss: 732.8193\n",
      "Epoch [38/100], Step [800/4091], Loss: 777.0425\n",
      "Epoch [38/100], Step [900/4091], Loss: 451.8220\n",
      "Epoch [38/100], Step [1000/4091], Loss: 616.3714\n",
      "Epoch [38/100], Step [1100/4091], Loss: 546.7411\n",
      "Epoch [38/100], Step [1200/4091], Loss: 571.6051\n",
      "Epoch [38/100], Step [1300/4091], Loss: 681.7684\n",
      "Epoch [38/100], Step [1400/4091], Loss: 571.6314\n",
      "Epoch [38/100], Step [1500/4091], Loss: 594.4249\n",
      "Epoch [38/100], Step [1600/4091], Loss: 621.4074\n",
      "Epoch [38/100], Step [1700/4091], Loss: 428.4200\n",
      "Epoch [38/100], Step [1800/4091], Loss: 785.0259\n",
      "Epoch [38/100], Step [1900/4091], Loss: 738.9916\n",
      "Epoch [38/100], Step [2000/4091], Loss: 708.9178\n",
      "Epoch [38/100], Step [2100/4091], Loss: 646.7942\n",
      "Epoch [38/100], Step [2200/4091], Loss: 412.4008\n",
      "Epoch [38/100], Step [2300/4091], Loss: 833.5477\n",
      "Epoch [38/100], Step [2400/4091], Loss: 557.4245\n",
      "Epoch [38/100], Step [2500/4091], Loss: 524.7087\n",
      "Epoch [38/100], Step [2600/4091], Loss: 764.7940\n",
      "Epoch [38/100], Step [2700/4091], Loss: 704.9463\n",
      "Epoch [38/100], Step [2800/4091], Loss: 786.6913\n",
      "Epoch [38/100], Step [2900/4091], Loss: 829.5721\n",
      "Epoch [38/100], Step [3000/4091], Loss: 734.8271\n",
      "Epoch [38/100], Step [3100/4091], Loss: 703.7714\n",
      "Epoch [38/100], Step [3200/4091], Loss: 425.7581\n",
      "Epoch [38/100], Step [3300/4091], Loss: 561.3420\n",
      "Epoch [38/100], Step [3400/4091], Loss: 726.6738\n",
      "Epoch [38/100], Step [3500/4091], Loss: 768.6810\n",
      "Epoch [38/100], Step [3600/4091], Loss: 528.4525\n",
      "Epoch [38/100], Step [3700/4091], Loss: 765.6855\n",
      "Epoch [38/100], Step [3800/4091], Loss: 687.2228\n",
      "Epoch [38/100], Step [3900/4091], Loss: 577.7480\n",
      "Epoch [38/100], Step [4000/4091], Loss: 596.4182\n",
      "Epoch [39/100], Step [100/4091], Loss: 729.6741\n",
      "Epoch [39/100], Step [200/4091], Loss: 528.8469\n",
      "Epoch [39/100], Step [300/4091], Loss: 744.4524\n",
      "Epoch [39/100], Step [400/4091], Loss: 537.0565\n",
      "Epoch [39/100], Step [500/4091], Loss: 577.7535\n",
      "Epoch [39/100], Step [600/4091], Loss: 639.8668\n",
      "Epoch [39/100], Step [700/4091], Loss: 539.6498\n",
      "Epoch [39/100], Step [800/4091], Loss: 555.1381\n",
      "Epoch [39/100], Step [900/4091], Loss: 687.7230\n",
      "Epoch [39/100], Step [1000/4091], Loss: 718.8756\n",
      "Epoch [39/100], Step [1100/4091], Loss: 527.9816\n",
      "Epoch [39/100], Step [1200/4091], Loss: 712.4739\n",
      "Epoch [39/100], Step [1300/4091], Loss: 781.3641\n",
      "Epoch [39/100], Step [1400/4091], Loss: 601.7761\n",
      "Epoch [39/100], Step [1500/4091], Loss: 468.3219\n",
      "Epoch [39/100], Step [1600/4091], Loss: 628.4003\n",
      "Epoch [39/100], Step [1700/4091], Loss: 850.4629\n",
      "Epoch [39/100], Step [1800/4091], Loss: 580.6993\n",
      "Epoch [39/100], Step [1900/4091], Loss: 604.5255\n",
      "Epoch [39/100], Step [2000/4091], Loss: 901.3267\n",
      "Epoch [39/100], Step [2100/4091], Loss: 597.0127\n",
      "Epoch [39/100], Step [2200/4091], Loss: 612.7864\n",
      "Epoch [39/100], Step [2300/4091], Loss: 740.7352\n",
      "Epoch [39/100], Step [2400/4091], Loss: 719.0766\n",
      "Epoch [39/100], Step [2500/4091], Loss: 793.3328\n",
      "Epoch [39/100], Step [2600/4091], Loss: 673.6735\n",
      "Epoch [39/100], Step [2700/4091], Loss: 385.1720\n",
      "Epoch [39/100], Step [2800/4091], Loss: 711.3292\n",
      "Epoch [39/100], Step [2900/4091], Loss: 584.0560\n",
      "Epoch [39/100], Step [3000/4091], Loss: 651.0745\n",
      "Epoch [39/100], Step [3100/4091], Loss: 611.2397\n",
      "Epoch [39/100], Step [3200/4091], Loss: 683.6516\n",
      "Epoch [39/100], Step [3300/4091], Loss: 799.2458\n",
      "Epoch [39/100], Step [3400/4091], Loss: 866.9515\n",
      "Epoch [39/100], Step [3500/4091], Loss: 578.2980\n",
      "Epoch [39/100], Step [3600/4091], Loss: 745.0739\n",
      "Epoch [39/100], Step [3700/4091], Loss: 576.6796\n",
      "Epoch [39/100], Step [3800/4091], Loss: 668.3760\n",
      "Epoch [39/100], Step [3900/4091], Loss: 550.4751\n",
      "Epoch [39/100], Step [4000/4091], Loss: 642.1204\n",
      "Epoch [40/100], Step [100/4091], Loss: 720.3238\n",
      "Epoch [40/100], Step [200/4091], Loss: 669.7124\n",
      "Epoch [40/100], Step [300/4091], Loss: 958.9209\n",
      "Epoch [40/100], Step [400/4091], Loss: 695.1307\n",
      "Epoch [40/100], Step [500/4091], Loss: 639.5038\n",
      "Epoch [40/100], Step [600/4091], Loss: 919.6443\n",
      "Epoch [40/100], Step [700/4091], Loss: 703.6569\n",
      "Epoch [40/100], Step [800/4091], Loss: 873.9211\n",
      "Epoch [40/100], Step [900/4091], Loss: 474.5173\n",
      "Epoch [40/100], Step [1000/4091], Loss: 727.2606\n",
      "Epoch [40/100], Step [1100/4091], Loss: 490.6607\n",
      "Epoch [40/100], Step [1200/4091], Loss: 653.1008\n",
      "Epoch [40/100], Step [1300/4091], Loss: 605.9059\n",
      "Epoch [40/100], Step [1400/4091], Loss: 675.8785\n",
      "Epoch [40/100], Step [1500/4091], Loss: 610.5077\n",
      "Epoch [40/100], Step [1600/4091], Loss: 592.5405\n",
      "Epoch [40/100], Step [1700/4091], Loss: 629.7340\n",
      "Epoch [40/100], Step [1800/4091], Loss: 574.3056\n",
      "Epoch [40/100], Step [1900/4091], Loss: 733.9835\n",
      "Epoch [40/100], Step [2000/4091], Loss: 623.3876\n",
      "Epoch [40/100], Step [2100/4091], Loss: 650.8359\n",
      "Epoch [40/100], Step [2200/4091], Loss: 570.2972\n",
      "Epoch [40/100], Step [2300/4091], Loss: 891.4859\n",
      "Epoch [40/100], Step [2400/4091], Loss: 552.5406\n",
      "Epoch [40/100], Step [2500/4091], Loss: 602.6331\n",
      "Epoch [40/100], Step [2600/4091], Loss: 688.3704\n",
      "Epoch [40/100], Step [2700/4091], Loss: 748.6106\n",
      "Epoch [40/100], Step [2800/4091], Loss: 622.2937\n",
      "Epoch [40/100], Step [2900/4091], Loss: 637.4716\n",
      "Epoch [40/100], Step [3000/4091], Loss: 617.1064\n",
      "Epoch [40/100], Step [3100/4091], Loss: 547.4191\n",
      "Epoch [40/100], Step [3200/4091], Loss: 674.8077\n",
      "Epoch [40/100], Step [3300/4091], Loss: 802.5291\n",
      "Epoch [40/100], Step [3400/4091], Loss: 750.7739\n",
      "Epoch [40/100], Step [3500/4091], Loss: 659.5822\n",
      "Epoch [40/100], Step [3600/4091], Loss: 660.8387\n",
      "Epoch [40/100], Step [3700/4091], Loss: 620.2366\n",
      "Epoch [40/100], Step [3800/4091], Loss: 761.8441\n",
      "Epoch [40/100], Step [3900/4091], Loss: 686.6918\n",
      "Epoch [40/100], Step [4000/4091], Loss: 739.0166\n",
      "Epoch [41/100], Step [100/4091], Loss: 751.1736\n",
      "Epoch [41/100], Step [200/4091], Loss: 665.3187\n",
      "Epoch [41/100], Step [300/4091], Loss: 556.9735\n",
      "Epoch [41/100], Step [400/4091], Loss: 794.2489\n",
      "Epoch [41/100], Step [500/4091], Loss: 797.0205\n",
      "Epoch [41/100], Step [600/4091], Loss: 767.1873\n",
      "Epoch [41/100], Step [700/4091], Loss: 763.2668\n",
      "Epoch [41/100], Step [800/4091], Loss: 754.8121\n",
      "Epoch [41/100], Step [900/4091], Loss: 554.6136\n",
      "Epoch [41/100], Step [1000/4091], Loss: 634.7066\n",
      "Epoch [41/100], Step [1100/4091], Loss: 730.0568\n",
      "Epoch [41/100], Step [1200/4091], Loss: 628.0074\n",
      "Epoch [41/100], Step [1300/4091], Loss: 757.5012\n",
      "Epoch [41/100], Step [1400/4091], Loss: 835.8821\n",
      "Epoch [41/100], Step [1500/4091], Loss: 613.0115\n",
      "Epoch [41/100], Step [1600/4091], Loss: 958.0989\n",
      "Epoch [41/100], Step [1700/4091], Loss: 732.8041\n",
      "Epoch [41/100], Step [1800/4091], Loss: 776.9295\n",
      "Epoch [41/100], Step [1900/4091], Loss: 567.2784\n",
      "Epoch [41/100], Step [2000/4091], Loss: 745.8328\n",
      "Epoch [41/100], Step [2100/4091], Loss: 655.8638\n",
      "Epoch [41/100], Step [2200/4091], Loss: 875.8634\n",
      "Epoch [41/100], Step [2300/4091], Loss: 570.2687\n",
      "Epoch [41/100], Step [2400/4091], Loss: 561.9406\n",
      "Epoch [41/100], Step [2500/4091], Loss: 651.9534\n",
      "Epoch [41/100], Step [2600/4091], Loss: 769.2649\n",
      "Epoch [41/100], Step [2700/4091], Loss: 619.2395\n",
      "Epoch [41/100], Step [2800/4091], Loss: 645.1646\n",
      "Epoch [41/100], Step [2900/4091], Loss: 622.5802\n",
      "Epoch [41/100], Step [3000/4091], Loss: 664.5949\n",
      "Epoch [41/100], Step [3100/4091], Loss: 758.7570\n",
      "Epoch [41/100], Step [3200/4091], Loss: 904.0969\n",
      "Epoch [41/100], Step [3300/4091], Loss: 680.6182\n",
      "Epoch [41/100], Step [3400/4091], Loss: 824.9029\n",
      "Epoch [41/100], Step [3500/4091], Loss: 850.7719\n",
      "Epoch [41/100], Step [3600/4091], Loss: 878.5236\n",
      "Epoch [41/100], Step [3700/4091], Loss: 802.2335\n",
      "Epoch [41/100], Step [3800/4091], Loss: 685.2046\n",
      "Epoch [41/100], Step [3900/4091], Loss: 905.2383\n",
      "Epoch [41/100], Step [4000/4091], Loss: 744.7048\n",
      "Epoch [42/100], Step [100/4091], Loss: 755.6754\n",
      "Epoch [42/100], Step [200/4091], Loss: 772.9313\n",
      "Epoch [42/100], Step [300/4091], Loss: 625.5438\n",
      "Epoch [42/100], Step [400/4091], Loss: 813.8708\n",
      "Epoch [42/100], Step [500/4091], Loss: 598.1147\n",
      "Epoch [42/100], Step [600/4091], Loss: 458.9409\n",
      "Epoch [42/100], Step [700/4091], Loss: 615.4631\n",
      "Epoch [42/100], Step [800/4091], Loss: 932.9838\n",
      "Epoch [42/100], Step [900/4091], Loss: 550.7034\n",
      "Epoch [42/100], Step [1000/4091], Loss: 662.4709\n",
      "Epoch [42/100], Step [1100/4091], Loss: 622.0790\n",
      "Epoch [42/100], Step [1200/4091], Loss: 557.7062\n",
      "Epoch [42/100], Step [1300/4091], Loss: 589.5909\n",
      "Epoch [42/100], Step [1400/4091], Loss: 749.3387\n",
      "Epoch [42/100], Step [1500/4091], Loss: 599.4449\n",
      "Epoch [42/100], Step [1600/4091], Loss: 677.9611\n",
      "Epoch [42/100], Step [1700/4091], Loss: 545.8640\n",
      "Epoch [42/100], Step [1800/4091], Loss: 510.9810\n",
      "Epoch [42/100], Step [1900/4091], Loss: 607.1919\n",
      "Epoch [42/100], Step [2000/4091], Loss: 639.4155\n",
      "Epoch [42/100], Step [2100/4091], Loss: 759.9082\n",
      "Epoch [42/100], Step [2200/4091], Loss: 676.6124\n",
      "Epoch [42/100], Step [2300/4091], Loss: 711.8110\n",
      "Epoch [42/100], Step [2400/4091], Loss: 767.0045\n",
      "Epoch [42/100], Step [2500/4091], Loss: 476.5750\n",
      "Epoch [42/100], Step [2600/4091], Loss: 595.7173\n",
      "Epoch [42/100], Step [2700/4091], Loss: 424.3952\n",
      "Epoch [42/100], Step [2800/4091], Loss: 550.1526\n",
      "Epoch [42/100], Step [2900/4091], Loss: 617.5224\n",
      "Epoch [42/100], Step [3000/4091], Loss: 1068.0881\n",
      "Epoch [42/100], Step [3100/4091], Loss: 641.0901\n",
      "Epoch [42/100], Step [3200/4091], Loss: 697.1921\n",
      "Epoch [42/100], Step [3300/4091], Loss: 765.3823\n",
      "Epoch [42/100], Step [3400/4091], Loss: 907.0695\n",
      "Epoch [42/100], Step [3500/4091], Loss: 613.9821\n",
      "Epoch [42/100], Step [3600/4091], Loss: 963.8079\n",
      "Epoch [42/100], Step [3700/4091], Loss: 530.2658\n",
      "Epoch [42/100], Step [3800/4091], Loss: 529.9169\n",
      "Epoch [42/100], Step [3900/4091], Loss: 814.1785\n",
      "Epoch [42/100], Step [4000/4091], Loss: 536.9270\n",
      "Epoch [43/100], Step [100/4091], Loss: 747.4092\n",
      "Epoch [43/100], Step [200/4091], Loss: 687.8599\n",
      "Epoch [43/100], Step [300/4091], Loss: 812.7125\n",
      "Epoch [43/100], Step [400/4091], Loss: 691.3453\n",
      "Epoch [43/100], Step [500/4091], Loss: 519.0590\n",
      "Epoch [43/100], Step [600/4091], Loss: 860.9257\n",
      "Epoch [43/100], Step [700/4091], Loss: 584.3846\n",
      "Epoch [43/100], Step [800/4091], Loss: 693.2342\n",
      "Epoch [43/100], Step [900/4091], Loss: 717.6919\n",
      "Epoch [43/100], Step [1000/4091], Loss: 566.6771\n",
      "Epoch [43/100], Step [1100/4091], Loss: 693.6520\n",
      "Epoch [43/100], Step [1200/4091], Loss: 688.8646\n",
      "Epoch [43/100], Step [1300/4091], Loss: 612.0323\n",
      "Epoch [43/100], Step [1400/4091], Loss: 858.8416\n",
      "Epoch [43/100], Step [1500/4091], Loss: 813.2078\n",
      "Epoch [43/100], Step [1600/4091], Loss: 594.8622\n",
      "Epoch [43/100], Step [1700/4091], Loss: 588.7603\n",
      "Epoch [43/100], Step [1800/4091], Loss: 497.4916\n",
      "Epoch [43/100], Step [1900/4091], Loss: 640.9321\n",
      "Epoch [43/100], Step [2000/4091], Loss: 792.3596\n",
      "Epoch [43/100], Step [2100/4091], Loss: 551.5532\n",
      "Epoch [43/100], Step [2200/4091], Loss: 626.7136\n",
      "Epoch [43/100], Step [2300/4091], Loss: 664.6194\n",
      "Epoch [43/100], Step [2400/4091], Loss: 509.6368\n",
      "Epoch [43/100], Step [2500/4091], Loss: 674.8579\n",
      "Epoch [43/100], Step [2600/4091], Loss: 561.6606\n",
      "Epoch [43/100], Step [2700/4091], Loss: 612.2375\n",
      "Epoch [43/100], Step [2800/4091], Loss: 568.2296\n",
      "Epoch [43/100], Step [2900/4091], Loss: 447.0262\n",
      "Epoch [43/100], Step [3000/4091], Loss: 662.6071\n",
      "Epoch [43/100], Step [3100/4091], Loss: 785.1993\n",
      "Epoch [43/100], Step [3200/4091], Loss: 647.7267\n",
      "Epoch [43/100], Step [3300/4091], Loss: 394.4864\n",
      "Epoch [43/100], Step [3400/4091], Loss: 582.3870\n",
      "Epoch [43/100], Step [3500/4091], Loss: 1040.1268\n",
      "Epoch [43/100], Step [3600/4091], Loss: 461.7128\n",
      "Epoch [43/100], Step [3700/4091], Loss: 666.3123\n",
      "Epoch [43/100], Step [3800/4091], Loss: 818.5441\n",
      "Epoch [43/100], Step [3900/4091], Loss: 764.6459\n",
      "Epoch [43/100], Step [4000/4091], Loss: 753.4926\n",
      "Epoch [44/100], Step [100/4091], Loss: 545.6226\n",
      "Epoch [44/100], Step [200/4091], Loss: 564.0244\n",
      "Epoch [44/100], Step [300/4091], Loss: 602.7753\n",
      "Epoch [44/100], Step [400/4091], Loss: 673.7486\n",
      "Epoch [44/100], Step [500/4091], Loss: 671.2731\n",
      "Epoch [44/100], Step [600/4091], Loss: 714.5518\n",
      "Epoch [44/100], Step [700/4091], Loss: 604.8356\n",
      "Epoch [44/100], Step [800/4091], Loss: 801.8491\n",
      "Epoch [44/100], Step [900/4091], Loss: 870.9625\n",
      "Epoch [44/100], Step [1000/4091], Loss: 686.0611\n",
      "Epoch [44/100], Step [1100/4091], Loss: 559.0989\n",
      "Epoch [44/100], Step [1200/4091], Loss: 601.3029\n",
      "Epoch [44/100], Step [1300/4091], Loss: 653.6855\n",
      "Epoch [44/100], Step [1400/4091], Loss: 729.3580\n",
      "Epoch [44/100], Step [1500/4091], Loss: 561.2039\n",
      "Epoch [44/100], Step [1600/4091], Loss: 642.9996\n",
      "Epoch [44/100], Step [1700/4091], Loss: 1003.8893\n",
      "Epoch [44/100], Step [1800/4091], Loss: 564.5975\n",
      "Epoch [44/100], Step [1900/4091], Loss: 715.2456\n",
      "Epoch [44/100], Step [2000/4091], Loss: 613.7623\n",
      "Epoch [44/100], Step [2100/4091], Loss: 675.8658\n",
      "Epoch [44/100], Step [2200/4091], Loss: 823.8576\n",
      "Epoch [44/100], Step [2300/4091], Loss: 592.6183\n",
      "Epoch [44/100], Step [2400/4091], Loss: 628.1716\n",
      "Epoch [44/100], Step [2500/4091], Loss: 623.8232\n",
      "Epoch [44/100], Step [2600/4091], Loss: 490.9338\n",
      "Epoch [44/100], Step [2700/4091], Loss: 680.8725\n",
      "Epoch [44/100], Step [2800/4091], Loss: 759.0462\n",
      "Epoch [44/100], Step [2900/4091], Loss: 529.7142\n",
      "Epoch [44/100], Step [3000/4091], Loss: 647.9307\n",
      "Epoch [44/100], Step [3100/4091], Loss: 772.4603\n",
      "Epoch [44/100], Step [3200/4091], Loss: 773.6774\n",
      "Epoch [44/100], Step [3300/4091], Loss: 654.2616\n",
      "Epoch [44/100], Step [3400/4091], Loss: 682.9968\n",
      "Epoch [44/100], Step [3500/4091], Loss: 622.0691\n",
      "Epoch [44/100], Step [3600/4091], Loss: 650.2684\n",
      "Epoch [44/100], Step [3700/4091], Loss: 533.2150\n",
      "Epoch [44/100], Step [3800/4091], Loss: 581.3717\n",
      "Epoch [44/100], Step [3900/4091], Loss: 657.2582\n",
      "Epoch [44/100], Step [4000/4091], Loss: 724.5755\n",
      "Epoch [45/100], Step [100/4091], Loss: 739.3326\n",
      "Epoch [45/100], Step [200/4091], Loss: 481.1906\n",
      "Epoch [45/100], Step [300/4091], Loss: 786.2526\n",
      "Epoch [45/100], Step [400/4091], Loss: 988.8157\n",
      "Epoch [45/100], Step [500/4091], Loss: 732.7383\n",
      "Epoch [45/100], Step [600/4091], Loss: 607.0167\n",
      "Epoch [45/100], Step [700/4091], Loss: 716.8744\n",
      "Epoch [45/100], Step [800/4091], Loss: 545.3691\n",
      "Epoch [45/100], Step [900/4091], Loss: 680.2477\n",
      "Epoch [45/100], Step [1000/4091], Loss: 746.5261\n",
      "Epoch [45/100], Step [1100/4091], Loss: 766.3564\n",
      "Epoch [45/100], Step [1200/4091], Loss: 644.0264\n",
      "Epoch [45/100], Step [1300/4091], Loss: 507.4684\n",
      "Epoch [45/100], Step [1400/4091], Loss: 851.4543\n",
      "Epoch [45/100], Step [1500/4091], Loss: 461.0759\n",
      "Epoch [45/100], Step [1600/4091], Loss: 643.8018\n",
      "Epoch [45/100], Step [1700/4091], Loss: 645.7549\n",
      "Epoch [45/100], Step [1800/4091], Loss: 822.6206\n",
      "Epoch [45/100], Step [1900/4091], Loss: 591.4518\n",
      "Epoch [45/100], Step [2000/4091], Loss: 691.7836\n",
      "Epoch [45/100], Step [2100/4091], Loss: 629.1969\n",
      "Epoch [45/100], Step [2200/4091], Loss: 676.3452\n",
      "Epoch [45/100], Step [2300/4091], Loss: 449.0635\n",
      "Epoch [45/100], Step [2400/4091], Loss: 896.8860\n",
      "Epoch [45/100], Step [2500/4091], Loss: 665.9536\n",
      "Epoch [45/100], Step [2600/4091], Loss: 632.8774\n",
      "Epoch [45/100], Step [2700/4091], Loss: 757.8026\n",
      "Epoch [45/100], Step [2800/4091], Loss: 623.6027\n",
      "Epoch [45/100], Step [2900/4091], Loss: 766.7448\n",
      "Epoch [45/100], Step [3000/4091], Loss: 577.6041\n",
      "Epoch [45/100], Step [3100/4091], Loss: 473.7253\n",
      "Epoch [45/100], Step [3200/4091], Loss: 525.5386\n",
      "Epoch [45/100], Step [3300/4091], Loss: 528.8112\n",
      "Epoch [45/100], Step [3400/4091], Loss: 524.8838\n",
      "Epoch [45/100], Step [3500/4091], Loss: 581.0963\n",
      "Epoch [45/100], Step [3600/4091], Loss: 587.8271\n",
      "Epoch [45/100], Step [3700/4091], Loss: 590.6071\n",
      "Epoch [45/100], Step [3800/4091], Loss: 676.7932\n",
      "Epoch [45/100], Step [3900/4091], Loss: 539.7620\n",
      "Epoch [45/100], Step [4000/4091], Loss: 832.4855\n",
      "Epoch [46/100], Step [100/4091], Loss: 709.9168\n",
      "Epoch [46/100], Step [200/4091], Loss: 674.5432\n",
      "Epoch [46/100], Step [300/4091], Loss: 680.8141\n",
      "Epoch [46/100], Step [400/4091], Loss: 707.0180\n",
      "Epoch [46/100], Step [500/4091], Loss: 627.8961\n",
      "Epoch [46/100], Step [600/4091], Loss: 842.6227\n",
      "Epoch [46/100], Step [700/4091], Loss: 574.7802\n",
      "Epoch [46/100], Step [800/4091], Loss: 608.4376\n",
      "Epoch [46/100], Step [900/4091], Loss: 557.7574\n",
      "Epoch [46/100], Step [1000/4091], Loss: 524.1165\n",
      "Epoch [46/100], Step [1100/4091], Loss: 439.4351\n",
      "Epoch [46/100], Step [1200/4091], Loss: 810.9192\n",
      "Epoch [46/100], Step [1300/4091], Loss: 535.9451\n",
      "Epoch [46/100], Step [1400/4091], Loss: 669.1746\n",
      "Epoch [46/100], Step [1500/4091], Loss: 640.5928\n",
      "Epoch [46/100], Step [1600/4091], Loss: 807.7617\n",
      "Epoch [46/100], Step [1700/4091], Loss: 434.8967\n",
      "Epoch [46/100], Step [1800/4091], Loss: 562.4503\n",
      "Epoch [46/100], Step [1900/4091], Loss: 618.1526\n",
      "Epoch [46/100], Step [2000/4091], Loss: 568.9762\n",
      "Epoch [46/100], Step [2100/4091], Loss: 564.2780\n",
      "Epoch [46/100], Step [2200/4091], Loss: 636.2913\n",
      "Epoch [46/100], Step [2300/4091], Loss: 829.7550\n",
      "Epoch [46/100], Step [2400/4091], Loss: 623.6567\n",
      "Epoch [46/100], Step [2500/4091], Loss: 668.9431\n",
      "Epoch [46/100], Step [2600/4091], Loss: 632.5049\n",
      "Epoch [46/100], Step [2700/4091], Loss: 640.5084\n",
      "Epoch [46/100], Step [2800/4091], Loss: 581.7010\n",
      "Epoch [46/100], Step [2900/4091], Loss: 783.3220\n",
      "Epoch [46/100], Step [3000/4091], Loss: 962.9268\n",
      "Epoch [46/100], Step [3100/4091], Loss: 800.5552\n",
      "Epoch [46/100], Step [3200/4091], Loss: 724.2614\n",
      "Epoch [46/100], Step [3300/4091], Loss: 876.3563\n",
      "Epoch [46/100], Step [3400/4091], Loss: 597.2122\n",
      "Epoch [46/100], Step [3500/4091], Loss: 627.4509\n",
      "Epoch [46/100], Step [3600/4091], Loss: 561.9576\n",
      "Epoch [46/100], Step [3700/4091], Loss: 466.5835\n",
      "Epoch [46/100], Step [3800/4091], Loss: 566.3636\n",
      "Epoch [46/100], Step [3900/4091], Loss: 621.8211\n",
      "Epoch [46/100], Step [4000/4091], Loss: 602.8868\n",
      "Epoch [47/100], Step [100/4091], Loss: 709.0003\n",
      "Epoch [47/100], Step [200/4091], Loss: 838.5693\n",
      "Epoch [47/100], Step [300/4091], Loss: 472.4670\n",
      "Epoch [47/100], Step [400/4091], Loss: 675.3157\n",
      "Epoch [47/100], Step [500/4091], Loss: 689.3730\n",
      "Epoch [47/100], Step [600/4091], Loss: 600.2423\n",
      "Epoch [47/100], Step [700/4091], Loss: 778.3771\n",
      "Epoch [47/100], Step [800/4091], Loss: 454.8838\n",
      "Epoch [47/100], Step [900/4091], Loss: 768.5590\n",
      "Epoch [47/100], Step [1000/4091], Loss: 673.9117\n",
      "Epoch [47/100], Step [1100/4091], Loss: 539.8134\n",
      "Epoch [47/100], Step [1200/4091], Loss: 704.9509\n",
      "Epoch [47/100], Step [1300/4091], Loss: 825.6928\n",
      "Epoch [47/100], Step [1400/4091], Loss: 592.4592\n",
      "Epoch [47/100], Step [1500/4091], Loss: 708.4398\n",
      "Epoch [47/100], Step [1600/4091], Loss: 862.9251\n",
      "Epoch [47/100], Step [1700/4091], Loss: 582.1906\n",
      "Epoch [47/100], Step [1800/4091], Loss: 621.0305\n",
      "Epoch [47/100], Step [1900/4091], Loss: 1054.4464\n",
      "Epoch [47/100], Step [2000/4091], Loss: 803.8005\n",
      "Epoch [47/100], Step [2100/4091], Loss: 651.0668\n",
      "Epoch [47/100], Step [2200/4091], Loss: 717.8169\n",
      "Epoch [47/100], Step [2300/4091], Loss: 718.2995\n",
      "Epoch [47/100], Step [2400/4091], Loss: 874.0123\n",
      "Epoch [47/100], Step [2500/4091], Loss: 698.1630\n",
      "Epoch [47/100], Step [2600/4091], Loss: 907.9397\n",
      "Epoch [47/100], Step [2700/4091], Loss: 689.8206\n",
      "Epoch [47/100], Step [2800/4091], Loss: 688.9231\n",
      "Epoch [47/100], Step [2900/4091], Loss: 615.5861\n",
      "Epoch [47/100], Step [3000/4091], Loss: 680.7307\n",
      "Epoch [47/100], Step [3100/4091], Loss: 760.6895\n",
      "Epoch [47/100], Step [3200/4091], Loss: 473.9683\n",
      "Epoch [47/100], Step [3300/4091], Loss: 622.2058\n",
      "Epoch [47/100], Step [3400/4091], Loss: 664.8976\n",
      "Epoch [47/100], Step [3500/4091], Loss: 882.2172\n",
      "Epoch [47/100], Step [3600/4091], Loss: 711.5278\n",
      "Epoch [47/100], Step [3700/4091], Loss: 784.2583\n",
      "Epoch [47/100], Step [3800/4091], Loss: 616.1123\n",
      "Epoch [47/100], Step [3900/4091], Loss: 513.9757\n",
      "Epoch [47/100], Step [4000/4091], Loss: 500.1187\n",
      "Epoch [48/100], Step [100/4091], Loss: 597.5825\n",
      "Epoch [48/100], Step [200/4091], Loss: 586.5886\n",
      "Epoch [48/100], Step [300/4091], Loss: 688.2338\n",
      "Epoch [48/100], Step [400/4091], Loss: 879.6321\n",
      "Epoch [48/100], Step [500/4091], Loss: 701.5054\n",
      "Epoch [48/100], Step [600/4091], Loss: 711.8967\n",
      "Epoch [48/100], Step [700/4091], Loss: 645.5865\n",
      "Epoch [48/100], Step [800/4091], Loss: 684.7438\n",
      "Epoch [48/100], Step [900/4091], Loss: 744.2966\n",
      "Epoch [48/100], Step [1000/4091], Loss: 736.8654\n",
      "Epoch [48/100], Step [1100/4091], Loss: 542.3336\n",
      "Epoch [48/100], Step [1200/4091], Loss: 659.4288\n",
      "Epoch [48/100], Step [1300/4091], Loss: 601.9215\n",
      "Epoch [48/100], Step [1400/4091], Loss: 679.9427\n",
      "Epoch [48/100], Step [1500/4091], Loss: 811.9140\n",
      "Epoch [48/100], Step [1600/4091], Loss: 461.8565\n",
      "Epoch [48/100], Step [1700/4091], Loss: 657.0920\n",
      "Epoch [48/100], Step [1800/4091], Loss: 668.6723\n",
      "Epoch [48/100], Step [1900/4091], Loss: 561.8247\n",
      "Epoch [48/100], Step [2000/4091], Loss: 680.8260\n",
      "Epoch [48/100], Step [2100/4091], Loss: 569.0566\n",
      "Epoch [48/100], Step [2200/4091], Loss: 494.5526\n",
      "Epoch [48/100], Step [2300/4091], Loss: 679.8528\n",
      "Epoch [48/100], Step [2400/4091], Loss: 769.4108\n",
      "Epoch [48/100], Step [2500/4091], Loss: 952.4042\n",
      "Epoch [48/100], Step [2600/4091], Loss: 945.5065\n",
      "Epoch [48/100], Step [2700/4091], Loss: 712.9664\n",
      "Epoch [48/100], Step [2800/4091], Loss: 680.3042\n",
      "Epoch [48/100], Step [2900/4091], Loss: 563.1379\n",
      "Epoch [48/100], Step [3000/4091], Loss: 835.7366\n",
      "Epoch [48/100], Step [3100/4091], Loss: 625.9013\n",
      "Epoch [48/100], Step [3200/4091], Loss: 539.2211\n",
      "Epoch [48/100], Step [3300/4091], Loss: 621.5522\n",
      "Epoch [48/100], Step [3400/4091], Loss: 832.9484\n",
      "Epoch [48/100], Step [3500/4091], Loss: 597.6149\n",
      "Epoch [48/100], Step [3600/4091], Loss: 528.4100\n",
      "Epoch [48/100], Step [3700/4091], Loss: 528.8325\n",
      "Epoch [48/100], Step [3800/4091], Loss: 731.1747\n",
      "Epoch [48/100], Step [3900/4091], Loss: 691.2051\n",
      "Epoch [48/100], Step [4000/4091], Loss: 383.1115\n",
      "Epoch [49/100], Step [100/4091], Loss: 662.6103\n",
      "Epoch [49/100], Step [200/4091], Loss: 909.2783\n",
      "Epoch [49/100], Step [300/4091], Loss: 719.6872\n",
      "Epoch [49/100], Step [400/4091], Loss: 687.1960\n",
      "Epoch [49/100], Step [500/4091], Loss: 620.5020\n",
      "Epoch [49/100], Step [600/4091], Loss: 709.0714\n",
      "Epoch [49/100], Step [700/4091], Loss: 544.5575\n",
      "Epoch [49/100], Step [800/4091], Loss: 647.2440\n",
      "Epoch [49/100], Step [900/4091], Loss: 818.8052\n",
      "Epoch [49/100], Step [1000/4091], Loss: 542.2900\n",
      "Epoch [49/100], Step [1100/4091], Loss: 664.8181\n",
      "Epoch [49/100], Step [1200/4091], Loss: 571.3368\n",
      "Epoch [49/100], Step [1300/4091], Loss: 799.7692\n",
      "Epoch [49/100], Step [1400/4091], Loss: 800.1722\n",
      "Epoch [49/100], Step [1500/4091], Loss: 527.7144\n",
      "Epoch [49/100], Step [1600/4091], Loss: 862.9078\n",
      "Epoch [49/100], Step [1700/4091], Loss: 705.8025\n",
      "Epoch [49/100], Step [1800/4091], Loss: 644.8754\n",
      "Epoch [49/100], Step [1900/4091], Loss: 959.1862\n",
      "Epoch [49/100], Step [2000/4091], Loss: 681.7830\n",
      "Epoch [49/100], Step [2100/4091], Loss: 743.3782\n",
      "Epoch [49/100], Step [2200/4091], Loss: 627.5988\n",
      "Epoch [49/100], Step [2300/4091], Loss: 592.6664\n",
      "Epoch [49/100], Step [2400/4091], Loss: 795.8788\n",
      "Epoch [49/100], Step [2500/4091], Loss: 512.4915\n",
      "Epoch [49/100], Step [2600/4091], Loss: 672.5978\n",
      "Epoch [49/100], Step [2700/4091], Loss: 647.7321\n",
      "Epoch [49/100], Step [2800/4091], Loss: 402.5530\n",
      "Epoch [49/100], Step [2900/4091], Loss: 739.0900\n",
      "Epoch [49/100], Step [3000/4091], Loss: 709.9480\n",
      "Epoch [49/100], Step [3100/4091], Loss: 590.6841\n",
      "Epoch [49/100], Step [3200/4091], Loss: 930.6112\n",
      "Epoch [49/100], Step [3300/4091], Loss: 634.2380\n",
      "Epoch [49/100], Step [3400/4091], Loss: 664.6965\n",
      "Epoch [49/100], Step [3500/4091], Loss: 609.9177\n",
      "Epoch [49/100], Step [3600/4091], Loss: 676.1117\n",
      "Epoch [49/100], Step [3700/4091], Loss: 686.3912\n",
      "Epoch [49/100], Step [3800/4091], Loss: 522.2582\n",
      "Epoch [49/100], Step [3900/4091], Loss: 760.5278\n",
      "Epoch [49/100], Step [4000/4091], Loss: 531.1816\n",
      "Epoch [50/100], Step [100/4091], Loss: 721.2329\n",
      "Epoch [50/100], Step [200/4091], Loss: 663.6366\n",
      "Epoch [50/100], Step [300/4091], Loss: 821.4873\n",
      "Epoch [50/100], Step [400/4091], Loss: 745.8536\n",
      "Epoch [50/100], Step [500/4091], Loss: 671.9427\n",
      "Epoch [50/100], Step [600/4091], Loss: 807.4362\n",
      "Epoch [50/100], Step [700/4091], Loss: 833.4454\n",
      "Epoch [50/100], Step [800/4091], Loss: 753.1566\n",
      "Epoch [50/100], Step [900/4091], Loss: 546.5300\n",
      "Epoch [50/100], Step [1000/4091], Loss: 746.3428\n",
      "Epoch [50/100], Step [1100/4091], Loss: 630.1355\n",
      "Epoch [50/100], Step [1200/4091], Loss: 607.2505\n",
      "Epoch [50/100], Step [1300/4091], Loss: 684.8594\n",
      "Epoch [50/100], Step [1400/4091], Loss: 711.3495\n",
      "Epoch [50/100], Step [1500/4091], Loss: 582.4048\n",
      "Epoch [50/100], Step [1600/4091], Loss: 552.1472\n",
      "Epoch [50/100], Step [1700/4091], Loss: 517.7335\n",
      "Epoch [50/100], Step [1800/4091], Loss: 723.5087\n",
      "Epoch [50/100], Step [1900/4091], Loss: 839.1898\n",
      "Epoch [50/100], Step [2000/4091], Loss: 590.2799\n",
      "Epoch [50/100], Step [2100/4091], Loss: 709.7093\n",
      "Epoch [50/100], Step [2200/4091], Loss: 874.5981\n",
      "Epoch [50/100], Step [2300/4091], Loss: 619.6708\n",
      "Epoch [50/100], Step [2400/4091], Loss: 958.9379\n",
      "Epoch [50/100], Step [2500/4091], Loss: 727.0811\n",
      "Epoch [50/100], Step [2600/4091], Loss: 693.4122\n",
      "Epoch [50/100], Step [2700/4091], Loss: 737.2756\n",
      "Epoch [50/100], Step [2800/4091], Loss: 565.4351\n",
      "Epoch [50/100], Step [2900/4091], Loss: 610.6455\n",
      "Epoch [50/100], Step [3000/4091], Loss: 561.1036\n",
      "Epoch [50/100], Step [3100/4091], Loss: 722.8594\n",
      "Epoch [50/100], Step [3200/4091], Loss: 677.6801\n",
      "Epoch [50/100], Step [3300/4091], Loss: 698.6624\n",
      "Epoch [50/100], Step [3400/4091], Loss: 925.8096\n",
      "Epoch [50/100], Step [3500/4091], Loss: 536.1176\n",
      "Epoch [50/100], Step [3600/4091], Loss: 769.7456\n",
      "Epoch [50/100], Step [3700/4091], Loss: 540.7006\n",
      "Epoch [50/100], Step [3800/4091], Loss: 645.8889\n",
      "Epoch [50/100], Step [3900/4091], Loss: 772.5020\n",
      "Epoch [50/100], Step [4000/4091], Loss: 1015.1084\n",
      "Epoch [51/100], Step [100/4091], Loss: 658.2981\n",
      "Epoch [51/100], Step [200/4091], Loss: 816.5600\n",
      "Epoch [51/100], Step [300/4091], Loss: 807.4601\n",
      "Epoch [51/100], Step [400/4091], Loss: 517.4921\n",
      "Epoch [51/100], Step [500/4091], Loss: 606.9832\n",
      "Epoch [51/100], Step [600/4091], Loss: 720.0895\n",
      "Epoch [51/100], Step [700/4091], Loss: 919.9967\n",
      "Epoch [51/100], Step [800/4091], Loss: 800.8569\n",
      "Epoch [51/100], Step [900/4091], Loss: 803.4376\n",
      "Epoch [51/100], Step [1000/4091], Loss: 626.8213\n",
      "Epoch [51/100], Step [1100/4091], Loss: 516.4697\n",
      "Epoch [51/100], Step [1200/4091], Loss: 485.2104\n",
      "Epoch [51/100], Step [1300/4091], Loss: 688.6240\n",
      "Epoch [51/100], Step [1400/4091], Loss: 723.2493\n",
      "Epoch [51/100], Step [1500/4091], Loss: 591.9066\n",
      "Epoch [51/100], Step [1600/4091], Loss: 528.5279\n",
      "Epoch [51/100], Step [1700/4091], Loss: 718.0116\n",
      "Epoch [51/100], Step [1800/4091], Loss: 758.1712\n",
      "Epoch [51/100], Step [1900/4091], Loss: 743.7792\n",
      "Epoch [51/100], Step [2000/4091], Loss: 749.9618\n",
      "Epoch [51/100], Step [2100/4091], Loss: 837.1355\n",
      "Epoch [51/100], Step [2200/4091], Loss: 1084.0001\n",
      "Epoch [51/100], Step [2300/4091], Loss: 766.5568\n",
      "Epoch [51/100], Step [2400/4091], Loss: 878.6017\n",
      "Epoch [51/100], Step [2500/4091], Loss: 719.0013\n",
      "Epoch [51/100], Step [2600/4091], Loss: 677.5057\n",
      "Epoch [51/100], Step [2700/4091], Loss: 590.5466\n",
      "Epoch [51/100], Step [2800/4091], Loss: 485.9888\n",
      "Epoch [51/100], Step [2900/4091], Loss: 834.6910\n",
      "Epoch [51/100], Step [3000/4091], Loss: 524.5644\n",
      "Epoch [51/100], Step [3100/4091], Loss: 848.4810\n",
      "Epoch [51/100], Step [3200/4091], Loss: 474.8326\n",
      "Epoch [51/100], Step [3300/4091], Loss: 647.4061\n",
      "Epoch [51/100], Step [3400/4091], Loss: 736.7911\n",
      "Epoch [51/100], Step [3500/4091], Loss: 761.6190\n",
      "Epoch [51/100], Step [3600/4091], Loss: 539.7011\n",
      "Epoch [51/100], Step [3700/4091], Loss: 926.6797\n",
      "Epoch [51/100], Step [3800/4091], Loss: 632.3248\n",
      "Epoch [51/100], Step [3900/4091], Loss: 715.6313\n",
      "Epoch [51/100], Step [4000/4091], Loss: 759.2729\n",
      "Epoch [52/100], Step [100/4091], Loss: 668.1832\n",
      "Epoch [52/100], Step [200/4091], Loss: 614.2493\n",
      "Epoch [52/100], Step [300/4091], Loss: 709.7122\n",
      "Epoch [52/100], Step [400/4091], Loss: 741.4874\n",
      "Epoch [52/100], Step [500/4091], Loss: 764.1970\n",
      "Epoch [52/100], Step [600/4091], Loss: 733.4460\n",
      "Epoch [52/100], Step [700/4091], Loss: 627.9989\n",
      "Epoch [52/100], Step [800/4091], Loss: 741.7420\n",
      "Epoch [52/100], Step [900/4091], Loss: 670.6761\n",
      "Epoch [52/100], Step [1000/4091], Loss: 581.3971\n",
      "Epoch [52/100], Step [1100/4091], Loss: 763.3275\n",
      "Epoch [52/100], Step [1200/4091], Loss: 960.4244\n",
      "Epoch [52/100], Step [1300/4091], Loss: 511.3981\n",
      "Epoch [52/100], Step [1400/4091], Loss: 764.8731\n",
      "Epoch [52/100], Step [1500/4091], Loss: 557.1952\n",
      "Epoch [52/100], Step [1600/4091], Loss: 656.5184\n",
      "Epoch [52/100], Step [1700/4091], Loss: 741.8534\n",
      "Epoch [52/100], Step [1800/4091], Loss: 793.5366\n",
      "Epoch [52/100], Step [1900/4091], Loss: 736.7050\n",
      "Epoch [52/100], Step [2000/4091], Loss: 541.7827\n",
      "Epoch [52/100], Step [2100/4091], Loss: 749.8171\n",
      "Epoch [52/100], Step [2200/4091], Loss: 733.7769\n",
      "Epoch [52/100], Step [2300/4091], Loss: 802.7345\n",
      "Epoch [52/100], Step [2400/4091], Loss: 641.1740\n",
      "Epoch [52/100], Step [2500/4091], Loss: 669.5905\n",
      "Epoch [52/100], Step [2600/4091], Loss: 725.4191\n",
      "Epoch [52/100], Step [2700/4091], Loss: 550.8771\n",
      "Epoch [52/100], Step [2800/4091], Loss: 629.4542\n",
      "Epoch [52/100], Step [2900/4091], Loss: 829.0276\n",
      "Epoch [52/100], Step [3000/4091], Loss: 502.7062\n",
      "Epoch [52/100], Step [3100/4091], Loss: 598.5416\n",
      "Epoch [52/100], Step [3200/4091], Loss: 498.9177\n",
      "Epoch [52/100], Step [3300/4091], Loss: 535.8409\n",
      "Epoch [52/100], Step [3400/4091], Loss: 649.4618\n",
      "Epoch [52/100], Step [3500/4091], Loss: 512.9119\n",
      "Epoch [52/100], Step [3600/4091], Loss: 850.2196\n",
      "Epoch [52/100], Step [3700/4091], Loss: 611.4629\n",
      "Epoch [52/100], Step [3800/4091], Loss: 655.3368\n",
      "Epoch [52/100], Step [3900/4091], Loss: 530.1069\n",
      "Epoch [52/100], Step [4000/4091], Loss: 611.4360\n",
      "Epoch [53/100], Step [100/4091], Loss: 583.4510\n",
      "Epoch [53/100], Step [200/4091], Loss: 778.6832\n",
      "Epoch [53/100], Step [300/4091], Loss: 479.6520\n",
      "Epoch [53/100], Step [400/4091], Loss: 596.2668\n",
      "Epoch [53/100], Step [500/4091], Loss: 512.3756\n",
      "Epoch [53/100], Step [600/4091], Loss: 669.2602\n",
      "Epoch [53/100], Step [700/4091], Loss: 509.7614\n",
      "Epoch [53/100], Step [800/4091], Loss: 523.9502\n",
      "Epoch [53/100], Step [900/4091], Loss: 938.0820\n",
      "Epoch [53/100], Step [1000/4091], Loss: 987.2899\n",
      "Epoch [53/100], Step [1100/4091], Loss: 781.8867\n",
      "Epoch [53/100], Step [1200/4091], Loss: 696.7879\n",
      "Epoch [53/100], Step [1300/4091], Loss: 672.0669\n",
      "Epoch [53/100], Step [1400/4091], Loss: 579.1239\n",
      "Epoch [53/100], Step [1500/4091], Loss: 617.8521\n",
      "Epoch [53/100], Step [1600/4091], Loss: 761.1993\n",
      "Epoch [53/100], Step [1700/4091], Loss: 725.5939\n",
      "Epoch [53/100], Step [1800/4091], Loss: 565.4699\n",
      "Epoch [53/100], Step [1900/4091], Loss: 772.5251\n",
      "Epoch [53/100], Step [2000/4091], Loss: 647.4518\n",
      "Epoch [53/100], Step [2100/4091], Loss: 659.4858\n",
      "Epoch [53/100], Step [2200/4091], Loss: 530.7851\n",
      "Epoch [53/100], Step [2300/4091], Loss: 523.8669\n",
      "Epoch [53/100], Step [2400/4091], Loss: 599.5524\n",
      "Epoch [53/100], Step [2500/4091], Loss: 633.4169\n",
      "Epoch [53/100], Step [2600/4091], Loss: 719.1227\n",
      "Epoch [53/100], Step [2700/4091], Loss: 800.9704\n",
      "Epoch [53/100], Step [2800/4091], Loss: 647.1552\n",
      "Epoch [53/100], Step [2900/4091], Loss: 1020.1249\n",
      "Epoch [53/100], Step [3000/4091], Loss: 599.6687\n",
      "Epoch [53/100], Step [3100/4091], Loss: 834.6476\n",
      "Epoch [53/100], Step [3200/4091], Loss: 444.3758\n",
      "Epoch [53/100], Step [3300/4091], Loss: 568.4873\n",
      "Epoch [53/100], Step [3400/4091], Loss: 648.7596\n",
      "Epoch [53/100], Step [3500/4091], Loss: 431.0231\n",
      "Epoch [53/100], Step [3600/4091], Loss: 578.8029\n",
      "Epoch [53/100], Step [3700/4091], Loss: 745.2971\n",
      "Epoch [53/100], Step [3800/4091], Loss: 498.2122\n",
      "Epoch [53/100], Step [3900/4091], Loss: 609.3453\n",
      "Epoch [53/100], Step [4000/4091], Loss: 514.1806\n",
      "Epoch [54/100], Step [100/4091], Loss: 621.0524\n",
      "Epoch [54/100], Step [200/4091], Loss: 862.6485\n",
      "Epoch [54/100], Step [300/4091], Loss: 510.9086\n",
      "Epoch [54/100], Step [400/4091], Loss: 597.6479\n",
      "Epoch [54/100], Step [500/4091], Loss: 682.8994\n",
      "Epoch [54/100], Step [600/4091], Loss: 563.4883\n",
      "Epoch [54/100], Step [700/4091], Loss: 682.7649\n",
      "Epoch [54/100], Step [800/4091], Loss: 512.7841\n",
      "Epoch [54/100], Step [900/4091], Loss: 926.6016\n",
      "Epoch [54/100], Step [1000/4091], Loss: 805.8152\n",
      "Epoch [54/100], Step [1100/4091], Loss: 693.5461\n",
      "Epoch [54/100], Step [1200/4091], Loss: 771.3612\n",
      "Epoch [54/100], Step [1300/4091], Loss: 585.6456\n",
      "Epoch [54/100], Step [1400/4091], Loss: 449.9878\n",
      "Epoch [54/100], Step [1500/4091], Loss: 637.4364\n",
      "Epoch [54/100], Step [1600/4091], Loss: 446.0476\n",
      "Epoch [54/100], Step [1700/4091], Loss: 722.4882\n",
      "Epoch [54/100], Step [1800/4091], Loss: 752.9213\n",
      "Epoch [54/100], Step [1900/4091], Loss: 744.9064\n",
      "Epoch [54/100], Step [2000/4091], Loss: 872.4417\n",
      "Epoch [54/100], Step [2100/4091], Loss: 638.4990\n",
      "Epoch [54/100], Step [2200/4091], Loss: 592.9058\n",
      "Epoch [54/100], Step [2300/4091], Loss: 680.1078\n",
      "Epoch [54/100], Step [2400/4091], Loss: 907.5521\n",
      "Epoch [54/100], Step [2500/4091], Loss: 514.9958\n",
      "Epoch [54/100], Step [2600/4091], Loss: 584.8013\n",
      "Epoch [54/100], Step [2700/4091], Loss: 795.7628\n",
      "Epoch [54/100], Step [2800/4091], Loss: 741.0479\n",
      "Epoch [54/100], Step [2900/4091], Loss: 555.9579\n",
      "Epoch [54/100], Step [3000/4091], Loss: 533.4704\n",
      "Epoch [54/100], Step [3100/4091], Loss: 595.9194\n",
      "Epoch [54/100], Step [3200/4091], Loss: 663.2332\n",
      "Epoch [54/100], Step [3300/4091], Loss: 502.1014\n",
      "Epoch [54/100], Step [3400/4091], Loss: 765.6505\n",
      "Epoch [54/100], Step [3500/4091], Loss: 545.6140\n",
      "Epoch [54/100], Step [3600/4091], Loss: 870.7299\n",
      "Epoch [54/100], Step [3700/4091], Loss: 645.9100\n",
      "Epoch [54/100], Step [3800/4091], Loss: 689.8379\n",
      "Epoch [54/100], Step [3900/4091], Loss: 850.9987\n",
      "Epoch [54/100], Step [4000/4091], Loss: 683.9728\n",
      "Epoch [55/100], Step [100/4091], Loss: 865.2630\n",
      "Epoch [55/100], Step [200/4091], Loss: 530.7450\n",
      "Epoch [55/100], Step [300/4091], Loss: 815.3213\n",
      "Epoch [55/100], Step [400/4091], Loss: 703.3004\n",
      "Epoch [55/100], Step [500/4091], Loss: 610.3700\n",
      "Epoch [55/100], Step [600/4091], Loss: 590.8288\n",
      "Epoch [55/100], Step [700/4091], Loss: 701.2299\n",
      "Epoch [55/100], Step [800/4091], Loss: 487.5107\n",
      "Epoch [55/100], Step [900/4091], Loss: 640.6331\n",
      "Epoch [55/100], Step [1000/4091], Loss: 436.7340\n",
      "Epoch [55/100], Step [1100/4091], Loss: 583.4142\n",
      "Epoch [55/100], Step [1200/4091], Loss: 489.9120\n",
      "Epoch [55/100], Step [1300/4091], Loss: 673.1382\n",
      "Epoch [55/100], Step [1400/4091], Loss: 614.1968\n",
      "Epoch [55/100], Step [1500/4091], Loss: 736.5685\n",
      "Epoch [55/100], Step [1600/4091], Loss: 518.4334\n",
      "Epoch [55/100], Step [1700/4091], Loss: 605.3201\n",
      "Epoch [55/100], Step [1800/4091], Loss: 876.3401\n",
      "Epoch [55/100], Step [1900/4091], Loss: 791.1204\n",
      "Epoch [55/100], Step [2000/4091], Loss: 801.3212\n",
      "Epoch [55/100], Step [2100/4091], Loss: 608.3561\n",
      "Epoch [55/100], Step [2200/4091], Loss: 809.2330\n",
      "Epoch [55/100], Step [2300/4091], Loss: 582.5997\n",
      "Epoch [55/100], Step [2400/4091], Loss: 761.2395\n",
      "Epoch [55/100], Step [2500/4091], Loss: 849.6112\n",
      "Epoch [55/100], Step [2600/4091], Loss: 670.3134\n",
      "Epoch [55/100], Step [2700/4091], Loss: 538.7990\n",
      "Epoch [55/100], Step [2800/4091], Loss: 532.0540\n",
      "Epoch [55/100], Step [2900/4091], Loss: 562.7594\n",
      "Epoch [55/100], Step [3000/4091], Loss: 786.5921\n",
      "Epoch [55/100], Step [3100/4091], Loss: 740.1055\n",
      "Epoch [55/100], Step [3200/4091], Loss: 798.8386\n",
      "Epoch [55/100], Step [3300/4091], Loss: 785.4023\n",
      "Epoch [55/100], Step [3400/4091], Loss: 557.4930\n",
      "Epoch [55/100], Step [3500/4091], Loss: 559.5727\n",
      "Epoch [55/100], Step [3600/4091], Loss: 807.7615\n",
      "Epoch [55/100], Step [3700/4091], Loss: 517.7469\n",
      "Epoch [55/100], Step [3800/4091], Loss: 490.8554\n",
      "Epoch [55/100], Step [3900/4091], Loss: 643.1233\n",
      "Epoch [55/100], Step [4000/4091], Loss: 591.6318\n",
      "Epoch [56/100], Step [100/4091], Loss: 427.8704\n",
      "Epoch [56/100], Step [200/4091], Loss: 486.1297\n",
      "Epoch [56/100], Step [300/4091], Loss: 708.6727\n",
      "Epoch [56/100], Step [400/4091], Loss: 633.0989\n",
      "Epoch [56/100], Step [500/4091], Loss: 772.6116\n",
      "Epoch [56/100], Step [600/4091], Loss: 570.3950\n",
      "Epoch [56/100], Step [700/4091], Loss: 772.0635\n",
      "Epoch [56/100], Step [800/4091], Loss: 767.9119\n",
      "Epoch [56/100], Step [900/4091], Loss: 772.9948\n",
      "Epoch [56/100], Step [1000/4091], Loss: 709.0639\n",
      "Epoch [56/100], Step [1100/4091], Loss: 744.9312\n",
      "Epoch [56/100], Step [1200/4091], Loss: 553.3054\n",
      "Epoch [56/100], Step [1300/4091], Loss: 548.6703\n",
      "Epoch [56/100], Step [1400/4091], Loss: 740.4319\n",
      "Epoch [56/100], Step [1500/4091], Loss: 624.9067\n",
      "Epoch [56/100], Step [1600/4091], Loss: 662.4069\n",
      "Epoch [56/100], Step [1700/4091], Loss: 545.1296\n",
      "Epoch [56/100], Step [1800/4091], Loss: 711.2704\n",
      "Epoch [56/100], Step [1900/4091], Loss: 678.0274\n",
      "Epoch [56/100], Step [2000/4091], Loss: 721.5084\n",
      "Epoch [56/100], Step [2100/4091], Loss: 503.1834\n",
      "Epoch [56/100], Step [2200/4091], Loss: 630.2067\n",
      "Epoch [56/100], Step [2300/4091], Loss: 745.0637\n",
      "Epoch [56/100], Step [2400/4091], Loss: 724.2032\n",
      "Epoch [56/100], Step [2500/4091], Loss: 541.2396\n",
      "Epoch [56/100], Step [2600/4091], Loss: 621.8976\n",
      "Epoch [56/100], Step [2700/4091], Loss: 611.1798\n",
      "Epoch [56/100], Step [2800/4091], Loss: 694.9104\n",
      "Epoch [56/100], Step [2900/4091], Loss: 787.3851\n",
      "Epoch [56/100], Step [3000/4091], Loss: 701.8107\n",
      "Epoch [56/100], Step [3100/4091], Loss: 710.3857\n",
      "Epoch [56/100], Step [3200/4091], Loss: 534.0971\n",
      "Epoch [56/100], Step [3300/4091], Loss: 477.5046\n",
      "Epoch [56/100], Step [3400/4091], Loss: 612.7827\n",
      "Epoch [56/100], Step [3500/4091], Loss: 738.4459\n",
      "Epoch [56/100], Step [3600/4091], Loss: 570.5654\n",
      "Epoch [56/100], Step [3700/4091], Loss: 594.8148\n",
      "Epoch [56/100], Step [3800/4091], Loss: 800.9129\n",
      "Epoch [56/100], Step [3900/4091], Loss: 549.4374\n",
      "Epoch [56/100], Step [4000/4091], Loss: 717.7253\n",
      "Epoch [57/100], Step [100/4091], Loss: 940.0017\n",
      "Epoch [57/100], Step [200/4091], Loss: 478.1186\n",
      "Epoch [57/100], Step [300/4091], Loss: 861.4798\n",
      "Epoch [57/100], Step [400/4091], Loss: 577.2782\n",
      "Epoch [57/100], Step [500/4091], Loss: 694.9762\n",
      "Epoch [57/100], Step [600/4091], Loss: 676.7216\n",
      "Epoch [57/100], Step [700/4091], Loss: 630.2278\n",
      "Epoch [57/100], Step [800/4091], Loss: 620.5148\n",
      "Epoch [57/100], Step [900/4091], Loss: 847.5594\n",
      "Epoch [57/100], Step [1000/4091], Loss: 640.4235\n",
      "Epoch [57/100], Step [1100/4091], Loss: 592.6450\n",
      "Epoch [57/100], Step [1200/4091], Loss: 730.4477\n",
      "Epoch [57/100], Step [1300/4091], Loss: 499.9067\n",
      "Epoch [57/100], Step [1400/4091], Loss: 580.6858\n",
      "Epoch [57/100], Step [1500/4091], Loss: 685.7302\n",
      "Epoch [57/100], Step [1600/4091], Loss: 574.0895\n",
      "Epoch [57/100], Step [1700/4091], Loss: 759.4021\n",
      "Epoch [57/100], Step [1800/4091], Loss: 792.2887\n",
      "Epoch [57/100], Step [1900/4091], Loss: 589.6488\n",
      "Epoch [57/100], Step [2000/4091], Loss: 648.0102\n",
      "Epoch [57/100], Step [2100/4091], Loss: 762.6495\n",
      "Epoch [57/100], Step [2200/4091], Loss: 942.1052\n",
      "Epoch [57/100], Step [2300/4091], Loss: 685.0363\n",
      "Epoch [57/100], Step [2400/4091], Loss: 509.3595\n",
      "Epoch [57/100], Step [2500/4091], Loss: 657.0867\n",
      "Epoch [57/100], Step [2600/4091], Loss: 552.2697\n",
      "Epoch [57/100], Step [2700/4091], Loss: 946.5267\n",
      "Epoch [57/100], Step [2800/4091], Loss: 504.4583\n",
      "Epoch [57/100], Step [2900/4091], Loss: 450.8638\n",
      "Epoch [57/100], Step [3000/4091], Loss: 751.9050\n",
      "Epoch [57/100], Step [3100/4091], Loss: 828.7059\n",
      "Epoch [57/100], Step [3200/4091], Loss: 716.2573\n",
      "Epoch [57/100], Step [3300/4091], Loss: 593.0442\n",
      "Epoch [57/100], Step [3400/4091], Loss: 511.5531\n",
      "Epoch [57/100], Step [3500/4091], Loss: 693.2064\n",
      "Epoch [57/100], Step [3600/4091], Loss: 586.5301\n",
      "Epoch [57/100], Step [3700/4091], Loss: 595.5402\n",
      "Epoch [57/100], Step [3800/4091], Loss: 679.3743\n",
      "Epoch [57/100], Step [3900/4091], Loss: 714.9407\n",
      "Epoch [57/100], Step [4000/4091], Loss: 869.7723\n",
      "Epoch [58/100], Step [100/4091], Loss: 651.8936\n",
      "Epoch [58/100], Step [200/4091], Loss: 801.9197\n",
      "Epoch [58/100], Step [300/4091], Loss: 950.3955\n",
      "Epoch [58/100], Step [400/4091], Loss: 375.7209\n",
      "Epoch [58/100], Step [500/4091], Loss: 780.4553\n",
      "Epoch [58/100], Step [600/4091], Loss: 752.7153\n",
      "Epoch [58/100], Step [700/4091], Loss: 780.7669\n",
      "Epoch [58/100], Step [800/4091], Loss: 690.2859\n",
      "Epoch [58/100], Step [900/4091], Loss: 638.7904\n",
      "Epoch [58/100], Step [1000/4091], Loss: 595.8988\n",
      "Epoch [58/100], Step [1100/4091], Loss: 612.8719\n",
      "Epoch [58/100], Step [1200/4091], Loss: 797.4233\n",
      "Epoch [58/100], Step [1300/4091], Loss: 497.0124\n",
      "Epoch [58/100], Step [1400/4091], Loss: 639.6559\n",
      "Epoch [58/100], Step [1500/4091], Loss: 705.7219\n",
      "Epoch [58/100], Step [1600/4091], Loss: 768.8136\n",
      "Epoch [58/100], Step [1700/4091], Loss: 704.7878\n",
      "Epoch [58/100], Step [1800/4091], Loss: 743.5355\n",
      "Epoch [58/100], Step [1900/4091], Loss: 611.9402\n",
      "Epoch [58/100], Step [2000/4091], Loss: 901.5054\n",
      "Epoch [58/100], Step [2100/4091], Loss: 547.0434\n",
      "Epoch [58/100], Step [2200/4091], Loss: 789.9861\n",
      "Epoch [58/100], Step [2300/4091], Loss: 871.5853\n",
      "Epoch [58/100], Step [2400/4091], Loss: 800.3284\n",
      "Epoch [58/100], Step [2500/4091], Loss: 693.3799\n",
      "Epoch [58/100], Step [2600/4091], Loss: 563.2119\n",
      "Epoch [58/100], Step [2700/4091], Loss: 462.4218\n",
      "Epoch [58/100], Step [2800/4091], Loss: 629.4841\n",
      "Epoch [58/100], Step [2900/4091], Loss: 782.9484\n",
      "Epoch [58/100], Step [3000/4091], Loss: 906.2756\n",
      "Epoch [58/100], Step [3100/4091], Loss: 783.7605\n",
      "Epoch [58/100], Step [3200/4091], Loss: 471.6383\n",
      "Epoch [58/100], Step [3300/4091], Loss: 700.0953\n",
      "Epoch [58/100], Step [3400/4091], Loss: 713.8470\n",
      "Epoch [58/100], Step [3500/4091], Loss: 719.1764\n",
      "Epoch [58/100], Step [3600/4091], Loss: 507.3418\n",
      "Epoch [58/100], Step [3700/4091], Loss: 493.4067\n",
      "Epoch [58/100], Step [3800/4091], Loss: 519.6327\n",
      "Epoch [58/100], Step [3900/4091], Loss: 737.5940\n",
      "Epoch [58/100], Step [4000/4091], Loss: 737.4608\n",
      "Epoch [59/100], Step [100/4091], Loss: 741.8455\n",
      "Epoch [59/100], Step [200/4091], Loss: 753.3857\n",
      "Epoch [59/100], Step [300/4091], Loss: 610.4023\n",
      "Epoch [59/100], Step [400/4091], Loss: 744.0872\n",
      "Epoch [59/100], Step [500/4091], Loss: 778.7939\n",
      "Epoch [59/100], Step [600/4091], Loss: 903.8001\n",
      "Epoch [59/100], Step [700/4091], Loss: 842.1699\n",
      "Epoch [59/100], Step [800/4091], Loss: 753.7878\n",
      "Epoch [59/100], Step [900/4091], Loss: 651.3906\n",
      "Epoch [59/100], Step [1000/4091], Loss: 653.8840\n",
      "Epoch [59/100], Step [1100/4091], Loss: 964.3958\n",
      "Epoch [59/100], Step [1200/4091], Loss: 585.7885\n",
      "Epoch [59/100], Step [1300/4091], Loss: 506.1260\n",
      "Epoch [59/100], Step [1400/4091], Loss: 617.6080\n",
      "Epoch [59/100], Step [1500/4091], Loss: 760.7700\n",
      "Epoch [59/100], Step [1600/4091], Loss: 666.3414\n",
      "Epoch [59/100], Step [1700/4091], Loss: 696.1563\n",
      "Epoch [59/100], Step [1800/4091], Loss: 487.9242\n",
      "Epoch [59/100], Step [1900/4091], Loss: 711.7175\n",
      "Epoch [59/100], Step [2000/4091], Loss: 765.8094\n",
      "Epoch [59/100], Step [2100/4091], Loss: 513.9186\n",
      "Epoch [59/100], Step [2200/4091], Loss: 839.6118\n",
      "Epoch [59/100], Step [2300/4091], Loss: 908.8156\n",
      "Epoch [59/100], Step [2400/4091], Loss: 621.6481\n",
      "Epoch [59/100], Step [2500/4091], Loss: 740.8347\n",
      "Epoch [59/100], Step [2600/4091], Loss: 473.1556\n",
      "Epoch [59/100], Step [2700/4091], Loss: 725.5674\n",
      "Epoch [59/100], Step [2800/4091], Loss: 918.0873\n",
      "Epoch [59/100], Step [2900/4091], Loss: 839.1659\n",
      "Epoch [59/100], Step [3000/4091], Loss: 768.4827\n",
      "Epoch [59/100], Step [3100/4091], Loss: 667.2191\n",
      "Epoch [59/100], Step [3200/4091], Loss: 880.2974\n",
      "Epoch [59/100], Step [3300/4091], Loss: 964.2157\n",
      "Epoch [59/100], Step [3400/4091], Loss: 536.8213\n",
      "Epoch [59/100], Step [3500/4091], Loss: 747.1835\n",
      "Epoch [59/100], Step [3600/4091], Loss: 486.9768\n",
      "Epoch [59/100], Step [3700/4091], Loss: 722.4531\n",
      "Epoch [59/100], Step [3800/4091], Loss: 652.4921\n",
      "Epoch [59/100], Step [3900/4091], Loss: 538.9646\n",
      "Epoch [59/100], Step [4000/4091], Loss: 562.2083\n",
      "Epoch [60/100], Step [100/4091], Loss: 438.6951\n",
      "Epoch [60/100], Step [200/4091], Loss: 814.7173\n",
      "Epoch [60/100], Step [300/4091], Loss: 866.6523\n",
      "Epoch [60/100], Step [400/4091], Loss: 796.5916\n",
      "Epoch [60/100], Step [500/4091], Loss: 550.6469\n",
      "Epoch [60/100], Step [600/4091], Loss: 948.4070\n",
      "Epoch [60/100], Step [700/4091], Loss: 663.4222\n",
      "Epoch [60/100], Step [800/4091], Loss: 711.2125\n",
      "Epoch [60/100], Step [900/4091], Loss: 662.5674\n",
      "Epoch [60/100], Step [1000/4091], Loss: 460.3931\n",
      "Epoch [60/100], Step [1100/4091], Loss: 663.1534\n",
      "Epoch [60/100], Step [1200/4091], Loss: 560.2122\n",
      "Epoch [60/100], Step [1300/4091], Loss: 518.8387\n",
      "Epoch [60/100], Step [1400/4091], Loss: 803.6531\n",
      "Epoch [60/100], Step [1500/4091], Loss: 645.8076\n",
      "Epoch [60/100], Step [1600/4091], Loss: 584.9579\n",
      "Epoch [60/100], Step [1700/4091], Loss: 876.9244\n",
      "Epoch [60/100], Step [1800/4091], Loss: 854.4406\n",
      "Epoch [60/100], Step [1900/4091], Loss: 641.3557\n",
      "Epoch [60/100], Step [2000/4091], Loss: 751.9884\n",
      "Epoch [60/100], Step [2100/4091], Loss: 540.1819\n",
      "Epoch [60/100], Step [2200/4091], Loss: 783.1330\n",
      "Epoch [60/100], Step [2300/4091], Loss: 679.3315\n",
      "Epoch [60/100], Step [2400/4091], Loss: 589.1885\n",
      "Epoch [60/100], Step [2500/4091], Loss: 477.0282\n",
      "Epoch [60/100], Step [2600/4091], Loss: 984.8389\n",
      "Epoch [60/100], Step [2700/4091], Loss: 536.4160\n",
      "Epoch [60/100], Step [2800/4091], Loss: 672.1719\n",
      "Epoch [60/100], Step [2900/4091], Loss: 936.2810\n",
      "Epoch [60/100], Step [3000/4091], Loss: 467.6745\n",
      "Epoch [60/100], Step [3100/4091], Loss: 658.2803\n",
      "Epoch [60/100], Step [3200/4091], Loss: 764.0554\n",
      "Epoch [60/100], Step [3300/4091], Loss: 637.9139\n",
      "Epoch [60/100], Step [3400/4091], Loss: 783.4085\n",
      "Epoch [60/100], Step [3500/4091], Loss: 602.5846\n",
      "Epoch [60/100], Step [3600/4091], Loss: 742.3633\n",
      "Epoch [60/100], Step [3700/4091], Loss: 569.2870\n",
      "Epoch [60/100], Step [3800/4091], Loss: 504.5815\n",
      "Epoch [60/100], Step [3900/4091], Loss: 758.5601\n",
      "Epoch [60/100], Step [4000/4091], Loss: 749.9404\n",
      "Epoch [61/100], Step [100/4091], Loss: 647.7930\n",
      "Epoch [61/100], Step [200/4091], Loss: 406.7067\n",
      "Epoch [61/100], Step [300/4091], Loss: 708.9314\n",
      "Epoch [61/100], Step [400/4091], Loss: 941.9351\n",
      "Epoch [61/100], Step [500/4091], Loss: 621.2564\n",
      "Epoch [61/100], Step [600/4091], Loss: 576.2407\n",
      "Epoch [61/100], Step [700/4091], Loss: 555.8237\n",
      "Epoch [61/100], Step [800/4091], Loss: 643.0737\n",
      "Epoch [61/100], Step [900/4091], Loss: 547.1284\n",
      "Epoch [61/100], Step [1000/4091], Loss: 764.0681\n",
      "Epoch [61/100], Step [1100/4091], Loss: 761.3705\n",
      "Epoch [61/100], Step [1200/4091], Loss: 489.7021\n",
      "Epoch [61/100], Step [1300/4091], Loss: 823.4776\n",
      "Epoch [61/100], Step [1400/4091], Loss: 626.0049\n",
      "Epoch [61/100], Step [1500/4091], Loss: 706.9100\n",
      "Epoch [61/100], Step [1600/4091], Loss: 740.8495\n",
      "Epoch [61/100], Step [1700/4091], Loss: 761.3459\n",
      "Epoch [61/100], Step [1800/4091], Loss: 909.8875\n",
      "Epoch [61/100], Step [1900/4091], Loss: 620.8225\n",
      "Epoch [61/100], Step [2000/4091], Loss: 567.5709\n",
      "Epoch [61/100], Step [2100/4091], Loss: 504.8408\n",
      "Epoch [61/100], Step [2200/4091], Loss: 671.6774\n",
      "Epoch [61/100], Step [2300/4091], Loss: 886.7162\n",
      "Epoch [61/100], Step [2400/4091], Loss: 652.6082\n",
      "Epoch [61/100], Step [2500/4091], Loss: 648.6738\n",
      "Epoch [61/100], Step [2600/4091], Loss: 845.8342\n",
      "Epoch [61/100], Step [2700/4091], Loss: 698.6211\n",
      "Epoch [61/100], Step [2800/4091], Loss: 816.3152\n",
      "Epoch [61/100], Step [2900/4091], Loss: 511.4656\n",
      "Epoch [61/100], Step [3000/4091], Loss: 570.5569\n",
      "Epoch [61/100], Step [3100/4091], Loss: 685.7438\n",
      "Epoch [61/100], Step [3200/4091], Loss: 574.6086\n",
      "Epoch [61/100], Step [3300/4091], Loss: 478.5821\n",
      "Epoch [61/100], Step [3400/4091], Loss: 813.8599\n",
      "Epoch [61/100], Step [3500/4091], Loss: 559.4215\n",
      "Epoch [61/100], Step [3600/4091], Loss: 635.9009\n",
      "Epoch [61/100], Step [3700/4091], Loss: 490.1072\n",
      "Epoch [61/100], Step [3800/4091], Loss: 625.0621\n",
      "Epoch [61/100], Step [3900/4091], Loss: 658.0265\n",
      "Epoch [61/100], Step [4000/4091], Loss: 595.1678\n",
      "Epoch [62/100], Step [100/4091], Loss: 672.1879\n",
      "Epoch [62/100], Step [200/4091], Loss: 578.1415\n",
      "Epoch [62/100], Step [300/4091], Loss: 573.2911\n",
      "Epoch [62/100], Step [400/4091], Loss: 414.1259\n",
      "Epoch [62/100], Step [500/4091], Loss: 701.1613\n",
      "Epoch [62/100], Step [600/4091], Loss: 762.5127\n",
      "Epoch [62/100], Step [700/4091], Loss: 704.9175\n",
      "Epoch [62/100], Step [800/4091], Loss: 541.7022\n",
      "Epoch [62/100], Step [900/4091], Loss: 542.2415\n",
      "Epoch [62/100], Step [1000/4091], Loss: 648.8286\n",
      "Epoch [62/100], Step [1100/4091], Loss: 463.0837\n",
      "Epoch [62/100], Step [1200/4091], Loss: 875.4422\n",
      "Epoch [62/100], Step [1300/4091], Loss: 623.9641\n",
      "Epoch [62/100], Step [1400/4091], Loss: 595.9497\n",
      "Epoch [62/100], Step [1500/4091], Loss: 661.1102\n",
      "Epoch [62/100], Step [1600/4091], Loss: 742.1394\n",
      "Epoch [62/100], Step [1700/4091], Loss: 545.1437\n",
      "Epoch [62/100], Step [1800/4091], Loss: 751.2427\n",
      "Epoch [62/100], Step [1900/4091], Loss: 436.2102\n",
      "Epoch [62/100], Step [2000/4091], Loss: 667.1465\n",
      "Epoch [62/100], Step [2100/4091], Loss: 835.4841\n",
      "Epoch [62/100], Step [2200/4091], Loss: 530.5889\n",
      "Epoch [62/100], Step [2300/4091], Loss: 590.1324\n",
      "Epoch [62/100], Step [2400/4091], Loss: 778.7902\n",
      "Epoch [62/100], Step [2500/4091], Loss: 606.2626\n",
      "Epoch [62/100], Step [2600/4091], Loss: 524.1260\n",
      "Epoch [62/100], Step [2700/4091], Loss: 713.8406\n",
      "Epoch [62/100], Step [2800/4091], Loss: 590.3458\n",
      "Epoch [62/100], Step [2900/4091], Loss: 733.4841\n",
      "Epoch [62/100], Step [3000/4091], Loss: 526.9881\n",
      "Epoch [62/100], Step [3100/4091], Loss: 661.4946\n",
      "Epoch [62/100], Step [3200/4091], Loss: 766.5816\n",
      "Epoch [62/100], Step [3300/4091], Loss: 675.4550\n",
      "Epoch [62/100], Step [3400/4091], Loss: 596.3290\n",
      "Epoch [62/100], Step [3500/4091], Loss: 608.1534\n",
      "Epoch [62/100], Step [3600/4091], Loss: 1048.2539\n",
      "Epoch [62/100], Step [3700/4091], Loss: 492.5328\n",
      "Epoch [62/100], Step [3800/4091], Loss: 626.5259\n",
      "Epoch [62/100], Step [3900/4091], Loss: 563.3930\n",
      "Epoch [62/100], Step [4000/4091], Loss: 902.5682\n",
      "Epoch [63/100], Step [100/4091], Loss: 695.4904\n",
      "Epoch [63/100], Step [200/4091], Loss: 672.1680\n",
      "Epoch [63/100], Step [300/4091], Loss: 495.3675\n",
      "Epoch [63/100], Step [400/4091], Loss: 802.1279\n",
      "Epoch [63/100], Step [500/4091], Loss: 620.3452\n",
      "Epoch [63/100], Step [600/4091], Loss: 696.0210\n",
      "Epoch [63/100], Step [700/4091], Loss: 985.1231\n",
      "Epoch [63/100], Step [800/4091], Loss: 735.3756\n",
      "Epoch [63/100], Step [900/4091], Loss: 549.2668\n",
      "Epoch [63/100], Step [1000/4091], Loss: 609.7756\n",
      "Epoch [63/100], Step [1100/4091], Loss: 658.3153\n",
      "Epoch [63/100], Step [1200/4091], Loss: 573.3105\n",
      "Epoch [63/100], Step [1300/4091], Loss: 855.1968\n",
      "Epoch [63/100], Step [1400/4091], Loss: 638.0599\n",
      "Epoch [63/100], Step [1500/4091], Loss: 392.2946\n",
      "Epoch [63/100], Step [1600/4091], Loss: 754.5327\n",
      "Epoch [63/100], Step [1700/4091], Loss: 850.6223\n",
      "Epoch [63/100], Step [1800/4091], Loss: 773.8423\n",
      "Epoch [63/100], Step [1900/4091], Loss: 854.3368\n",
      "Epoch [63/100], Step [2000/4091], Loss: 538.1435\n",
      "Epoch [63/100], Step [2100/4091], Loss: 493.7327\n",
      "Epoch [63/100], Step [2200/4091], Loss: 582.7386\n",
      "Epoch [63/100], Step [2300/4091], Loss: 703.0839\n",
      "Epoch [63/100], Step [2400/4091], Loss: 708.4727\n",
      "Epoch [63/100], Step [2500/4091], Loss: 642.4564\n",
      "Epoch [63/100], Step [2600/4091], Loss: 749.2232\n",
      "Epoch [63/100], Step [2700/4091], Loss: 623.7122\n",
      "Epoch [63/100], Step [2800/4091], Loss: 815.3897\n",
      "Epoch [63/100], Step [2900/4091], Loss: 706.3840\n",
      "Epoch [63/100], Step [3000/4091], Loss: 736.5969\n",
      "Epoch [63/100], Step [3100/4091], Loss: 725.2263\n",
      "Epoch [63/100], Step [3200/4091], Loss: 642.7424\n",
      "Epoch [63/100], Step [3300/4091], Loss: 876.0331\n",
      "Epoch [63/100], Step [3400/4091], Loss: 758.8864\n",
      "Epoch [63/100], Step [3500/4091], Loss: 689.9314\n",
      "Epoch [63/100], Step [3600/4091], Loss: 796.0024\n",
      "Epoch [63/100], Step [3700/4091], Loss: 734.9951\n",
      "Epoch [63/100], Step [3800/4091], Loss: 834.1801\n",
      "Epoch [63/100], Step [3900/4091], Loss: 619.6558\n",
      "Epoch [63/100], Step [4000/4091], Loss: 639.1119\n",
      "Epoch [64/100], Step [100/4091], Loss: 655.2765\n",
      "Epoch [64/100], Step [200/4091], Loss: 774.6333\n",
      "Epoch [64/100], Step [300/4091], Loss: 584.2330\n",
      "Epoch [64/100], Step [400/4091], Loss: 631.6212\n",
      "Epoch [64/100], Step [500/4091], Loss: 884.8963\n",
      "Epoch [64/100], Step [600/4091], Loss: 521.4144\n",
      "Epoch [64/100], Step [700/4091], Loss: 675.2058\n",
      "Epoch [64/100], Step [800/4091], Loss: 603.6412\n",
      "Epoch [64/100], Step [900/4091], Loss: 623.2442\n",
      "Epoch [64/100], Step [1000/4091], Loss: 588.3068\n",
      "Epoch [64/100], Step [1100/4091], Loss: 480.1960\n",
      "Epoch [64/100], Step [1200/4091], Loss: 730.2274\n",
      "Epoch [64/100], Step [1300/4091], Loss: 834.8456\n",
      "Epoch [64/100], Step [1400/4091], Loss: 507.4902\n",
      "Epoch [64/100], Step [1500/4091], Loss: 660.7169\n",
      "Epoch [64/100], Step [1600/4091], Loss: 879.5339\n",
      "Epoch [64/100], Step [1700/4091], Loss: 891.5452\n",
      "Epoch [64/100], Step [1800/4091], Loss: 851.4789\n",
      "Epoch [64/100], Step [1900/4091], Loss: 787.1343\n",
      "Epoch [64/100], Step [2000/4091], Loss: 746.0979\n",
      "Epoch [64/100], Step [2100/4091], Loss: 902.2122\n",
      "Epoch [64/100], Step [2200/4091], Loss: 781.9417\n",
      "Epoch [64/100], Step [2300/4091], Loss: 652.9401\n",
      "Epoch [64/100], Step [2400/4091], Loss: 639.3911\n",
      "Epoch [64/100], Step [2500/4091], Loss: 634.0924\n",
      "Epoch [64/100], Step [2600/4091], Loss: 691.6521\n",
      "Epoch [64/100], Step [2700/4091], Loss: 702.0040\n",
      "Epoch [64/100], Step [2800/4091], Loss: 628.9597\n",
      "Epoch [64/100], Step [2900/4091], Loss: 769.3254\n",
      "Epoch [64/100], Step [3000/4091], Loss: 571.8460\n",
      "Epoch [64/100], Step [3100/4091], Loss: 587.6578\n",
      "Epoch [64/100], Step [3200/4091], Loss: 484.7545\n",
      "Epoch [64/100], Step [3300/4091], Loss: 720.4542\n",
      "Epoch [64/100], Step [3400/4091], Loss: 721.8869\n",
      "Epoch [64/100], Step [3500/4091], Loss: 935.8257\n",
      "Epoch [64/100], Step [3600/4091], Loss: 501.8054\n",
      "Epoch [64/100], Step [3700/4091], Loss: 692.2162\n",
      "Epoch [64/100], Step [3800/4091], Loss: 727.3940\n",
      "Epoch [64/100], Step [3900/4091], Loss: 1044.9717\n",
      "Epoch [64/100], Step [4000/4091], Loss: 720.1999\n",
      "Epoch [65/100], Step [100/4091], Loss: 749.2532\n",
      "Epoch [65/100], Step [200/4091], Loss: 774.2961\n",
      "Epoch [65/100], Step [300/4091], Loss: 618.0341\n",
      "Epoch [65/100], Step [400/4091], Loss: 769.6409\n",
      "Epoch [65/100], Step [500/4091], Loss: 607.0897\n",
      "Epoch [65/100], Step [600/4091], Loss: 713.3508\n",
      "Epoch [65/100], Step [700/4091], Loss: 845.5001\n",
      "Epoch [65/100], Step [800/4091], Loss: 598.2161\n",
      "Epoch [65/100], Step [900/4091], Loss: 601.6199\n",
      "Epoch [65/100], Step [1000/4091], Loss: 820.2385\n",
      "Epoch [65/100], Step [1100/4091], Loss: 687.7236\n",
      "Epoch [65/100], Step [1200/4091], Loss: 765.5888\n",
      "Epoch [65/100], Step [1300/4091], Loss: 463.7342\n",
      "Epoch [65/100], Step [1400/4091], Loss: 618.6150\n",
      "Epoch [65/100], Step [1500/4091], Loss: 506.4412\n",
      "Epoch [65/100], Step [1600/4091], Loss: 765.9713\n",
      "Epoch [65/100], Step [1700/4091], Loss: 667.1063\n",
      "Epoch [65/100], Step [1800/4091], Loss: 514.5693\n",
      "Epoch [65/100], Step [1900/4091], Loss: 618.1026\n",
      "Epoch [65/100], Step [2000/4091], Loss: 680.5037\n",
      "Epoch [65/100], Step [2100/4091], Loss: 683.1815\n",
      "Epoch [65/100], Step [2200/4091], Loss: 570.0618\n",
      "Epoch [65/100], Step [2300/4091], Loss: 622.1419\n",
      "Epoch [65/100], Step [2400/4091], Loss: 531.6119\n",
      "Epoch [65/100], Step [2500/4091], Loss: 568.4118\n",
      "Epoch [65/100], Step [2600/4091], Loss: 571.2908\n",
      "Epoch [65/100], Step [2700/4091], Loss: 591.1288\n",
      "Epoch [65/100], Step [2800/4091], Loss: 664.0541\n",
      "Epoch [65/100], Step [2900/4091], Loss: 637.4791\n",
      "Epoch [65/100], Step [3000/4091], Loss: 678.3295\n",
      "Epoch [65/100], Step [3100/4091], Loss: 685.1203\n",
      "Epoch [65/100], Step [3200/4091], Loss: 1033.1305\n",
      "Epoch [65/100], Step [3300/4091], Loss: 802.8884\n",
      "Epoch [65/100], Step [3400/4091], Loss: 510.4669\n",
      "Epoch [65/100], Step [3500/4091], Loss: 491.0234\n",
      "Epoch [65/100], Step [3600/4091], Loss: 787.4309\n",
      "Epoch [65/100], Step [3700/4091], Loss: 679.0176\n",
      "Epoch [65/100], Step [3800/4091], Loss: 628.9252\n",
      "Epoch [65/100], Step [3900/4091], Loss: 679.9068\n",
      "Epoch [65/100], Step [4000/4091], Loss: 560.2602\n",
      "Epoch [66/100], Step [100/4091], Loss: 715.9884\n",
      "Epoch [66/100], Step [200/4091], Loss: 741.5953\n",
      "Epoch [66/100], Step [300/4091], Loss: 673.9604\n",
      "Epoch [66/100], Step [400/4091], Loss: 644.1172\n",
      "Epoch [66/100], Step [500/4091], Loss: 584.8481\n",
      "Epoch [66/100], Step [600/4091], Loss: 747.9767\n",
      "Epoch [66/100], Step [700/4091], Loss: 663.2713\n",
      "Epoch [66/100], Step [800/4091], Loss: 464.3899\n",
      "Epoch [66/100], Step [900/4091], Loss: 703.5259\n",
      "Epoch [66/100], Step [1000/4091], Loss: 554.5769\n",
      "Epoch [66/100], Step [1100/4091], Loss: 677.1429\n",
      "Epoch [66/100], Step [1200/4091], Loss: 584.1185\n",
      "Epoch [66/100], Step [1300/4091], Loss: 562.2482\n",
      "Epoch [66/100], Step [1400/4091], Loss: 540.5531\n",
      "Epoch [66/100], Step [1500/4091], Loss: 555.3300\n",
      "Epoch [66/100], Step [1600/4091], Loss: 810.9309\n",
      "Epoch [66/100], Step [1700/4091], Loss: 781.4249\n",
      "Epoch [66/100], Step [1800/4091], Loss: 662.4209\n",
      "Epoch [66/100], Step [1900/4091], Loss: 569.6694\n",
      "Epoch [66/100], Step [2000/4091], Loss: 697.1454\n",
      "Epoch [66/100], Step [2100/4091], Loss: 770.8279\n",
      "Epoch [66/100], Step [2200/4091], Loss: 609.8340\n",
      "Epoch [66/100], Step [2300/4091], Loss: 764.3461\n",
      "Epoch [66/100], Step [2400/4091], Loss: 641.6146\n",
      "Epoch [66/100], Step [2500/4091], Loss: 816.2529\n",
      "Epoch [66/100], Step [2600/4091], Loss: 650.8762\n",
      "Epoch [66/100], Step [2700/4091], Loss: 669.4386\n",
      "Epoch [66/100], Step [2800/4091], Loss: 662.9773\n",
      "Epoch [66/100], Step [2900/4091], Loss: 803.6712\n",
      "Epoch [66/100], Step [3000/4091], Loss: 680.5884\n",
      "Epoch [66/100], Step [3100/4091], Loss: 662.7164\n",
      "Epoch [66/100], Step [3200/4091], Loss: 509.1049\n",
      "Epoch [66/100], Step [3300/4091], Loss: 453.9853\n",
      "Epoch [66/100], Step [3400/4091], Loss: 458.0469\n",
      "Epoch [66/100], Step [3500/4091], Loss: 668.5447\n",
      "Epoch [66/100], Step [3600/4091], Loss: 678.3303\n",
      "Epoch [66/100], Step [3700/4091], Loss: 609.8963\n",
      "Epoch [66/100], Step [3800/4091], Loss: 416.0400\n",
      "Epoch [66/100], Step [3900/4091], Loss: 857.4794\n",
      "Epoch [66/100], Step [4000/4091], Loss: 1039.6484\n",
      "Epoch [67/100], Step [100/4091], Loss: 712.7797\n",
      "Epoch [67/100], Step [200/4091], Loss: 630.0383\n",
      "Epoch [67/100], Step [300/4091], Loss: 794.8945\n",
      "Epoch [67/100], Step [400/4091], Loss: 477.9092\n",
      "Epoch [67/100], Step [500/4091], Loss: 645.0338\n",
      "Epoch [67/100], Step [600/4091], Loss: 639.7041\n",
      "Epoch [67/100], Step [700/4091], Loss: 531.2620\n",
      "Epoch [67/100], Step [800/4091], Loss: 556.7898\n",
      "Epoch [67/100], Step [900/4091], Loss: 667.6650\n",
      "Epoch [67/100], Step [1000/4091], Loss: 739.6420\n",
      "Epoch [67/100], Step [1100/4091], Loss: 997.0093\n",
      "Epoch [67/100], Step [1200/4091], Loss: 874.6129\n",
      "Epoch [67/100], Step [1300/4091], Loss: 647.7357\n",
      "Epoch [67/100], Step [1400/4091], Loss: 764.0428\n",
      "Epoch [67/100], Step [1500/4091], Loss: 563.2716\n",
      "Epoch [67/100], Step [1600/4091], Loss: 626.0541\n",
      "Epoch [67/100], Step [1700/4091], Loss: 888.0486\n",
      "Epoch [67/100], Step [1800/4091], Loss: 759.3410\n",
      "Epoch [67/100], Step [1900/4091], Loss: 686.2271\n",
      "Epoch [67/100], Step [2000/4091], Loss: 600.5262\n",
      "Epoch [67/100], Step [2100/4091], Loss: 833.6663\n",
      "Epoch [67/100], Step [2200/4091], Loss: 491.9463\n",
      "Epoch [67/100], Step [2300/4091], Loss: 762.9705\n",
      "Epoch [67/100], Step [2400/4091], Loss: 512.0821\n",
      "Epoch [67/100], Step [2500/4091], Loss: 576.2112\n",
      "Epoch [67/100], Step [2600/4091], Loss: 671.5146\n",
      "Epoch [67/100], Step [2700/4091], Loss: 613.0131\n",
      "Epoch [67/100], Step [2800/4091], Loss: 784.1953\n",
      "Epoch [67/100], Step [2900/4091], Loss: 665.5594\n",
      "Epoch [67/100], Step [3000/4091], Loss: 879.2305\n",
      "Epoch [67/100], Step [3100/4091], Loss: 773.7175\n",
      "Epoch [67/100], Step [3200/4091], Loss: 780.0099\n",
      "Epoch [67/100], Step [3300/4091], Loss: 512.7468\n",
      "Epoch [67/100], Step [3400/4091], Loss: 671.3520\n",
      "Epoch [67/100], Step [3500/4091], Loss: 583.5523\n",
      "Epoch [67/100], Step [3600/4091], Loss: 680.5984\n",
      "Epoch [67/100], Step [3700/4091], Loss: 586.0723\n",
      "Epoch [67/100], Step [3800/4091], Loss: 697.1495\n",
      "Epoch [67/100], Step [3900/4091], Loss: 537.9229\n",
      "Epoch [67/100], Step [4000/4091], Loss: 655.1257\n",
      "Epoch [68/100], Step [100/4091], Loss: 883.8519\n",
      "Epoch [68/100], Step [200/4091], Loss: 686.2457\n",
      "Epoch [68/100], Step [300/4091], Loss: 631.1651\n",
      "Epoch [68/100], Step [400/4091], Loss: 763.3770\n",
      "Epoch [68/100], Step [500/4091], Loss: 736.9133\n",
      "Epoch [68/100], Step [600/4091], Loss: 609.5926\n",
      "Epoch [68/100], Step [700/4091], Loss: 599.8131\n",
      "Epoch [68/100], Step [800/4091], Loss: 918.4736\n",
      "Epoch [68/100], Step [900/4091], Loss: 763.1396\n",
      "Epoch [68/100], Step [1000/4091], Loss: 533.5532\n",
      "Epoch [68/100], Step [1100/4091], Loss: 450.7329\n",
      "Epoch [68/100], Step [1200/4091], Loss: 790.7671\n",
      "Epoch [68/100], Step [1300/4091], Loss: 562.2576\n",
      "Epoch [68/100], Step [1400/4091], Loss: 489.3859\n",
      "Epoch [68/100], Step [1500/4091], Loss: 824.7491\n",
      "Epoch [68/100], Step [1600/4091], Loss: 797.9169\n",
      "Epoch [68/100], Step [1700/4091], Loss: 795.4924\n",
      "Epoch [68/100], Step [1800/4091], Loss: 648.9714\n",
      "Epoch [68/100], Step [1900/4091], Loss: 681.4151\n",
      "Epoch [68/100], Step [2000/4091], Loss: 735.6177\n",
      "Epoch [68/100], Step [2100/4091], Loss: 746.8868\n",
      "Epoch [68/100], Step [2200/4091], Loss: 639.3854\n",
      "Epoch [68/100], Step [2300/4091], Loss: 791.0972\n",
      "Epoch [68/100], Step [2400/4091], Loss: 602.2379\n",
      "Epoch [68/100], Step [2500/4091], Loss: 511.2683\n",
      "Epoch [68/100], Step [2600/4091], Loss: 756.3351\n",
      "Epoch [68/100], Step [2700/4091], Loss: 686.5163\n",
      "Epoch [68/100], Step [2800/4091], Loss: 855.6127\n",
      "Epoch [68/100], Step [2900/4091], Loss: 922.6663\n",
      "Epoch [68/100], Step [3000/4091], Loss: 562.2109\n",
      "Epoch [68/100], Step [3100/4091], Loss: 931.3021\n",
      "Epoch [68/100], Step [3200/4091], Loss: 714.4907\n",
      "Epoch [68/100], Step [3300/4091], Loss: 613.9526\n",
      "Epoch [68/100], Step [3400/4091], Loss: 470.8492\n",
      "Epoch [68/100], Step [3500/4091], Loss: 663.6763\n",
      "Epoch [68/100], Step [3600/4091], Loss: 678.7243\n",
      "Epoch [68/100], Step [3700/4091], Loss: 784.6534\n",
      "Epoch [68/100], Step [3800/4091], Loss: 675.8138\n",
      "Epoch [68/100], Step [3900/4091], Loss: 739.0082\n",
      "Epoch [68/100], Step [4000/4091], Loss: 583.7129\n",
      "Epoch [69/100], Step [100/4091], Loss: 862.0693\n",
      "Epoch [69/100], Step [200/4091], Loss: 469.4975\n",
      "Epoch [69/100], Step [300/4091], Loss: 670.3363\n",
      "Epoch [69/100], Step [400/4091], Loss: 517.8472\n",
      "Epoch [69/100], Step [500/4091], Loss: 633.9872\n",
      "Epoch [69/100], Step [600/4091], Loss: 767.5902\n",
      "Epoch [69/100], Step [700/4091], Loss: 500.7168\n",
      "Epoch [69/100], Step [800/4091], Loss: 453.5237\n",
      "Epoch [69/100], Step [900/4091], Loss: 714.4481\n",
      "Epoch [69/100], Step [1000/4091], Loss: 910.8834\n",
      "Epoch [69/100], Step [1100/4091], Loss: 601.6385\n",
      "Epoch [69/100], Step [1200/4091], Loss: 905.2153\n",
      "Epoch [69/100], Step [1300/4091], Loss: 607.5359\n",
      "Epoch [69/100], Step [1400/4091], Loss: 678.0479\n",
      "Epoch [69/100], Step [1500/4091], Loss: 740.8132\n",
      "Epoch [69/100], Step [1600/4091], Loss: 760.8800\n",
      "Epoch [69/100], Step [1700/4091], Loss: 647.7234\n",
      "Epoch [69/100], Step [1800/4091], Loss: 477.2614\n",
      "Epoch [69/100], Step [1900/4091], Loss: 610.6027\n",
      "Epoch [69/100], Step [2000/4091], Loss: 790.9036\n",
      "Epoch [69/100], Step [2100/4091], Loss: 652.4628\n",
      "Epoch [69/100], Step [2200/4091], Loss: 617.1789\n",
      "Epoch [69/100], Step [2300/4091], Loss: 802.4974\n",
      "Epoch [69/100], Step [2400/4091], Loss: 604.7350\n",
      "Epoch [69/100], Step [2500/4091], Loss: 746.8392\n",
      "Epoch [69/100], Step [2600/4091], Loss: 949.4911\n",
      "Epoch [69/100], Step [2700/4091], Loss: 639.7234\n",
      "Epoch [69/100], Step [2800/4091], Loss: 939.0540\n",
      "Epoch [69/100], Step [2900/4091], Loss: 685.9227\n",
      "Epoch [69/100], Step [3000/4091], Loss: 691.8993\n",
      "Epoch [69/100], Step [3100/4091], Loss: 632.6070\n",
      "Epoch [69/100], Step [3200/4091], Loss: 623.6380\n",
      "Epoch [69/100], Step [3300/4091], Loss: 648.3001\n",
      "Epoch [69/100], Step [3400/4091], Loss: 515.0051\n",
      "Epoch [69/100], Step [3500/4091], Loss: 665.8286\n",
      "Epoch [69/100], Step [3600/4091], Loss: 707.5957\n",
      "Epoch [69/100], Step [3700/4091], Loss: 608.9502\n",
      "Epoch [69/100], Step [3800/4091], Loss: 754.8737\n",
      "Epoch [69/100], Step [3900/4091], Loss: 781.4258\n",
      "Epoch [69/100], Step [4000/4091], Loss: 588.1190\n",
      "Epoch [70/100], Step [100/4091], Loss: 498.9577\n",
      "Epoch [70/100], Step [200/4091], Loss: 692.0870\n",
      "Epoch [70/100], Step [300/4091], Loss: 637.4207\n",
      "Epoch [70/100], Step [400/4091], Loss: 829.2798\n",
      "Epoch [70/100], Step [500/4091], Loss: 706.1398\n",
      "Epoch [70/100], Step [600/4091], Loss: 538.1146\n",
      "Epoch [70/100], Step [700/4091], Loss: 522.3089\n",
      "Epoch [70/100], Step [800/4091], Loss: 533.1047\n",
      "Epoch [70/100], Step [900/4091], Loss: 653.7299\n",
      "Epoch [70/100], Step [1000/4091], Loss: 626.8325\n",
      "Epoch [70/100], Step [1100/4091], Loss: 759.1836\n",
      "Epoch [70/100], Step [1200/4091], Loss: 706.0786\n",
      "Epoch [70/100], Step [1300/4091], Loss: 757.4023\n",
      "Epoch [70/100], Step [1400/4091], Loss: 685.6107\n",
      "Epoch [70/100], Step [1500/4091], Loss: 671.7918\n",
      "Epoch [70/100], Step [1600/4091], Loss: 523.8167\n",
      "Epoch [70/100], Step [1700/4091], Loss: 746.3391\n",
      "Epoch [70/100], Step [1800/4091], Loss: 801.7752\n",
      "Epoch [70/100], Step [1900/4091], Loss: 593.7777\n",
      "Epoch [70/100], Step [2000/4091], Loss: 730.8792\n",
      "Epoch [70/100], Step [2100/4091], Loss: 657.6439\n",
      "Epoch [70/100], Step [2200/4091], Loss: 579.6133\n",
      "Epoch [70/100], Step [2300/4091], Loss: 670.6415\n",
      "Epoch [70/100], Step [2400/4091], Loss: 459.7968\n",
      "Epoch [70/100], Step [2500/4091], Loss: 578.9226\n",
      "Epoch [70/100], Step [2600/4091], Loss: 690.2031\n",
      "Epoch [70/100], Step [2700/4091], Loss: 606.8444\n",
      "Epoch [70/100], Step [2800/4091], Loss: 673.6396\n",
      "Epoch [70/100], Step [2900/4091], Loss: 558.4846\n",
      "Epoch [70/100], Step [3000/4091], Loss: 623.6702\n",
      "Epoch [70/100], Step [3100/4091], Loss: 842.5294\n",
      "Epoch [70/100], Step [3200/4091], Loss: 512.9122\n",
      "Epoch [70/100], Step [3300/4091], Loss: 674.3813\n",
      "Epoch [70/100], Step [3400/4091], Loss: 726.1693\n",
      "Epoch [70/100], Step [3500/4091], Loss: 630.0698\n",
      "Epoch [70/100], Step [3600/4091], Loss: 634.4437\n",
      "Epoch [70/100], Step [3700/4091], Loss: 803.0826\n",
      "Epoch [70/100], Step [3800/4091], Loss: 642.6910\n",
      "Epoch [70/100], Step [3900/4091], Loss: 1028.6720\n",
      "Epoch [70/100], Step [4000/4091], Loss: 646.1246\n",
      "Epoch [71/100], Step [100/4091], Loss: 624.8939\n",
      "Epoch [71/100], Step [200/4091], Loss: 942.1044\n",
      "Epoch [71/100], Step [300/4091], Loss: 644.2047\n",
      "Epoch [71/100], Step [400/4091], Loss: 585.3456\n",
      "Epoch [71/100], Step [500/4091], Loss: 563.8970\n",
      "Epoch [71/100], Step [600/4091], Loss: 637.5834\n",
      "Epoch [71/100], Step [700/4091], Loss: 553.3503\n",
      "Epoch [71/100], Step [800/4091], Loss: 503.2448\n",
      "Epoch [71/100], Step [900/4091], Loss: 695.4365\n",
      "Epoch [71/100], Step [1000/4091], Loss: 586.6611\n",
      "Epoch [71/100], Step [1100/4091], Loss: 682.8405\n",
      "Epoch [71/100], Step [1200/4091], Loss: 545.7293\n",
      "Epoch [71/100], Step [1300/4091], Loss: 750.1557\n",
      "Epoch [71/100], Step [1400/4091], Loss: 1035.5530\n",
      "Epoch [71/100], Step [1500/4091], Loss: 796.5277\n",
      "Epoch [71/100], Step [1600/4091], Loss: 630.0102\n",
      "Epoch [71/100], Step [1700/4091], Loss: 583.4467\n",
      "Epoch [71/100], Step [1800/4091], Loss: 650.2048\n",
      "Epoch [71/100], Step [1900/4091], Loss: 592.7730\n",
      "Epoch [71/100], Step [2000/4091], Loss: 547.2065\n",
      "Epoch [71/100], Step [2100/4091], Loss: 580.8316\n",
      "Epoch [71/100], Step [2200/4091], Loss: 600.3782\n",
      "Epoch [71/100], Step [2300/4091], Loss: 564.1600\n",
      "Epoch [71/100], Step [2400/4091], Loss: 574.7543\n",
      "Epoch [71/100], Step [2500/4091], Loss: 681.3217\n",
      "Epoch [71/100], Step [2600/4091], Loss: 677.5999\n",
      "Epoch [71/100], Step [2700/4091], Loss: 547.4574\n",
      "Epoch [71/100], Step [2800/4091], Loss: 557.7192\n",
      "Epoch [71/100], Step [2900/4091], Loss: 813.8773\n",
      "Epoch [71/100], Step [3000/4091], Loss: 985.6480\n",
      "Epoch [71/100], Step [3100/4091], Loss: 758.9624\n",
      "Epoch [71/100], Step [3200/4091], Loss: 582.2212\n",
      "Epoch [71/100], Step [3300/4091], Loss: 761.0463\n",
      "Epoch [71/100], Step [3400/4091], Loss: 676.3405\n",
      "Epoch [71/100], Step [3500/4091], Loss: 788.4446\n",
      "Epoch [71/100], Step [3600/4091], Loss: 666.1830\n",
      "Epoch [71/100], Step [3700/4091], Loss: 699.7672\n",
      "Epoch [71/100], Step [3800/4091], Loss: 541.3384\n",
      "Epoch [71/100], Step [3900/4091], Loss: 679.4893\n",
      "Epoch [71/100], Step [4000/4091], Loss: 717.1484\n",
      "Epoch [72/100], Step [100/4091], Loss: 548.9918\n",
      "Epoch [72/100], Step [200/4091], Loss: 514.5591\n",
      "Epoch [72/100], Step [300/4091], Loss: 649.5660\n",
      "Epoch [72/100], Step [400/4091], Loss: 439.2368\n",
      "Epoch [72/100], Step [500/4091], Loss: 709.8542\n",
      "Epoch [72/100], Step [600/4091], Loss: 634.1143\n",
      "Epoch [72/100], Step [700/4091], Loss: 550.2827\n",
      "Epoch [72/100], Step [800/4091], Loss: 847.5535\n",
      "Epoch [72/100], Step [900/4091], Loss: 636.7856\n",
      "Epoch [72/100], Step [1000/4091], Loss: 552.3271\n",
      "Epoch [72/100], Step [1100/4091], Loss: 879.5331\n",
      "Epoch [72/100], Step [1200/4091], Loss: 783.1456\n",
      "Epoch [72/100], Step [1300/4091], Loss: 799.6155\n",
      "Epoch [72/100], Step [1400/4091], Loss: 757.2555\n",
      "Epoch [72/100], Step [1500/4091], Loss: 658.0922\n",
      "Epoch [72/100], Step [1600/4091], Loss: 701.0273\n",
      "Epoch [72/100], Step [1700/4091], Loss: 614.7224\n",
      "Epoch [72/100], Step [1800/4091], Loss: 590.8538\n",
      "Epoch [72/100], Step [1900/4091], Loss: 784.2083\n",
      "Epoch [72/100], Step [2000/4091], Loss: 576.1753\n",
      "Epoch [72/100], Step [2100/4091], Loss: 455.3869\n",
      "Epoch [72/100], Step [2200/4091], Loss: 510.9857\n",
      "Epoch [72/100], Step [2300/4091], Loss: 655.0629\n",
      "Epoch [72/100], Step [2400/4091], Loss: 846.1020\n",
      "Epoch [72/100], Step [2500/4091], Loss: 806.7339\n",
      "Epoch [72/100], Step [2600/4091], Loss: 628.8959\n",
      "Epoch [72/100], Step [2700/4091], Loss: 549.4633\n",
      "Epoch [72/100], Step [2800/4091], Loss: 519.4234\n",
      "Epoch [72/100], Step [2900/4091], Loss: 849.2036\n",
      "Epoch [72/100], Step [3000/4091], Loss: 674.5247\n",
      "Epoch [72/100], Step [3100/4091], Loss: 546.5904\n",
      "Epoch [72/100], Step [3200/4091], Loss: 748.1118\n",
      "Epoch [72/100], Step [3300/4091], Loss: 529.1362\n",
      "Epoch [72/100], Step [3400/4091], Loss: 619.1584\n",
      "Epoch [72/100], Step [3500/4091], Loss: 627.4949\n",
      "Epoch [72/100], Step [3600/4091], Loss: 682.8361\n",
      "Epoch [72/100], Step [3700/4091], Loss: 782.6993\n",
      "Epoch [72/100], Step [3800/4091], Loss: 583.3436\n",
      "Epoch [72/100], Step [3900/4091], Loss: 537.8537\n",
      "Epoch [72/100], Step [4000/4091], Loss: 487.2656\n",
      "Epoch [73/100], Step [100/4091], Loss: 715.9250\n",
      "Epoch [73/100], Step [200/4091], Loss: 700.0171\n",
      "Epoch [73/100], Step [300/4091], Loss: 672.1679\n",
      "Epoch [73/100], Step [400/4091], Loss: 590.9384\n",
      "Epoch [73/100], Step [500/4091], Loss: 640.2832\n",
      "Epoch [73/100], Step [600/4091], Loss: 377.1203\n",
      "Epoch [73/100], Step [700/4091], Loss: 824.1439\n",
      "Epoch [73/100], Step [800/4091], Loss: 623.2733\n",
      "Epoch [73/100], Step [900/4091], Loss: 690.2657\n",
      "Epoch [73/100], Step [1000/4091], Loss: 748.9524\n",
      "Epoch [73/100], Step [1100/4091], Loss: 564.9802\n",
      "Epoch [73/100], Step [1200/4091], Loss: 881.2883\n",
      "Epoch [73/100], Step [1300/4091], Loss: 719.0073\n",
      "Epoch [73/100], Step [1400/4091], Loss: 705.4156\n",
      "Epoch [73/100], Step [1500/4091], Loss: 560.3762\n",
      "Epoch [73/100], Step [1600/4091], Loss: 607.4717\n",
      "Epoch [73/100], Step [1700/4091], Loss: 539.1345\n",
      "Epoch [73/100], Step [1800/4091], Loss: 1020.6490\n",
      "Epoch [73/100], Step [1900/4091], Loss: 613.0270\n",
      "Epoch [73/100], Step [2000/4091], Loss: 609.1948\n",
      "Epoch [73/100], Step [2100/4091], Loss: 763.6519\n",
      "Epoch [73/100], Step [2200/4091], Loss: 499.4637\n",
      "Epoch [73/100], Step [2300/4091], Loss: 745.6360\n",
      "Epoch [73/100], Step [2400/4091], Loss: 773.6213\n",
      "Epoch [73/100], Step [2500/4091], Loss: 708.5352\n",
      "Epoch [73/100], Step [2600/4091], Loss: 542.2652\n",
      "Epoch [73/100], Step [2700/4091], Loss: 531.1082\n",
      "Epoch [73/100], Step [2800/4091], Loss: 564.7847\n",
      "Epoch [73/100], Step [2900/4091], Loss: 694.2982\n",
      "Epoch [73/100], Step [3000/4091], Loss: 518.1244\n",
      "Epoch [73/100], Step [3100/4091], Loss: 769.0529\n",
      "Epoch [73/100], Step [3200/4091], Loss: 962.2190\n",
      "Epoch [73/100], Step [3300/4091], Loss: 630.6566\n",
      "Epoch [73/100], Step [3400/4091], Loss: 744.2358\n",
      "Epoch [73/100], Step [3500/4091], Loss: 566.4251\n",
      "Epoch [73/100], Step [3600/4091], Loss: 751.2941\n",
      "Epoch [73/100], Step [3700/4091], Loss: 573.6191\n",
      "Epoch [73/100], Step [3800/4091], Loss: 655.5126\n",
      "Epoch [73/100], Step [3900/4091], Loss: 607.2952\n",
      "Epoch [73/100], Step [4000/4091], Loss: 746.2988\n",
      "Epoch [74/100], Step [100/4091], Loss: 645.7230\n",
      "Epoch [74/100], Step [200/4091], Loss: 599.6804\n",
      "Epoch [74/100], Step [300/4091], Loss: 737.8870\n",
      "Epoch [74/100], Step [400/4091], Loss: 772.1619\n",
      "Epoch [74/100], Step [500/4091], Loss: 625.7145\n",
      "Epoch [74/100], Step [600/4091], Loss: 628.9296\n",
      "Epoch [74/100], Step [700/4091], Loss: 514.6139\n",
      "Epoch [74/100], Step [800/4091], Loss: 659.4825\n",
      "Epoch [74/100], Step [900/4091], Loss: 544.3045\n",
      "Epoch [74/100], Step [1000/4091], Loss: 471.5179\n",
      "Epoch [74/100], Step [1100/4091], Loss: 623.7013\n",
      "Epoch [74/100], Step [1200/4091], Loss: 689.2083\n",
      "Epoch [74/100], Step [1300/4091], Loss: 764.0156\n",
      "Epoch [74/100], Step [1400/4091], Loss: 601.7841\n",
      "Epoch [74/100], Step [1500/4091], Loss: 719.4272\n",
      "Epoch [74/100], Step [1600/4091], Loss: 708.8012\n",
      "Epoch [74/100], Step [1700/4091], Loss: 675.7599\n",
      "Epoch [74/100], Step [1800/4091], Loss: 621.9918\n",
      "Epoch [74/100], Step [1900/4091], Loss: 658.3677\n",
      "Epoch [74/100], Step [2000/4091], Loss: 477.9328\n",
      "Epoch [74/100], Step [2100/4091], Loss: 808.5955\n",
      "Epoch [74/100], Step [2200/4091], Loss: 770.5563\n",
      "Epoch [74/100], Step [2300/4091], Loss: 593.7281\n",
      "Epoch [74/100], Step [2400/4091], Loss: 678.1716\n",
      "Epoch [74/100], Step [2500/4091], Loss: 806.9963\n",
      "Epoch [74/100], Step [2600/4091], Loss: 700.4419\n",
      "Epoch [74/100], Step [2700/4091], Loss: 625.6546\n",
      "Epoch [74/100], Step [2800/4091], Loss: 583.5221\n",
      "Epoch [74/100], Step [2900/4091], Loss: 866.1864\n",
      "Epoch [74/100], Step [3000/4091], Loss: 771.3387\n",
      "Epoch [74/100], Step [3100/4091], Loss: 530.7773\n",
      "Epoch [74/100], Step [3200/4091], Loss: 490.2932\n",
      "Epoch [74/100], Step [3300/4091], Loss: 852.8629\n",
      "Epoch [74/100], Step [3400/4091], Loss: 553.5853\n",
      "Epoch [74/100], Step [3500/4091], Loss: 702.8800\n",
      "Epoch [74/100], Step [3600/4091], Loss: 578.0731\n",
      "Epoch [74/100], Step [3700/4091], Loss: 746.5681\n",
      "Epoch [74/100], Step [3800/4091], Loss: 567.6226\n",
      "Epoch [74/100], Step [3900/4091], Loss: 505.5987\n",
      "Epoch [74/100], Step [4000/4091], Loss: 740.3717\n",
      "Epoch [75/100], Step [100/4091], Loss: 869.6938\n",
      "Epoch [75/100], Step [200/4091], Loss: 656.2284\n",
      "Epoch [75/100], Step [300/4091], Loss: 529.8838\n",
      "Epoch [75/100], Step [400/4091], Loss: 559.4055\n",
      "Epoch [75/100], Step [500/4091], Loss: 903.2963\n",
      "Epoch [75/100], Step [600/4091], Loss: 686.9995\n",
      "Epoch [75/100], Step [700/4091], Loss: 637.3364\n",
      "Epoch [75/100], Step [800/4091], Loss: 682.3384\n",
      "Epoch [75/100], Step [900/4091], Loss: 592.5642\n",
      "Epoch [75/100], Step [1000/4091], Loss: 623.9616\n",
      "Epoch [75/100], Step [1100/4091], Loss: 757.1465\n",
      "Epoch [75/100], Step [1200/4091], Loss: 597.3291\n",
      "Epoch [75/100], Step [1300/4091], Loss: 781.1228\n",
      "Epoch [75/100], Step [1400/4091], Loss: 552.3253\n",
      "Epoch [75/100], Step [1500/4091], Loss: 614.2387\n",
      "Epoch [75/100], Step [1600/4091], Loss: 518.8458\n",
      "Epoch [75/100], Step [1700/4091], Loss: 862.5577\n",
      "Epoch [75/100], Step [1800/4091], Loss: 946.1348\n",
      "Epoch [75/100], Step [1900/4091], Loss: 567.1459\n",
      "Epoch [75/100], Step [2000/4091], Loss: 590.5648\n",
      "Epoch [75/100], Step [2100/4091], Loss: 575.3007\n",
      "Epoch [75/100], Step [2200/4091], Loss: 892.5078\n",
      "Epoch [75/100], Step [2300/4091], Loss: 402.7574\n",
      "Epoch [75/100], Step [2400/4091], Loss: 493.6095\n",
      "Epoch [75/100], Step [2500/4091], Loss: 733.8146\n",
      "Epoch [75/100], Step [2600/4091], Loss: 634.5234\n",
      "Epoch [75/100], Step [2700/4091], Loss: 563.5272\n",
      "Epoch [75/100], Step [2800/4091], Loss: 700.8173\n",
      "Epoch [75/100], Step [2900/4091], Loss: 496.5933\n",
      "Epoch [75/100], Step [3000/4091], Loss: 495.2844\n",
      "Epoch [75/100], Step [3100/4091], Loss: 611.5491\n",
      "Epoch [75/100], Step [3200/4091], Loss: 594.0887\n",
      "Epoch [75/100], Step [3300/4091], Loss: 506.8459\n",
      "Epoch [75/100], Step [3400/4091], Loss: 680.4968\n",
      "Epoch [75/100], Step [3500/4091], Loss: 580.2594\n",
      "Epoch [75/100], Step [3600/4091], Loss: 471.8283\n",
      "Epoch [75/100], Step [3700/4091], Loss: 795.8671\n",
      "Epoch [75/100], Step [3800/4091], Loss: 647.9465\n",
      "Epoch [75/100], Step [3900/4091], Loss: 764.2925\n",
      "Epoch [75/100], Step [4000/4091], Loss: 700.5094\n",
      "Epoch [76/100], Step [100/4091], Loss: 581.6742\n",
      "Epoch [76/100], Step [200/4091], Loss: 482.4401\n",
      "Epoch [76/100], Step [300/4091], Loss: 721.1707\n",
      "Epoch [76/100], Step [400/4091], Loss: 783.9231\n",
      "Epoch [76/100], Step [500/4091], Loss: 908.4677\n",
      "Epoch [76/100], Step [600/4091], Loss: 686.4639\n",
      "Epoch [76/100], Step [700/4091], Loss: 735.7264\n",
      "Epoch [76/100], Step [800/4091], Loss: 782.9398\n",
      "Epoch [76/100], Step [900/4091], Loss: 652.8662\n",
      "Epoch [76/100], Step [1000/4091], Loss: 637.7457\n",
      "Epoch [76/100], Step [1100/4091], Loss: 628.1749\n",
      "Epoch [76/100], Step [1200/4091], Loss: 607.1014\n",
      "Epoch [76/100], Step [1300/4091], Loss: 661.8901\n",
      "Epoch [76/100], Step [1400/4091], Loss: 551.3771\n",
      "Epoch [76/100], Step [1500/4091], Loss: 674.7646\n",
      "Epoch [76/100], Step [1600/4091], Loss: 652.7963\n",
      "Epoch [76/100], Step [1700/4091], Loss: 627.4071\n",
      "Epoch [76/100], Step [1800/4091], Loss: 620.0618\n",
      "Epoch [76/100], Step [1900/4091], Loss: 762.7876\n",
      "Epoch [76/100], Step [2000/4091], Loss: 664.1621\n",
      "Epoch [76/100], Step [2100/4091], Loss: 845.6483\n",
      "Epoch [76/100], Step [2200/4091], Loss: 614.2135\n",
      "Epoch [76/100], Step [2300/4091], Loss: 596.3683\n",
      "Epoch [76/100], Step [2400/4091], Loss: 662.7282\n",
      "Epoch [76/100], Step [2500/4091], Loss: 595.0361\n",
      "Epoch [76/100], Step [2600/4091], Loss: 436.7578\n",
      "Epoch [76/100], Step [2700/4091], Loss: 454.3829\n",
      "Epoch [76/100], Step [2800/4091], Loss: 461.1389\n",
      "Epoch [76/100], Step [2900/4091], Loss: 539.4042\n",
      "Epoch [76/100], Step [3000/4091], Loss: 610.5988\n",
      "Epoch [76/100], Step [3100/4091], Loss: 579.0169\n",
      "Epoch [76/100], Step [3200/4091], Loss: 622.5900\n",
      "Epoch [76/100], Step [3300/4091], Loss: 523.1832\n",
      "Epoch [76/100], Step [3400/4091], Loss: 623.3043\n",
      "Epoch [76/100], Step [3500/4091], Loss: 689.2829\n",
      "Epoch [76/100], Step [3600/4091], Loss: 633.0319\n",
      "Epoch [76/100], Step [3700/4091], Loss: 523.1213\n",
      "Epoch [76/100], Step [3800/4091], Loss: 691.2076\n",
      "Epoch [76/100], Step [3900/4091], Loss: 560.8487\n",
      "Epoch [76/100], Step [4000/4091], Loss: 775.7129\n",
      "Epoch [77/100], Step [100/4091], Loss: 974.9752\n",
      "Epoch [77/100], Step [200/4091], Loss: 607.8414\n",
      "Epoch [77/100], Step [300/4091], Loss: 500.1710\n",
      "Epoch [77/100], Step [400/4091], Loss: 647.4772\n",
      "Epoch [77/100], Step [500/4091], Loss: 472.5971\n",
      "Epoch [77/100], Step [600/4091], Loss: 595.0193\n",
      "Epoch [77/100], Step [700/4091], Loss: 595.8050\n",
      "Epoch [77/100], Step [800/4091], Loss: 541.8743\n",
      "Epoch [77/100], Step [900/4091], Loss: 459.9710\n",
      "Epoch [77/100], Step [1000/4091], Loss: 744.9415\n",
      "Epoch [77/100], Step [1100/4091], Loss: 578.8430\n",
      "Epoch [77/100], Step [1200/4091], Loss: 777.8038\n",
      "Epoch [77/100], Step [1300/4091], Loss: 589.2294\n",
      "Epoch [77/100], Step [1400/4091], Loss: 577.0853\n",
      "Epoch [77/100], Step [1500/4091], Loss: 773.7068\n",
      "Epoch [77/100], Step [1600/4091], Loss: 775.1520\n",
      "Epoch [77/100], Step [1700/4091], Loss: 587.7688\n",
      "Epoch [77/100], Step [1800/4091], Loss: 867.5939\n",
      "Epoch [77/100], Step [1900/4091], Loss: 717.9897\n",
      "Epoch [77/100], Step [2000/4091], Loss: 594.0577\n",
      "Epoch [77/100], Step [2100/4091], Loss: 792.0327\n",
      "Epoch [77/100], Step [2200/4091], Loss: 540.9960\n",
      "Epoch [77/100], Step [2300/4091], Loss: 499.3246\n",
      "Epoch [77/100], Step [2400/4091], Loss: 547.4548\n",
      "Epoch [77/100], Step [2500/4091], Loss: 608.0665\n",
      "Epoch [77/100], Step [2600/4091], Loss: 778.2644\n",
      "Epoch [77/100], Step [2700/4091], Loss: 740.3453\n",
      "Epoch [77/100], Step [2800/4091], Loss: 733.5446\n",
      "Epoch [77/100], Step [2900/4091], Loss: 829.5249\n",
      "Epoch [77/100], Step [3000/4091], Loss: 661.4559\n",
      "Epoch [77/100], Step [3100/4091], Loss: 658.3749\n",
      "Epoch [77/100], Step [3200/4091], Loss: 559.3690\n",
      "Epoch [77/100], Step [3300/4091], Loss: 728.3807\n",
      "Epoch [77/100], Step [3400/4091], Loss: 658.0967\n",
      "Epoch [77/100], Step [3500/4091], Loss: 558.8887\n",
      "Epoch [77/100], Step [3600/4091], Loss: 775.7213\n",
      "Epoch [77/100], Step [3700/4091], Loss: 548.9947\n",
      "Epoch [77/100], Step [3800/4091], Loss: 583.6115\n",
      "Epoch [77/100], Step [3900/4091], Loss: 613.6948\n",
      "Epoch [77/100], Step [4000/4091], Loss: 694.1453\n",
      "Epoch [78/100], Step [100/4091], Loss: 654.6352\n",
      "Epoch [78/100], Step [200/4091], Loss: 671.6780\n",
      "Epoch [78/100], Step [300/4091], Loss: 568.5375\n",
      "Epoch [78/100], Step [400/4091], Loss: 524.7498\n",
      "Epoch [78/100], Step [500/4091], Loss: 566.0068\n",
      "Epoch [78/100], Step [600/4091], Loss: 654.9211\n",
      "Epoch [78/100], Step [700/4091], Loss: 699.9957\n",
      "Epoch [78/100], Step [800/4091], Loss: 501.8704\n",
      "Epoch [78/100], Step [900/4091], Loss: 522.4285\n",
      "Epoch [78/100], Step [1000/4091], Loss: 720.2991\n",
      "Epoch [78/100], Step [1100/4091], Loss: 752.5544\n",
      "Epoch [78/100], Step [1200/4091], Loss: 475.9465\n",
      "Epoch [78/100], Step [1300/4091], Loss: 590.6376\n",
      "Epoch [78/100], Step [1400/4091], Loss: 655.7454\n",
      "Epoch [78/100], Step [1500/4091], Loss: 590.3515\n",
      "Epoch [78/100], Step [1600/4091], Loss: 649.8954\n",
      "Epoch [78/100], Step [1700/4091], Loss: 642.4071\n",
      "Epoch [78/100], Step [1800/4091], Loss: 697.6575\n",
      "Epoch [78/100], Step [1900/4091], Loss: 675.3306\n",
      "Epoch [78/100], Step [2000/4091], Loss: 688.0262\n",
      "Epoch [78/100], Step [2100/4091], Loss: 720.9246\n",
      "Epoch [78/100], Step [2200/4091], Loss: 603.3989\n",
      "Epoch [78/100], Step [2300/4091], Loss: 860.3605\n",
      "Epoch [78/100], Step [2400/4091], Loss: 537.8412\n",
      "Epoch [78/100], Step [2500/4091], Loss: 669.1692\n",
      "Epoch [78/100], Step [2600/4091], Loss: 749.4646\n",
      "Epoch [78/100], Step [2700/4091], Loss: 677.5721\n",
      "Epoch [78/100], Step [2800/4091], Loss: 512.7487\n",
      "Epoch [78/100], Step [2900/4091], Loss: 558.1746\n",
      "Epoch [78/100], Step [3000/4091], Loss: 419.6650\n",
      "Epoch [78/100], Step [3100/4091], Loss: 749.5540\n",
      "Epoch [78/100], Step [3200/4091], Loss: 509.6646\n",
      "Epoch [78/100], Step [3300/4091], Loss: 492.3870\n",
      "Epoch [78/100], Step [3400/4091], Loss: 668.9570\n",
      "Epoch [78/100], Step [3500/4091], Loss: 547.4362\n",
      "Epoch [78/100], Step [3600/4091], Loss: 752.9596\n",
      "Epoch [78/100], Step [3700/4091], Loss: 546.9104\n",
      "Epoch [78/100], Step [3800/4091], Loss: 892.0417\n",
      "Epoch [78/100], Step [3900/4091], Loss: 743.6890\n",
      "Epoch [78/100], Step [4000/4091], Loss: 772.9780\n",
      "Epoch [79/100], Step [100/4091], Loss: 667.0567\n",
      "Epoch [79/100], Step [200/4091], Loss: 638.9824\n",
      "Epoch [79/100], Step [300/4091], Loss: 683.0920\n",
      "Epoch [79/100], Step [400/4091], Loss: 575.4379\n",
      "Epoch [79/100], Step [500/4091], Loss: 701.4193\n",
      "Epoch [79/100], Step [600/4091], Loss: 577.1650\n",
      "Epoch [79/100], Step [700/4091], Loss: 574.4707\n",
      "Epoch [79/100], Step [800/4091], Loss: 626.0667\n",
      "Epoch [79/100], Step [900/4091], Loss: 849.8588\n",
      "Epoch [79/100], Step [1000/4091], Loss: 628.1860\n",
      "Epoch [79/100], Step [1100/4091], Loss: 862.3234\n",
      "Epoch [79/100], Step [1200/4091], Loss: 653.5295\n",
      "Epoch [79/100], Step [1300/4091], Loss: 465.4153\n",
      "Epoch [79/100], Step [1400/4091], Loss: 844.0909\n",
      "Epoch [79/100], Step [1500/4091], Loss: 456.0041\n",
      "Epoch [79/100], Step [1600/4091], Loss: 523.7474\n",
      "Epoch [79/100], Step [1700/4091], Loss: 736.8500\n",
      "Epoch [79/100], Step [1800/4091], Loss: 584.3438\n",
      "Epoch [79/100], Step [1900/4091], Loss: 835.7682\n",
      "Epoch [79/100], Step [2000/4091], Loss: 729.8907\n",
      "Epoch [79/100], Step [2100/4091], Loss: 630.5876\n",
      "Epoch [79/100], Step [2200/4091], Loss: 615.9993\n",
      "Epoch [79/100], Step [2300/4091], Loss: 518.0928\n",
      "Epoch [79/100], Step [2400/4091], Loss: 615.4686\n",
      "Epoch [79/100], Step [2500/4091], Loss: 588.7048\n",
      "Epoch [79/100], Step [2600/4091], Loss: 509.4059\n",
      "Epoch [79/100], Step [2700/4091], Loss: 580.9489\n",
      "Epoch [79/100], Step [2800/4091], Loss: 713.0671\n",
      "Epoch [79/100], Step [2900/4091], Loss: 712.7035\n",
      "Epoch [79/100], Step [3000/4091], Loss: 498.8675\n",
      "Epoch [79/100], Step [3100/4091], Loss: 605.5502\n",
      "Epoch [79/100], Step [3200/4091], Loss: 844.6266\n",
      "Epoch [79/100], Step [3300/4091], Loss: 948.2640\n",
      "Epoch [79/100], Step [3400/4091], Loss: 487.6362\n",
      "Epoch [79/100], Step [3500/4091], Loss: 652.5753\n",
      "Epoch [79/100], Step [3600/4091], Loss: 751.3652\n",
      "Epoch [79/100], Step [3700/4091], Loss: 606.0064\n",
      "Epoch [79/100], Step [3800/4091], Loss: 753.3745\n",
      "Epoch [79/100], Step [3900/4091], Loss: 702.6837\n",
      "Epoch [79/100], Step [4000/4091], Loss: 722.5361\n",
      "Epoch [80/100], Step [100/4091], Loss: 688.7048\n",
      "Epoch [80/100], Step [200/4091], Loss: 652.6028\n",
      "Epoch [80/100], Step [300/4091], Loss: 460.7657\n",
      "Epoch [80/100], Step [400/4091], Loss: 604.8862\n",
      "Epoch [80/100], Step [500/4091], Loss: 783.4438\n",
      "Epoch [80/100], Step [600/4091], Loss: 721.5238\n",
      "Epoch [80/100], Step [700/4091], Loss: 747.5396\n",
      "Epoch [80/100], Step [800/4091], Loss: 588.9159\n",
      "Epoch [80/100], Step [900/4091], Loss: 614.4569\n",
      "Epoch [80/100], Step [1000/4091], Loss: 660.4028\n",
      "Epoch [80/100], Step [1100/4091], Loss: 1169.3231\n",
      "Epoch [80/100], Step [1200/4091], Loss: 546.6708\n",
      "Epoch [80/100], Step [1300/4091], Loss: 683.9374\n",
      "Epoch [80/100], Step [1400/4091], Loss: 663.7580\n",
      "Epoch [80/100], Step [1500/4091], Loss: 654.0685\n",
      "Epoch [80/100], Step [1600/4091], Loss: 576.8911\n",
      "Epoch [80/100], Step [1700/4091], Loss: 680.6260\n",
      "Epoch [80/100], Step [1800/4091], Loss: 722.9275\n",
      "Epoch [80/100], Step [1900/4091], Loss: 764.2717\n",
      "Epoch [80/100], Step [2000/4091], Loss: 621.5094\n",
      "Epoch [80/100], Step [2100/4091], Loss: 762.4425\n",
      "Epoch [80/100], Step [2200/4091], Loss: 539.1935\n",
      "Epoch [80/100], Step [2300/4091], Loss: 685.7741\n",
      "Epoch [80/100], Step [2400/4091], Loss: 803.2654\n",
      "Epoch [80/100], Step [2500/4091], Loss: 836.9929\n",
      "Epoch [80/100], Step [2600/4091], Loss: 652.1802\n",
      "Epoch [80/100], Step [2700/4091], Loss: 530.6370\n",
      "Epoch [80/100], Step [2800/4091], Loss: 702.3267\n",
      "Epoch [80/100], Step [2900/4091], Loss: 786.2466\n",
      "Epoch [80/100], Step [3000/4091], Loss: 686.4102\n",
      "Epoch [80/100], Step [3100/4091], Loss: 871.4678\n",
      "Epoch [80/100], Step [3200/4091], Loss: 562.7972\n",
      "Epoch [80/100], Step [3300/4091], Loss: 803.6626\n",
      "Epoch [80/100], Step [3400/4091], Loss: 568.6395\n",
      "Epoch [80/100], Step [3500/4091], Loss: 724.4948\n",
      "Epoch [80/100], Step [3600/4091], Loss: 595.5115\n",
      "Epoch [80/100], Step [3700/4091], Loss: 777.4072\n",
      "Epoch [80/100], Step [3800/4091], Loss: 582.6110\n",
      "Epoch [80/100], Step [3900/4091], Loss: 623.3439\n",
      "Epoch [80/100], Step [4000/4091], Loss: 663.5789\n",
      "Epoch [81/100], Step [100/4091], Loss: 637.5391\n",
      "Epoch [81/100], Step [200/4091], Loss: 519.2600\n",
      "Epoch [81/100], Step [300/4091], Loss: 643.7343\n",
      "Epoch [81/100], Step [400/4091], Loss: 621.9851\n",
      "Epoch [81/100], Step [500/4091], Loss: 715.7318\n",
      "Epoch [81/100], Step [600/4091], Loss: 724.3533\n",
      "Epoch [81/100], Step [700/4091], Loss: 697.3374\n",
      "Epoch [81/100], Step [800/4091], Loss: 614.4500\n",
      "Epoch [81/100], Step [900/4091], Loss: 1108.4910\n",
      "Epoch [81/100], Step [1000/4091], Loss: 626.1783\n",
      "Epoch [81/100], Step [1100/4091], Loss: 573.7542\n",
      "Epoch [81/100], Step [1200/4091], Loss: 672.1655\n",
      "Epoch [81/100], Step [1300/4091], Loss: 528.0636\n",
      "Epoch [81/100], Step [1400/4091], Loss: 700.7490\n",
      "Epoch [81/100], Step [1500/4091], Loss: 762.7429\n",
      "Epoch [81/100], Step [1600/4091], Loss: 654.3630\n",
      "Epoch [81/100], Step [1700/4091], Loss: 586.8057\n",
      "Epoch [81/100], Step [1800/4091], Loss: 415.6772\n",
      "Epoch [81/100], Step [1900/4091], Loss: 675.2429\n",
      "Epoch [81/100], Step [2000/4091], Loss: 521.1763\n",
      "Epoch [81/100], Step [2100/4091], Loss: 730.0385\n",
      "Epoch [81/100], Step [2200/4091], Loss: 557.5455\n",
      "Epoch [81/100], Step [2300/4091], Loss: 642.6768\n",
      "Epoch [81/100], Step [2400/4091], Loss: 775.4730\n",
      "Epoch [81/100], Step [2500/4091], Loss: 707.7968\n",
      "Epoch [81/100], Step [2600/4091], Loss: 544.5945\n",
      "Epoch [81/100], Step [2700/4091], Loss: 581.6353\n",
      "Epoch [81/100], Step [2800/4091], Loss: 730.0292\n",
      "Epoch [81/100], Step [2900/4091], Loss: 595.6921\n",
      "Epoch [81/100], Step [3000/4091], Loss: 649.4804\n",
      "Epoch [81/100], Step [3100/4091], Loss: 530.9637\n",
      "Epoch [81/100], Step [3200/4091], Loss: 610.5949\n",
      "Epoch [81/100], Step [3300/4091], Loss: 596.4726\n",
      "Epoch [81/100], Step [3400/4091], Loss: 581.0760\n",
      "Epoch [81/100], Step [3500/4091], Loss: 462.8450\n",
      "Epoch [81/100], Step [3600/4091], Loss: 778.2264\n",
      "Epoch [81/100], Step [3700/4091], Loss: 658.7225\n",
      "Epoch [81/100], Step [3800/4091], Loss: 709.9415\n",
      "Epoch [81/100], Step [3900/4091], Loss: 759.0052\n",
      "Epoch [81/100], Step [4000/4091], Loss: 674.7236\n",
      "Epoch [82/100], Step [100/4091], Loss: 646.8437\n",
      "Epoch [82/100], Step [200/4091], Loss: 760.7942\n",
      "Epoch [82/100], Step [300/4091], Loss: 709.7510\n",
      "Epoch [82/100], Step [400/4091], Loss: 753.6367\n",
      "Epoch [82/100], Step [500/4091], Loss: 488.2161\n",
      "Epoch [82/100], Step [600/4091], Loss: 513.1936\n",
      "Epoch [82/100], Step [700/4091], Loss: 855.1506\n",
      "Epoch [82/100], Step [800/4091], Loss: 704.1182\n",
      "Epoch [82/100], Step [900/4091], Loss: 785.1921\n",
      "Epoch [82/100], Step [1000/4091], Loss: 719.9613\n",
      "Epoch [82/100], Step [1100/4091], Loss: 607.5482\n",
      "Epoch [82/100], Step [1200/4091], Loss: 704.5911\n",
      "Epoch [82/100], Step [1300/4091], Loss: 528.9489\n",
      "Epoch [82/100], Step [1400/4091], Loss: 687.7772\n",
      "Epoch [82/100], Step [1500/4091], Loss: 775.4719\n",
      "Epoch [82/100], Step [1600/4091], Loss: 714.5893\n",
      "Epoch [82/100], Step [1700/4091], Loss: 783.3862\n",
      "Epoch [82/100], Step [1800/4091], Loss: 694.8276\n",
      "Epoch [82/100], Step [1900/4091], Loss: 659.0045\n",
      "Epoch [82/100], Step [2000/4091], Loss: 550.9825\n",
      "Epoch [82/100], Step [2100/4091], Loss: 843.1059\n",
      "Epoch [82/100], Step [2200/4091], Loss: 717.6591\n",
      "Epoch [82/100], Step [2300/4091], Loss: 661.9089\n",
      "Epoch [82/100], Step [2400/4091], Loss: 713.4075\n",
      "Epoch [82/100], Step [2500/4091], Loss: 541.2039\n",
      "Epoch [82/100], Step [2600/4091], Loss: 946.7180\n",
      "Epoch [82/100], Step [2700/4091], Loss: 576.9107\n",
      "Epoch [82/100], Step [2800/4091], Loss: 918.7048\n",
      "Epoch [82/100], Step [2900/4091], Loss: 689.1025\n",
      "Epoch [82/100], Step [3000/4091], Loss: 494.0865\n",
      "Epoch [82/100], Step [3100/4091], Loss: 465.4759\n",
      "Epoch [82/100], Step [3200/4091], Loss: 706.3675\n",
      "Epoch [82/100], Step [3300/4091], Loss: 496.7061\n",
      "Epoch [82/100], Step [3400/4091], Loss: 553.2369\n",
      "Epoch [82/100], Step [3500/4091], Loss: 541.1252\n",
      "Epoch [82/100], Step [3600/4091], Loss: 524.3505\n",
      "Epoch [82/100], Step [3700/4091], Loss: 809.0578\n",
      "Epoch [82/100], Step [3800/4091], Loss: 694.0893\n",
      "Epoch [82/100], Step [3900/4091], Loss: 772.7401\n",
      "Epoch [82/100], Step [4000/4091], Loss: 827.2101\n",
      "Epoch [83/100], Step [100/4091], Loss: 708.3174\n",
      "Epoch [83/100], Step [200/4091], Loss: 714.3667\n",
      "Epoch [83/100], Step [300/4091], Loss: 563.4984\n",
      "Epoch [83/100], Step [400/4091], Loss: 521.8873\n",
      "Epoch [83/100], Step [500/4091], Loss: 546.4580\n",
      "Epoch [83/100], Step [600/4091], Loss: 701.1756\n",
      "Epoch [83/100], Step [700/4091], Loss: 691.2247\n",
      "Epoch [83/100], Step [800/4091], Loss: 811.9003\n",
      "Epoch [83/100], Step [900/4091], Loss: 854.8675\n",
      "Epoch [83/100], Step [1000/4091], Loss: 634.6504\n",
      "Epoch [83/100], Step [1100/4091], Loss: 722.9368\n",
      "Epoch [83/100], Step [1200/4091], Loss: 532.5304\n",
      "Epoch [83/100], Step [1300/4091], Loss: 589.7362\n",
      "Epoch [83/100], Step [1400/4091], Loss: 594.1796\n",
      "Epoch [83/100], Step [1500/4091], Loss: 983.8963\n",
      "Epoch [83/100], Step [1600/4091], Loss: 607.7597\n",
      "Epoch [83/100], Step [1700/4091], Loss: 736.0908\n",
      "Epoch [83/100], Step [1800/4091], Loss: 748.1121\n",
      "Epoch [83/100], Step [1900/4091], Loss: 704.8232\n",
      "Epoch [83/100], Step [2000/4091], Loss: 549.7756\n",
      "Epoch [83/100], Step [2100/4091], Loss: 569.6859\n",
      "Epoch [83/100], Step [2200/4091], Loss: 478.3822\n",
      "Epoch [83/100], Step [2300/4091], Loss: 375.0613\n",
      "Epoch [83/100], Step [2400/4091], Loss: 592.5931\n",
      "Epoch [83/100], Step [2500/4091], Loss: 750.1721\n",
      "Epoch [83/100], Step [2600/4091], Loss: 675.5416\n",
      "Epoch [83/100], Step [2700/4091], Loss: 517.3939\n",
      "Epoch [83/100], Step [2800/4091], Loss: 735.7019\n",
      "Epoch [83/100], Step [2900/4091], Loss: 574.4344\n",
      "Epoch [83/100], Step [3000/4091], Loss: 610.9655\n",
      "Epoch [83/100], Step [3100/4091], Loss: 704.1585\n",
      "Epoch [83/100], Step [3200/4091], Loss: 1054.9976\n",
      "Epoch [83/100], Step [3300/4091], Loss: 696.3857\n",
      "Epoch [83/100], Step [3400/4091], Loss: 692.9146\n",
      "Epoch [83/100], Step [3500/4091], Loss: 510.0023\n",
      "Epoch [83/100], Step [3600/4091], Loss: 576.4690\n",
      "Epoch [83/100], Step [3700/4091], Loss: 638.0638\n",
      "Epoch [83/100], Step [3800/4091], Loss: 716.0712\n",
      "Epoch [83/100], Step [3900/4091], Loss: 593.7463\n",
      "Epoch [83/100], Step [4000/4091], Loss: 683.1683\n",
      "Epoch [84/100], Step [100/4091], Loss: 680.1666\n",
      "Epoch [84/100], Step [200/4091], Loss: 486.1302\n",
      "Epoch [84/100], Step [300/4091], Loss: 519.1783\n",
      "Epoch [84/100], Step [400/4091], Loss: 731.1088\n",
      "Epoch [84/100], Step [500/4091], Loss: 601.4649\n",
      "Epoch [84/100], Step [600/4091], Loss: 598.9180\n",
      "Epoch [84/100], Step [700/4091], Loss: 668.6300\n",
      "Epoch [84/100], Step [800/4091], Loss: 569.5044\n",
      "Epoch [84/100], Step [900/4091], Loss: 746.1219\n",
      "Epoch [84/100], Step [1000/4091], Loss: 440.6362\n",
      "Epoch [84/100], Step [1100/4091], Loss: 635.9158\n",
      "Epoch [84/100], Step [1200/4091], Loss: 706.9441\n",
      "Epoch [84/100], Step [1300/4091], Loss: 609.6256\n",
      "Epoch [84/100], Step [1400/4091], Loss: 429.3551\n",
      "Epoch [84/100], Step [1500/4091], Loss: 613.5274\n",
      "Epoch [84/100], Step [1600/4091], Loss: 863.6497\n",
      "Epoch [84/100], Step [1700/4091], Loss: 677.0316\n",
      "Epoch [84/100], Step [1800/4091], Loss: 663.7711\n",
      "Epoch [84/100], Step [1900/4091], Loss: 638.9278\n",
      "Epoch [84/100], Step [2000/4091], Loss: 764.4646\n",
      "Epoch [84/100], Step [2100/4091], Loss: 806.8667\n",
      "Epoch [84/100], Step [2200/4091], Loss: 780.3289\n",
      "Epoch [84/100], Step [2300/4091], Loss: 577.6279\n",
      "Epoch [84/100], Step [2400/4091], Loss: 524.0337\n",
      "Epoch [84/100], Step [2500/4091], Loss: 656.7545\n",
      "Epoch [84/100], Step [2600/4091], Loss: 714.4725\n",
      "Epoch [84/100], Step [2700/4091], Loss: 507.5379\n",
      "Epoch [84/100], Step [2800/4091], Loss: 683.0021\n",
      "Epoch [84/100], Step [2900/4091], Loss: 617.7770\n",
      "Epoch [84/100], Step [3000/4091], Loss: 722.0927\n",
      "Epoch [84/100], Step [3100/4091], Loss: 674.7928\n",
      "Epoch [84/100], Step [3200/4091], Loss: 663.6568\n",
      "Epoch [84/100], Step [3300/4091], Loss: 731.5312\n",
      "Epoch [84/100], Step [3400/4091], Loss: 628.9468\n",
      "Epoch [84/100], Step [3500/4091], Loss: 734.4012\n",
      "Epoch [84/100], Step [3600/4091], Loss: 638.7706\n",
      "Epoch [84/100], Step [3700/4091], Loss: 444.1451\n",
      "Epoch [84/100], Step [3800/4091], Loss: 462.0435\n",
      "Epoch [84/100], Step [3900/4091], Loss: 638.7039\n",
      "Epoch [84/100], Step [4000/4091], Loss: 567.3364\n",
      "Epoch [85/100], Step [100/4091], Loss: 844.0858\n",
      "Epoch [85/100], Step [200/4091], Loss: 638.6335\n",
      "Epoch [85/100], Step [300/4091], Loss: 602.0154\n",
      "Epoch [85/100], Step [400/4091], Loss: 570.4923\n",
      "Epoch [85/100], Step [500/4091], Loss: 881.7581\n",
      "Epoch [85/100], Step [600/4091], Loss: 670.3760\n",
      "Epoch [85/100], Step [700/4091], Loss: 835.4229\n",
      "Epoch [85/100], Step [800/4091], Loss: 759.6837\n",
      "Epoch [85/100], Step [900/4091], Loss: 654.7198\n",
      "Epoch [85/100], Step [1000/4091], Loss: 620.2068\n",
      "Epoch [85/100], Step [1100/4091], Loss: 523.6997\n",
      "Epoch [85/100], Step [1200/4091], Loss: 554.3640\n",
      "Epoch [85/100], Step [1300/4091], Loss: 459.4579\n",
      "Epoch [85/100], Step [1400/4091], Loss: 655.9261\n",
      "Epoch [85/100], Step [1500/4091], Loss: 578.6581\n",
      "Epoch [85/100], Step [1600/4091], Loss: 549.3394\n",
      "Epoch [85/100], Step [1700/4091], Loss: 632.3351\n",
      "Epoch [85/100], Step [1800/4091], Loss: 704.3164\n",
      "Epoch [85/100], Step [1900/4091], Loss: 467.6226\n",
      "Epoch [85/100], Step [2000/4091], Loss: 622.9023\n",
      "Epoch [85/100], Step [2100/4091], Loss: 693.9931\n",
      "Epoch [85/100], Step [2200/4091], Loss: 707.3995\n",
      "Epoch [85/100], Step [2300/4091], Loss: 722.0986\n",
      "Epoch [85/100], Step [2400/4091], Loss: 731.5728\n",
      "Epoch [85/100], Step [2500/4091], Loss: 938.7614\n",
      "Epoch [85/100], Step [2600/4091], Loss: 619.4455\n",
      "Epoch [85/100], Step [2700/4091], Loss: 535.1392\n",
      "Epoch [85/100], Step [2800/4091], Loss: 653.1916\n",
      "Epoch [85/100], Step [2900/4091], Loss: 614.5359\n",
      "Epoch [85/100], Step [3000/4091], Loss: 690.8125\n",
      "Epoch [85/100], Step [3100/4091], Loss: 627.3367\n",
      "Epoch [85/100], Step [3200/4091], Loss: 710.7587\n",
      "Epoch [85/100], Step [3300/4091], Loss: 526.4996\n",
      "Epoch [85/100], Step [3400/4091], Loss: 679.0185\n",
      "Epoch [85/100], Step [3500/4091], Loss: 602.7740\n",
      "Epoch [85/100], Step [3600/4091], Loss: 606.8340\n",
      "Epoch [85/100], Step [3700/4091], Loss: 708.9691\n",
      "Epoch [85/100], Step [3800/4091], Loss: 578.1702\n",
      "Epoch [85/100], Step [3900/4091], Loss: 636.0126\n",
      "Epoch [85/100], Step [4000/4091], Loss: 584.9940\n",
      "Epoch [86/100], Step [100/4091], Loss: 561.9061\n",
      "Epoch [86/100], Step [200/4091], Loss: 1085.9178\n",
      "Epoch [86/100], Step [300/4091], Loss: 650.5582\n",
      "Epoch [86/100], Step [400/4091], Loss: 636.8508\n",
      "Epoch [86/100], Step [500/4091], Loss: 799.0544\n",
      "Epoch [86/100], Step [600/4091], Loss: 798.4349\n",
      "Epoch [86/100], Step [700/4091], Loss: 594.5141\n",
      "Epoch [86/100], Step [800/4091], Loss: 770.3384\n",
      "Epoch [86/100], Step [900/4091], Loss: 773.6238\n",
      "Epoch [86/100], Step [1000/4091], Loss: 831.8837\n",
      "Epoch [86/100], Step [1100/4091], Loss: 996.0046\n",
      "Epoch [86/100], Step [1200/4091], Loss: 729.0298\n",
      "Epoch [86/100], Step [1300/4091], Loss: 867.6292\n",
      "Epoch [86/100], Step [1400/4091], Loss: 550.8490\n",
      "Epoch [86/100], Step [1500/4091], Loss: 474.1899\n",
      "Epoch [86/100], Step [1600/4091], Loss: 849.3636\n",
      "Epoch [86/100], Step [1700/4091], Loss: 597.3167\n",
      "Epoch [86/100], Step [1800/4091], Loss: 772.3151\n",
      "Epoch [86/100], Step [1900/4091], Loss: 570.4697\n",
      "Epoch [86/100], Step [2000/4091], Loss: 611.8852\n",
      "Epoch [86/100], Step [2100/4091], Loss: 684.8745\n",
      "Epoch [86/100], Step [2200/4091], Loss: 778.8074\n",
      "Epoch [86/100], Step [2300/4091], Loss: 515.8586\n",
      "Epoch [86/100], Step [2400/4091], Loss: 942.6304\n",
      "Epoch [86/100], Step [2500/4091], Loss: 817.4034\n",
      "Epoch [86/100], Step [2600/4091], Loss: 631.0494\n",
      "Epoch [86/100], Step [2700/4091], Loss: 515.8240\n",
      "Epoch [86/100], Step [2800/4091], Loss: 750.2223\n",
      "Epoch [86/100], Step [2900/4091], Loss: 753.3002\n",
      "Epoch [86/100], Step [3000/4091], Loss: 631.4940\n",
      "Epoch [86/100], Step [3100/4091], Loss: 657.4706\n",
      "Epoch [86/100], Step [3200/4091], Loss: 711.4847\n",
      "Epoch [86/100], Step [3300/4091], Loss: 660.1286\n",
      "Epoch [86/100], Step [3400/4091], Loss: 679.7137\n",
      "Epoch [86/100], Step [3500/4091], Loss: 636.3652\n",
      "Epoch [86/100], Step [3600/4091], Loss: 511.8365\n",
      "Epoch [86/100], Step [3700/4091], Loss: 807.0450\n",
      "Epoch [86/100], Step [3800/4091], Loss: 566.6406\n",
      "Epoch [86/100], Step [3900/4091], Loss: 781.6904\n",
      "Epoch [86/100], Step [4000/4091], Loss: 625.4434\n",
      "Epoch [87/100], Step [100/4091], Loss: 990.2664\n",
      "Epoch [87/100], Step [200/4091], Loss: 737.8152\n",
      "Epoch [87/100], Step [300/4091], Loss: 538.1780\n",
      "Epoch [87/100], Step [400/4091], Loss: 690.4902\n",
      "Epoch [87/100], Step [500/4091], Loss: 763.3943\n",
      "Epoch [87/100], Step [600/4091], Loss: 843.2898\n",
      "Epoch [87/100], Step [700/4091], Loss: 912.1652\n",
      "Epoch [87/100], Step [800/4091], Loss: 711.7950\n",
      "Epoch [87/100], Step [900/4091], Loss: 694.4190\n",
      "Epoch [87/100], Step [1000/4091], Loss: 569.3644\n",
      "Epoch [87/100], Step [1100/4091], Loss: 568.4115\n",
      "Epoch [87/100], Step [1200/4091], Loss: 537.3033\n",
      "Epoch [87/100], Step [1300/4091], Loss: 780.0704\n",
      "Epoch [87/100], Step [1400/4091], Loss: 494.2853\n",
      "Epoch [87/100], Step [1500/4091], Loss: 854.1082\n",
      "Epoch [87/100], Step [1600/4091], Loss: 535.0802\n",
      "Epoch [87/100], Step [1700/4091], Loss: 547.8568\n",
      "Epoch [87/100], Step [1800/4091], Loss: 821.0283\n",
      "Epoch [87/100], Step [1900/4091], Loss: 567.2053\n",
      "Epoch [87/100], Step [2000/4091], Loss: 521.3943\n",
      "Epoch [87/100], Step [2100/4091], Loss: 883.1010\n",
      "Epoch [87/100], Step [2200/4091], Loss: 580.8998\n",
      "Epoch [87/100], Step [2300/4091], Loss: 614.7604\n",
      "Epoch [87/100], Step [2400/4091], Loss: 658.6358\n",
      "Epoch [87/100], Step [2500/4091], Loss: 586.2086\n",
      "Epoch [87/100], Step [2600/4091], Loss: 692.7125\n",
      "Epoch [87/100], Step [2700/4091], Loss: 635.7986\n",
      "Epoch [87/100], Step [2800/4091], Loss: 523.6519\n",
      "Epoch [87/100], Step [2900/4091], Loss: 735.1245\n",
      "Epoch [87/100], Step [3000/4091], Loss: 630.5455\n",
      "Epoch [87/100], Step [3100/4091], Loss: 603.1616\n",
      "Epoch [87/100], Step [3200/4091], Loss: 597.8574\n",
      "Epoch [87/100], Step [3300/4091], Loss: 686.6781\n",
      "Epoch [87/100], Step [3400/4091], Loss: 651.5649\n",
      "Epoch [87/100], Step [3500/4091], Loss: 817.2764\n",
      "Epoch [87/100], Step [3600/4091], Loss: 579.6274\n",
      "Epoch [87/100], Step [3700/4091], Loss: 414.2629\n",
      "Epoch [87/100], Step [3800/4091], Loss: 666.9293\n",
      "Epoch [87/100], Step [3900/4091], Loss: 666.1235\n",
      "Epoch [87/100], Step [4000/4091], Loss: 612.6180\n",
      "Epoch [88/100], Step [100/4091], Loss: 523.4531\n",
      "Epoch [88/100], Step [200/4091], Loss: 469.9823\n",
      "Epoch [88/100], Step [300/4091], Loss: 826.5314\n",
      "Epoch [88/100], Step [400/4091], Loss: 449.5143\n",
      "Epoch [88/100], Step [500/4091], Loss: 708.0711\n",
      "Epoch [88/100], Step [600/4091], Loss: 731.4719\n",
      "Epoch [88/100], Step [700/4091], Loss: 668.0501\n",
      "Epoch [88/100], Step [800/4091], Loss: 710.6703\n",
      "Epoch [88/100], Step [900/4091], Loss: 609.2426\n",
      "Epoch [88/100], Step [1000/4091], Loss: 642.8412\n",
      "Epoch [88/100], Step [1100/4091], Loss: 671.3353\n",
      "Epoch [88/100], Step [1200/4091], Loss: 642.5760\n",
      "Epoch [88/100], Step [1300/4091], Loss: 859.9280\n",
      "Epoch [88/100], Step [1400/4091], Loss: 531.7927\n",
      "Epoch [88/100], Step [1500/4091], Loss: 590.7921\n",
      "Epoch [88/100], Step [1600/4091], Loss: 548.3655\n",
      "Epoch [88/100], Step [1700/4091], Loss: 887.1276\n",
      "Epoch [88/100], Step [1800/4091], Loss: 841.7075\n",
      "Epoch [88/100], Step [1900/4091], Loss: 773.6501\n",
      "Epoch [88/100], Step [2000/4091], Loss: 689.0660\n",
      "Epoch [88/100], Step [2100/4091], Loss: 439.4400\n",
      "Epoch [88/100], Step [2200/4091], Loss: 716.4409\n",
      "Epoch [88/100], Step [2300/4091], Loss: 657.4598\n",
      "Epoch [88/100], Step [2400/4091], Loss: 627.1326\n",
      "Epoch [88/100], Step [2500/4091], Loss: 711.0718\n",
      "Epoch [88/100], Step [2600/4091], Loss: 505.7385\n",
      "Epoch [88/100], Step [2700/4091], Loss: 900.0113\n",
      "Epoch [88/100], Step [2800/4091], Loss: 676.1175\n",
      "Epoch [88/100], Step [2900/4091], Loss: 693.2958\n",
      "Epoch [88/100], Step [3000/4091], Loss: 580.7795\n",
      "Epoch [88/100], Step [3100/4091], Loss: 775.2648\n",
      "Epoch [88/100], Step [3200/4091], Loss: 720.7386\n",
      "Epoch [88/100], Step [3300/4091], Loss: 640.9890\n",
      "Epoch [88/100], Step [3400/4091], Loss: 530.3537\n",
      "Epoch [88/100], Step [3500/4091], Loss: 672.9489\n",
      "Epoch [88/100], Step [3600/4091], Loss: 507.8174\n",
      "Epoch [88/100], Step [3700/4091], Loss: 574.2776\n",
      "Epoch [88/100], Step [3800/4091], Loss: 683.5310\n",
      "Epoch [88/100], Step [3900/4091], Loss: 778.5563\n",
      "Epoch [88/100], Step [4000/4091], Loss: 670.4409\n",
      "Epoch [89/100], Step [100/4091], Loss: 677.5930\n",
      "Epoch [89/100], Step [200/4091], Loss: 620.0244\n",
      "Epoch [89/100], Step [300/4091], Loss: 571.8210\n",
      "Epoch [89/100], Step [400/4091], Loss: 643.2213\n",
      "Epoch [89/100], Step [500/4091], Loss: 895.9068\n",
      "Epoch [89/100], Step [600/4091], Loss: 746.8031\n",
      "Epoch [89/100], Step [700/4091], Loss: 554.4453\n",
      "Epoch [89/100], Step [800/4091], Loss: 456.2032\n",
      "Epoch [89/100], Step [900/4091], Loss: 698.7429\n",
      "Epoch [89/100], Step [1000/4091], Loss: 686.8406\n",
      "Epoch [89/100], Step [1100/4091], Loss: 642.8130\n",
      "Epoch [89/100], Step [1200/4091], Loss: 961.8729\n",
      "Epoch [89/100], Step [1300/4091], Loss: 624.7318\n",
      "Epoch [89/100], Step [1400/4091], Loss: 763.6371\n",
      "Epoch [89/100], Step [1500/4091], Loss: 498.9183\n",
      "Epoch [89/100], Step [1600/4091], Loss: 595.1727\n",
      "Epoch [89/100], Step [1700/4091], Loss: 633.1100\n",
      "Epoch [89/100], Step [1800/4091], Loss: 768.8367\n",
      "Epoch [89/100], Step [1900/4091], Loss: 549.0101\n",
      "Epoch [89/100], Step [2000/4091], Loss: 816.5817\n",
      "Epoch [89/100], Step [2100/4091], Loss: 746.3037\n",
      "Epoch [89/100], Step [2200/4091], Loss: 873.7412\n",
      "Epoch [89/100], Step [2300/4091], Loss: 721.6807\n",
      "Epoch [89/100], Step [2400/4091], Loss: 744.3762\n",
      "Epoch [89/100], Step [2500/4091], Loss: 728.8722\n",
      "Epoch [89/100], Step [2600/4091], Loss: 961.6298\n",
      "Epoch [89/100], Step [2700/4091], Loss: 739.3113\n",
      "Epoch [89/100], Step [2800/4091], Loss: 634.6635\n",
      "Epoch [89/100], Step [2900/4091], Loss: 673.0976\n",
      "Epoch [89/100], Step [3000/4091], Loss: 656.3663\n",
      "Epoch [89/100], Step [3100/4091], Loss: 623.3865\n",
      "Epoch [89/100], Step [3200/4091], Loss: 699.5389\n",
      "Epoch [89/100], Step [3300/4091], Loss: 614.8121\n",
      "Epoch [89/100], Step [3400/4091], Loss: 483.8190\n",
      "Epoch [89/100], Step [3500/4091], Loss: 919.3724\n",
      "Epoch [89/100], Step [3600/4091], Loss: 643.7384\n",
      "Epoch [89/100], Step [3700/4091], Loss: 405.5757\n",
      "Epoch [89/100], Step [3800/4091], Loss: 541.5732\n",
      "Epoch [89/100], Step [3900/4091], Loss: 538.2614\n",
      "Epoch [89/100], Step [4000/4091], Loss: 861.3973\n",
      "Epoch [90/100], Step [100/4091], Loss: 737.7982\n",
      "Epoch [90/100], Step [200/4091], Loss: 818.0464\n",
      "Epoch [90/100], Step [300/4091], Loss: 861.3994\n",
      "Epoch [90/100], Step [400/4091], Loss: 699.6810\n",
      "Epoch [90/100], Step [500/4091], Loss: 542.5280\n",
      "Epoch [90/100], Step [600/4091], Loss: 636.6270\n",
      "Epoch [90/100], Step [700/4091], Loss: 756.3715\n",
      "Epoch [90/100], Step [800/4091], Loss: 409.2570\n",
      "Epoch [90/100], Step [900/4091], Loss: 663.7059\n",
      "Epoch [90/100], Step [1000/4091], Loss: 932.1783\n",
      "Epoch [90/100], Step [1100/4091], Loss: 590.2748\n",
      "Epoch [90/100], Step [1200/4091], Loss: 889.4999\n",
      "Epoch [90/100], Step [1300/4091], Loss: 523.1661\n",
      "Epoch [90/100], Step [1400/4091], Loss: 546.6603\n",
      "Epoch [90/100], Step [1500/4091], Loss: 801.8372\n",
      "Epoch [90/100], Step [1600/4091], Loss: 733.1409\n",
      "Epoch [90/100], Step [1700/4091], Loss: 566.9342\n",
      "Epoch [90/100], Step [1800/4091], Loss: 560.5812\n",
      "Epoch [90/100], Step [1900/4091], Loss: 845.8735\n",
      "Epoch [90/100], Step [2000/4091], Loss: 744.7838\n",
      "Epoch [90/100], Step [2100/4091], Loss: 645.8947\n",
      "Epoch [90/100], Step [2200/4091], Loss: 864.9599\n",
      "Epoch [90/100], Step [2300/4091], Loss: 802.2872\n",
      "Epoch [90/100], Step [2400/4091], Loss: 484.1851\n",
      "Epoch [90/100], Step [2500/4091], Loss: 525.2977\n",
      "Epoch [90/100], Step [2600/4091], Loss: 679.7052\n",
      "Epoch [90/100], Step [2700/4091], Loss: 739.8949\n",
      "Epoch [90/100], Step [2800/4091], Loss: 947.1622\n",
      "Epoch [90/100], Step [2900/4091], Loss: 522.4609\n",
      "Epoch [90/100], Step [3000/4091], Loss: 444.4688\n",
      "Epoch [90/100], Step [3100/4091], Loss: 616.1923\n",
      "Epoch [90/100], Step [3200/4091], Loss: 581.2899\n",
      "Epoch [90/100], Step [3300/4091], Loss: 717.1862\n",
      "Epoch [90/100], Step [3400/4091], Loss: 824.1556\n",
      "Epoch [90/100], Step [3500/4091], Loss: 739.1240\n",
      "Epoch [90/100], Step [3600/4091], Loss: 596.8655\n",
      "Epoch [90/100], Step [3700/4091], Loss: 819.9850\n",
      "Epoch [90/100], Step [3800/4091], Loss: 745.2302\n",
      "Epoch [90/100], Step [3900/4091], Loss: 642.2201\n",
      "Epoch [90/100], Step [4000/4091], Loss: 551.1982\n",
      "Epoch [91/100], Step [100/4091], Loss: 672.0837\n",
      "Epoch [91/100], Step [200/4091], Loss: 757.0911\n",
      "Epoch [91/100], Step [300/4091], Loss: 682.8977\n",
      "Epoch [91/100], Step [400/4091], Loss: 593.2424\n",
      "Epoch [91/100], Step [500/4091], Loss: 672.1346\n",
      "Epoch [91/100], Step [600/4091], Loss: 770.6232\n",
      "Epoch [91/100], Step [700/4091], Loss: 820.1474\n",
      "Epoch [91/100], Step [800/4091], Loss: 667.8750\n",
      "Epoch [91/100], Step [900/4091], Loss: 460.6589\n",
      "Epoch [91/100], Step [1000/4091], Loss: 733.2155\n",
      "Epoch [91/100], Step [1100/4091], Loss: 750.5984\n",
      "Epoch [91/100], Step [1200/4091], Loss: 533.3583\n",
      "Epoch [91/100], Step [1300/4091], Loss: 809.6989\n",
      "Epoch [91/100], Step [1400/4091], Loss: 792.0420\n",
      "Epoch [91/100], Step [1500/4091], Loss: 634.4883\n",
      "Epoch [91/100], Step [1600/4091], Loss: 496.2141\n",
      "Epoch [91/100], Step [1700/4091], Loss: 675.7939\n",
      "Epoch [91/100], Step [1800/4091], Loss: 700.9640\n",
      "Epoch [91/100], Step [1900/4091], Loss: 652.6582\n",
      "Epoch [91/100], Step [2000/4091], Loss: 964.9834\n",
      "Epoch [91/100], Step [2100/4091], Loss: 576.6996\n",
      "Epoch [91/100], Step [2200/4091], Loss: 747.0917\n",
      "Epoch [91/100], Step [2300/4091], Loss: 521.3801\n",
      "Epoch [91/100], Step [2400/4091], Loss: 544.3167\n",
      "Epoch [91/100], Step [2500/4091], Loss: 875.9041\n",
      "Epoch [91/100], Step [2600/4091], Loss: 399.0686\n",
      "Epoch [91/100], Step [2700/4091], Loss: 695.6946\n",
      "Epoch [91/100], Step [2800/4091], Loss: 659.0823\n",
      "Epoch [91/100], Step [2900/4091], Loss: 665.1917\n",
      "Epoch [91/100], Step [3000/4091], Loss: 521.3531\n",
      "Epoch [91/100], Step [3100/4091], Loss: 566.2027\n",
      "Epoch [91/100], Step [3200/4091], Loss: 574.3100\n",
      "Epoch [91/100], Step [3300/4091], Loss: 623.6756\n",
      "Epoch [91/100], Step [3400/4091], Loss: 523.4591\n",
      "Epoch [91/100], Step [3500/4091], Loss: 779.5553\n",
      "Epoch [91/100], Step [3600/4091], Loss: 596.5632\n",
      "Epoch [91/100], Step [3700/4091], Loss: 690.7249\n",
      "Epoch [91/100], Step [3800/4091], Loss: 567.1028\n",
      "Epoch [91/100], Step [3900/4091], Loss: 522.5238\n",
      "Epoch [91/100], Step [4000/4091], Loss: 729.3970\n",
      "Epoch [92/100], Step [100/4091], Loss: 764.4827\n",
      "Epoch [92/100], Step [200/4091], Loss: 607.8141\n",
      "Epoch [92/100], Step [300/4091], Loss: 575.0576\n",
      "Epoch [92/100], Step [400/4091], Loss: 812.9467\n",
      "Epoch [92/100], Step [500/4091], Loss: 520.9734\n",
      "Epoch [92/100], Step [600/4091], Loss: 733.4340\n",
      "Epoch [92/100], Step [700/4091], Loss: 722.7014\n",
      "Epoch [92/100], Step [800/4091], Loss: 602.1414\n",
      "Epoch [92/100], Step [900/4091], Loss: 661.4429\n",
      "Epoch [92/100], Step [1000/4091], Loss: 569.4208\n",
      "Epoch [92/100], Step [1100/4091], Loss: 942.5280\n",
      "Epoch [92/100], Step [1200/4091], Loss: 621.8729\n",
      "Epoch [92/100], Step [1300/4091], Loss: 665.5990\n",
      "Epoch [92/100], Step [1400/4091], Loss: 674.3770\n",
      "Epoch [92/100], Step [1500/4091], Loss: 711.3235\n",
      "Epoch [92/100], Step [1600/4091], Loss: 801.7244\n",
      "Epoch [92/100], Step [1700/4091], Loss: 685.3362\n",
      "Epoch [92/100], Step [1800/4091], Loss: 687.7618\n",
      "Epoch [92/100], Step [1900/4091], Loss: 558.3448\n",
      "Epoch [92/100], Step [2000/4091], Loss: 645.4694\n",
      "Epoch [92/100], Step [2100/4091], Loss: 714.5544\n",
      "Epoch [92/100], Step [2200/4091], Loss: 911.3336\n",
      "Epoch [92/100], Step [2300/4091], Loss: 622.9154\n",
      "Epoch [92/100], Step [2400/4091], Loss: 796.6496\n",
      "Epoch [92/100], Step [2500/4091], Loss: 703.6652\n",
      "Epoch [92/100], Step [2600/4091], Loss: 571.1396\n",
      "Epoch [92/100], Step [2700/4091], Loss: 715.0023\n",
      "Epoch [92/100], Step [2800/4091], Loss: 619.7551\n",
      "Epoch [92/100], Step [2900/4091], Loss: 686.1769\n",
      "Epoch [92/100], Step [3000/4091], Loss: 633.1278\n",
      "Epoch [92/100], Step [3100/4091], Loss: 942.7224\n",
      "Epoch [92/100], Step [3200/4091], Loss: 471.5295\n",
      "Epoch [92/100], Step [3300/4091], Loss: 661.6949\n",
      "Epoch [92/100], Step [3400/4091], Loss: 619.8962\n",
      "Epoch [92/100], Step [3500/4091], Loss: 694.5096\n",
      "Epoch [92/100], Step [3600/4091], Loss: 570.6741\n",
      "Epoch [92/100], Step [3700/4091], Loss: 483.9035\n",
      "Epoch [92/100], Step [3800/4091], Loss: 845.3793\n",
      "Epoch [92/100], Step [3900/4091], Loss: 602.3071\n",
      "Epoch [92/100], Step [4000/4091], Loss: 700.1042\n",
      "Epoch [93/100], Step [100/4091], Loss: 535.0435\n",
      "Epoch [93/100], Step [200/4091], Loss: 791.3395\n",
      "Epoch [93/100], Step [300/4091], Loss: 832.5330\n",
      "Epoch [93/100], Step [400/4091], Loss: 784.8059\n",
      "Epoch [93/100], Step [500/4091], Loss: 729.3199\n",
      "Epoch [93/100], Step [600/4091], Loss: 780.7310\n",
      "Epoch [93/100], Step [700/4091], Loss: 525.7296\n",
      "Epoch [93/100], Step [800/4091], Loss: 876.8638\n",
      "Epoch [93/100], Step [900/4091], Loss: 836.0145\n",
      "Epoch [93/100], Step [1000/4091], Loss: 528.8166\n",
      "Epoch [93/100], Step [1100/4091], Loss: 800.4420\n",
      "Epoch [93/100], Step [1200/4091], Loss: 693.9891\n",
      "Epoch [93/100], Step [1300/4091], Loss: 514.2841\n",
      "Epoch [93/100], Step [1400/4091], Loss: 729.6609\n",
      "Epoch [93/100], Step [1500/4091], Loss: 821.7989\n",
      "Epoch [93/100], Step [1600/4091], Loss: 584.5950\n",
      "Epoch [93/100], Step [1700/4091], Loss: 436.6098\n",
      "Epoch [93/100], Step [1800/4091], Loss: 665.2485\n",
      "Epoch [93/100], Step [1900/4091], Loss: 557.4248\n",
      "Epoch [93/100], Step [2000/4091], Loss: 527.5540\n",
      "Epoch [93/100], Step [2100/4091], Loss: 824.7714\n",
      "Epoch [93/100], Step [2200/4091], Loss: 415.4864\n",
      "Epoch [93/100], Step [2300/4091], Loss: 507.4995\n",
      "Epoch [93/100], Step [2400/4091], Loss: 845.9321\n",
      "Epoch [93/100], Step [2500/4091], Loss: 570.0530\n",
      "Epoch [93/100], Step [2600/4091], Loss: 739.8737\n",
      "Epoch [93/100], Step [2700/4091], Loss: 845.5586\n",
      "Epoch [93/100], Step [2800/4091], Loss: 594.8196\n",
      "Epoch [93/100], Step [2900/4091], Loss: 544.0830\n",
      "Epoch [93/100], Step [3000/4091], Loss: 509.8792\n",
      "Epoch [93/100], Step [3100/4091], Loss: 814.6513\n",
      "Epoch [93/100], Step [3200/4091], Loss: 682.2388\n",
      "Epoch [93/100], Step [3300/4091], Loss: 594.6317\n",
      "Epoch [93/100], Step [3400/4091], Loss: 777.3237\n",
      "Epoch [93/100], Step [3500/4091], Loss: 712.5912\n",
      "Epoch [93/100], Step [3600/4091], Loss: 660.7897\n",
      "Epoch [93/100], Step [3700/4091], Loss: 599.6600\n",
      "Epoch [93/100], Step [3800/4091], Loss: 534.3428\n",
      "Epoch [93/100], Step [3900/4091], Loss: 466.2902\n",
      "Epoch [93/100], Step [4000/4091], Loss: 704.4316\n",
      "Epoch [94/100], Step [100/4091], Loss: 496.0927\n",
      "Epoch [94/100], Step [200/4091], Loss: 654.2432\n",
      "Epoch [94/100], Step [300/4091], Loss: 685.8566\n",
      "Epoch [94/100], Step [400/4091], Loss: 901.9268\n",
      "Epoch [94/100], Step [500/4091], Loss: 708.4854\n",
      "Epoch [94/100], Step [600/4091], Loss: 596.0306\n",
      "Epoch [94/100], Step [700/4091], Loss: 551.9894\n",
      "Epoch [94/100], Step [800/4091], Loss: 871.1675\n",
      "Epoch [94/100], Step [900/4091], Loss: 778.7886\n",
      "Epoch [94/100], Step [1000/4091], Loss: 545.8870\n",
      "Epoch [94/100], Step [1100/4091], Loss: 761.6504\n",
      "Epoch [94/100], Step [1200/4091], Loss: 620.1204\n",
      "Epoch [94/100], Step [1300/4091], Loss: 845.6270\n",
      "Epoch [94/100], Step [1400/4091], Loss: 675.0386\n",
      "Epoch [94/100], Step [1500/4091], Loss: 791.3579\n",
      "Epoch [94/100], Step [1600/4091], Loss: 508.3204\n",
      "Epoch [94/100], Step [1700/4091], Loss: 670.5757\n",
      "Epoch [94/100], Step [1800/4091], Loss: 639.0068\n",
      "Epoch [94/100], Step [1900/4091], Loss: 591.1185\n",
      "Epoch [94/100], Step [2000/4091], Loss: 836.0790\n",
      "Epoch [94/100], Step [2100/4091], Loss: 684.6753\n",
      "Epoch [94/100], Step [2200/4091], Loss: 615.3860\n",
      "Epoch [94/100], Step [2300/4091], Loss: 657.6434\n",
      "Epoch [94/100], Step [2400/4091], Loss: 588.5793\n",
      "Epoch [94/100], Step [2500/4091], Loss: 607.9474\n",
      "Epoch [94/100], Step [2600/4091], Loss: 700.3007\n",
      "Epoch [94/100], Step [2700/4091], Loss: 685.3065\n",
      "Epoch [94/100], Step [2800/4091], Loss: 533.3658\n",
      "Epoch [94/100], Step [2900/4091], Loss: 528.9395\n",
      "Epoch [94/100], Step [3000/4091], Loss: 706.5038\n",
      "Epoch [94/100], Step [3100/4091], Loss: 619.0869\n",
      "Epoch [94/100], Step [3200/4091], Loss: 537.7108\n",
      "Epoch [94/100], Step [3300/4091], Loss: 656.4858\n",
      "Epoch [94/100], Step [3400/4091], Loss: 556.9884\n",
      "Epoch [94/100], Step [3500/4091], Loss: 856.9267\n",
      "Epoch [94/100], Step [3600/4091], Loss: 634.0185\n",
      "Epoch [94/100], Step [3700/4091], Loss: 642.3848\n",
      "Epoch [94/100], Step [3800/4091], Loss: 722.8748\n",
      "Epoch [94/100], Step [3900/4091], Loss: 700.7446\n",
      "Epoch [94/100], Step [4000/4091], Loss: 665.9709\n",
      "Epoch [95/100], Step [100/4091], Loss: 623.6018\n",
      "Epoch [95/100], Step [200/4091], Loss: 726.0111\n",
      "Epoch [95/100], Step [300/4091], Loss: 808.0144\n",
      "Epoch [95/100], Step [400/4091], Loss: 605.3226\n",
      "Epoch [95/100], Step [500/4091], Loss: 876.2746\n",
      "Epoch [95/100], Step [600/4091], Loss: 547.5555\n",
      "Epoch [95/100], Step [700/4091], Loss: 796.6714\n",
      "Epoch [95/100], Step [800/4091], Loss: 551.9834\n",
      "Epoch [95/100], Step [900/4091], Loss: 688.3186\n",
      "Epoch [95/100], Step [1000/4091], Loss: 886.1770\n",
      "Epoch [95/100], Step [1100/4091], Loss: 600.0204\n",
      "Epoch [95/100], Step [1200/4091], Loss: 587.8665\n",
      "Epoch [95/100], Step [1300/4091], Loss: 505.1200\n",
      "Epoch [95/100], Step [1400/4091], Loss: 653.4372\n",
      "Epoch [95/100], Step [1500/4091], Loss: 671.1628\n",
      "Epoch [95/100], Step [1600/4091], Loss: 596.2626\n",
      "Epoch [95/100], Step [1700/4091], Loss: 740.1973\n",
      "Epoch [95/100], Step [1800/4091], Loss: 743.9539\n",
      "Epoch [95/100], Step [1900/4091], Loss: 497.1056\n",
      "Epoch [95/100], Step [2000/4091], Loss: 570.3683\n",
      "Epoch [95/100], Step [2100/4091], Loss: 476.2470\n",
      "Epoch [95/100], Step [2200/4091], Loss: 597.6870\n",
      "Epoch [95/100], Step [2300/4091], Loss: 793.3020\n",
      "Epoch [95/100], Step [2400/4091], Loss: 646.9433\n",
      "Epoch [95/100], Step [2500/4091], Loss: 702.4043\n",
      "Epoch [95/100], Step [2600/4091], Loss: 595.5874\n",
      "Epoch [95/100], Step [2700/4091], Loss: 728.3835\n",
      "Epoch [95/100], Step [2800/4091], Loss: 737.8466\n",
      "Epoch [95/100], Step [2900/4091], Loss: 775.3105\n",
      "Epoch [95/100], Step [3000/4091], Loss: 648.6540\n",
      "Epoch [95/100], Step [3100/4091], Loss: 811.6971\n",
      "Epoch [95/100], Step [3200/4091], Loss: 609.5046\n",
      "Epoch [95/100], Step [3300/4091], Loss: 815.4094\n",
      "Epoch [95/100], Step [3400/4091], Loss: 667.2142\n",
      "Epoch [95/100], Step [3500/4091], Loss: 484.2778\n",
      "Epoch [95/100], Step [3600/4091], Loss: 868.5408\n",
      "Epoch [95/100], Step [3700/4091], Loss: 661.1881\n",
      "Epoch [95/100], Step [3800/4091], Loss: 608.2964\n",
      "Epoch [95/100], Step [3900/4091], Loss: 668.6393\n",
      "Epoch [95/100], Step [4000/4091], Loss: 546.1337\n",
      "Epoch [96/100], Step [100/4091], Loss: 518.1376\n",
      "Epoch [96/100], Step [200/4091], Loss: 449.4291\n",
      "Epoch [96/100], Step [300/4091], Loss: 597.9877\n",
      "Epoch [96/100], Step [400/4091], Loss: 834.2826\n",
      "Epoch [96/100], Step [500/4091], Loss: 708.4720\n",
      "Epoch [96/100], Step [600/4091], Loss: 631.3169\n",
      "Epoch [96/100], Step [700/4091], Loss: 628.8628\n",
      "Epoch [96/100], Step [800/4091], Loss: 722.9161\n",
      "Epoch [96/100], Step [900/4091], Loss: 914.0652\n",
      "Epoch [96/100], Step [1000/4091], Loss: 689.6100\n",
      "Epoch [96/100], Step [1100/4091], Loss: 865.8372\n",
      "Epoch [96/100], Step [1200/4091], Loss: 520.9938\n",
      "Epoch [96/100], Step [1300/4091], Loss: 476.1405\n",
      "Epoch [96/100], Step [1400/4091], Loss: 616.5542\n",
      "Epoch [96/100], Step [1500/4091], Loss: 575.1363\n",
      "Epoch [96/100], Step [1600/4091], Loss: 991.0107\n",
      "Epoch [96/100], Step [1700/4091], Loss: 488.2592\n",
      "Epoch [96/100], Step [1800/4091], Loss: 928.2166\n",
      "Epoch [96/100], Step [1900/4091], Loss: 550.1415\n",
      "Epoch [96/100], Step [2000/4091], Loss: 704.3003\n",
      "Epoch [96/100], Step [2100/4091], Loss: 1002.7574\n",
      "Epoch [96/100], Step [2200/4091], Loss: 401.6488\n",
      "Epoch [96/100], Step [2300/4091], Loss: 593.5959\n",
      "Epoch [96/100], Step [2400/4091], Loss: 676.0963\n",
      "Epoch [96/100], Step [2500/4091], Loss: 816.1813\n",
      "Epoch [96/100], Step [2600/4091], Loss: 708.1151\n",
      "Epoch [96/100], Step [2700/4091], Loss: 779.7982\n",
      "Epoch [96/100], Step [2800/4091], Loss: 687.5967\n",
      "Epoch [96/100], Step [2900/4091], Loss: 627.5887\n",
      "Epoch [96/100], Step [3000/4091], Loss: 560.9302\n",
      "Epoch [96/100], Step [3100/4091], Loss: 770.4209\n",
      "Epoch [96/100], Step [3200/4091], Loss: 893.7124\n",
      "Epoch [96/100], Step [3300/4091], Loss: 601.4492\n",
      "Epoch [96/100], Step [3400/4091], Loss: 860.6980\n",
      "Epoch [96/100], Step [3500/4091], Loss: 609.3016\n",
      "Epoch [96/100], Step [3600/4091], Loss: 791.6348\n",
      "Epoch [96/100], Step [3700/4091], Loss: 558.6268\n",
      "Epoch [96/100], Step [3800/4091], Loss: 782.4016\n",
      "Epoch [96/100], Step [3900/4091], Loss: 550.0753\n",
      "Epoch [96/100], Step [4000/4091], Loss: 777.9384\n",
      "Epoch [97/100], Step [100/4091], Loss: 613.6940\n",
      "Epoch [97/100], Step [200/4091], Loss: 802.0920\n",
      "Epoch [97/100], Step [300/4091], Loss: 634.3032\n",
      "Epoch [97/100], Step [400/4091], Loss: 872.8558\n",
      "Epoch [97/100], Step [500/4091], Loss: 839.6163\n",
      "Epoch [97/100], Step [600/4091], Loss: 649.3974\n",
      "Epoch [97/100], Step [700/4091], Loss: 507.5095\n",
      "Epoch [97/100], Step [800/4091], Loss: 695.0270\n",
      "Epoch [97/100], Step [900/4091], Loss: 579.5605\n",
      "Epoch [97/100], Step [1000/4091], Loss: 498.6774\n",
      "Epoch [97/100], Step [1100/4091], Loss: 508.8635\n",
      "Epoch [97/100], Step [1200/4091], Loss: 575.7110\n",
      "Epoch [97/100], Step [1300/4091], Loss: 742.7277\n",
      "Epoch [97/100], Step [1400/4091], Loss: 549.6028\n",
      "Epoch [97/100], Step [1500/4091], Loss: 804.6204\n",
      "Epoch [97/100], Step [1600/4091], Loss: 826.3843\n",
      "Epoch [97/100], Step [1700/4091], Loss: 633.6873\n",
      "Epoch [97/100], Step [1800/4091], Loss: 556.5323\n",
      "Epoch [97/100], Step [1900/4091], Loss: 519.7046\n",
      "Epoch [97/100], Step [2000/4091], Loss: 813.8591\n",
      "Epoch [97/100], Step [2100/4091], Loss: 564.1853\n",
      "Epoch [97/100], Step [2200/4091], Loss: 595.2108\n",
      "Epoch [97/100], Step [2300/4091], Loss: 563.7869\n",
      "Epoch [97/100], Step [2400/4091], Loss: 851.7872\n",
      "Epoch [97/100], Step [2500/4091], Loss: 790.6950\n",
      "Epoch [97/100], Step [2600/4091], Loss: 834.5712\n",
      "Epoch [97/100], Step [2700/4091], Loss: 765.7696\n",
      "Epoch [97/100], Step [2800/4091], Loss: 548.0413\n",
      "Epoch [97/100], Step [2900/4091], Loss: 880.9536\n",
      "Epoch [97/100], Step [3000/4091], Loss: 689.5624\n",
      "Epoch [97/100], Step [3100/4091], Loss: 518.4893\n",
      "Epoch [97/100], Step [3200/4091], Loss: 735.9501\n",
      "Epoch [97/100], Step [3300/4091], Loss: 643.1530\n",
      "Epoch [97/100], Step [3400/4091], Loss: 635.0619\n",
      "Epoch [97/100], Step [3500/4091], Loss: 488.7476\n",
      "Epoch [97/100], Step [3600/4091], Loss: 862.0052\n",
      "Epoch [97/100], Step [3700/4091], Loss: 764.8279\n",
      "Epoch [97/100], Step [3800/4091], Loss: 559.1497\n",
      "Epoch [97/100], Step [3900/4091], Loss: 509.6821\n",
      "Epoch [97/100], Step [4000/4091], Loss: 664.2018\n",
      "Epoch [98/100], Step [100/4091], Loss: 577.2567\n",
      "Epoch [98/100], Step [200/4091], Loss: 698.0135\n",
      "Epoch [98/100], Step [300/4091], Loss: 670.4252\n",
      "Epoch [98/100], Step [400/4091], Loss: 597.0123\n",
      "Epoch [98/100], Step [500/4091], Loss: 717.4625\n",
      "Epoch [98/100], Step [600/4091], Loss: 592.0751\n",
      "Epoch [98/100], Step [700/4091], Loss: 649.6056\n",
      "Epoch [98/100], Step [800/4091], Loss: 612.6246\n",
      "Epoch [98/100], Step [900/4091], Loss: 562.7060\n",
      "Epoch [98/100], Step [1000/4091], Loss: 610.7131\n",
      "Epoch [98/100], Step [1100/4091], Loss: 482.5599\n",
      "Epoch [98/100], Step [1200/4091], Loss: 528.0087\n",
      "Epoch [98/100], Step [1300/4091], Loss: 661.6551\n",
      "Epoch [98/100], Step [1400/4091], Loss: 984.7106\n",
      "Epoch [98/100], Step [1500/4091], Loss: 757.0787\n",
      "Epoch [98/100], Step [1600/4091], Loss: 534.6479\n",
      "Epoch [98/100], Step [1700/4091], Loss: 656.2947\n",
      "Epoch [98/100], Step [1800/4091], Loss: 480.6629\n",
      "Epoch [98/100], Step [1900/4091], Loss: 969.7421\n",
      "Epoch [98/100], Step [2000/4091], Loss: 554.3401\n",
      "Epoch [98/100], Step [2100/4091], Loss: 719.2164\n",
      "Epoch [98/100], Step [2200/4091], Loss: 642.5376\n",
      "Epoch [98/100], Step [2300/4091], Loss: 651.0970\n",
      "Epoch [98/100], Step [2400/4091], Loss: 647.4548\n",
      "Epoch [98/100], Step [2500/4091], Loss: 449.9864\n",
      "Epoch [98/100], Step [2600/4091], Loss: 852.5646\n",
      "Epoch [98/100], Step [2700/4091], Loss: 506.0372\n",
      "Epoch [98/100], Step [2800/4091], Loss: 633.2011\n",
      "Epoch [98/100], Step [2900/4091], Loss: 842.1351\n",
      "Epoch [98/100], Step [3000/4091], Loss: 640.9442\n",
      "Epoch [98/100], Step [3100/4091], Loss: 662.0317\n",
      "Epoch [98/100], Step [3200/4091], Loss: 595.0231\n",
      "Epoch [98/100], Step [3300/4091], Loss: 542.5578\n",
      "Epoch [98/100], Step [3400/4091], Loss: 620.9647\n",
      "Epoch [98/100], Step [3500/4091], Loss: 795.2184\n",
      "Epoch [98/100], Step [3600/4091], Loss: 571.9781\n",
      "Epoch [98/100], Step [3700/4091], Loss: 529.2220\n",
      "Epoch [98/100], Step [3800/4091], Loss: 612.2773\n",
      "Epoch [98/100], Step [3900/4091], Loss: 585.7707\n",
      "Epoch [98/100], Step [4000/4091], Loss: 603.7310\n",
      "Epoch [99/100], Step [100/4091], Loss: 811.7265\n",
      "Epoch [99/100], Step [200/4091], Loss: 696.0640\n",
      "Epoch [99/100], Step [300/4091], Loss: 841.8989\n",
      "Epoch [99/100], Step [400/4091], Loss: 461.1030\n",
      "Epoch [99/100], Step [500/4091], Loss: 825.4401\n",
      "Epoch [99/100], Step [600/4091], Loss: 700.3507\n",
      "Epoch [99/100], Step [700/4091], Loss: 696.3083\n",
      "Epoch [99/100], Step [800/4091], Loss: 803.7736\n",
      "Epoch [99/100], Step [900/4091], Loss: 684.2759\n",
      "Epoch [99/100], Step [1000/4091], Loss: 766.9304\n",
      "Epoch [99/100], Step [1100/4091], Loss: 514.3539\n",
      "Epoch [99/100], Step [1200/4091], Loss: 746.3942\n",
      "Epoch [99/100], Step [1300/4091], Loss: 708.2978\n",
      "Epoch [99/100], Step [1400/4091], Loss: 395.9558\n",
      "Epoch [99/100], Step [1500/4091], Loss: 726.5968\n",
      "Epoch [99/100], Step [1600/4091], Loss: 735.6760\n",
      "Epoch [99/100], Step [1700/4091], Loss: 592.8527\n",
      "Epoch [99/100], Step [1800/4091], Loss: 587.5593\n",
      "Epoch [99/100], Step [1900/4091], Loss: 568.9337\n",
      "Epoch [99/100], Step [2000/4091], Loss: 396.9340\n",
      "Epoch [99/100], Step [2100/4091], Loss: 565.9431\n",
      "Epoch [99/100], Step [2200/4091], Loss: 992.4273\n",
      "Epoch [99/100], Step [2300/4091], Loss: 566.1947\n",
      "Epoch [99/100], Step [2400/4091], Loss: 667.1646\n",
      "Epoch [99/100], Step [2500/4091], Loss: 551.3706\n",
      "Epoch [99/100], Step [2600/4091], Loss: 585.5001\n",
      "Epoch [99/100], Step [2700/4091], Loss: 624.9103\n",
      "Epoch [99/100], Step [2800/4091], Loss: 661.2419\n",
      "Epoch [99/100], Step [2900/4091], Loss: 550.3691\n",
      "Epoch [99/100], Step [3000/4091], Loss: 751.0835\n",
      "Epoch [99/100], Step [3100/4091], Loss: 602.5579\n",
      "Epoch [99/100], Step [3200/4091], Loss: 610.0112\n",
      "Epoch [99/100], Step [3300/4091], Loss: 580.0095\n",
      "Epoch [99/100], Step [3400/4091], Loss: 705.4733\n",
      "Epoch [99/100], Step [3500/4091], Loss: 793.7687\n",
      "Epoch [99/100], Step [3600/4091], Loss: 532.6420\n",
      "Epoch [99/100], Step [3700/4091], Loss: 657.5376\n",
      "Epoch [99/100], Step [3800/4091], Loss: 854.9359\n",
      "Epoch [99/100], Step [3900/4091], Loss: 751.7831\n",
      "Epoch [99/100], Step [4000/4091], Loss: 560.2866\n",
      "Epoch [100/100], Step [100/4091], Loss: 903.1542\n",
      "Epoch [100/100], Step [200/4091], Loss: 621.3007\n",
      "Epoch [100/100], Step [300/4091], Loss: 572.3680\n",
      "Epoch [100/100], Step [400/4091], Loss: 754.2365\n",
      "Epoch [100/100], Step [500/4091], Loss: 808.1017\n",
      "Epoch [100/100], Step [600/4091], Loss: 753.5428\n",
      "Epoch [100/100], Step [700/4091], Loss: 543.7743\n",
      "Epoch [100/100], Step [800/4091], Loss: 684.6621\n",
      "Epoch [100/100], Step [900/4091], Loss: 698.4338\n",
      "Epoch [100/100], Step [1000/4091], Loss: 470.4098\n",
      "Epoch [100/100], Step [1100/4091], Loss: 629.6974\n",
      "Epoch [100/100], Step [1200/4091], Loss: 730.1832\n",
      "Epoch [100/100], Step [1300/4091], Loss: 815.0593\n",
      "Epoch [100/100], Step [1400/4091], Loss: 773.4554\n",
      "Epoch [100/100], Step [1500/4091], Loss: 636.1600\n",
      "Epoch [100/100], Step [1600/4091], Loss: 519.9846\n",
      "Epoch [100/100], Step [1700/4091], Loss: 870.6849\n",
      "Epoch [100/100], Step [1800/4091], Loss: 606.1216\n",
      "Epoch [100/100], Step [1900/4091], Loss: 767.7758\n",
      "Epoch [100/100], Step [2000/4091], Loss: 660.0012\n",
      "Epoch [100/100], Step [2100/4091], Loss: 472.9347\n",
      "Epoch [100/100], Step [2200/4091], Loss: 481.7700\n",
      "Epoch [100/100], Step [2300/4091], Loss: 546.0443\n",
      "Epoch [100/100], Step [2400/4091], Loss: 773.5378\n",
      "Epoch [100/100], Step [2500/4091], Loss: 624.3401\n",
      "Epoch [100/100], Step [2600/4091], Loss: 545.5756\n",
      "Epoch [100/100], Step [2700/4091], Loss: 566.0801\n",
      "Epoch [100/100], Step [2800/4091], Loss: 793.0356\n",
      "Epoch [100/100], Step [2900/4091], Loss: 554.6550\n",
      "Epoch [100/100], Step [3000/4091], Loss: 489.3905\n",
      "Epoch [100/100], Step [3100/4091], Loss: 581.0844\n",
      "Epoch [100/100], Step [3200/4091], Loss: 840.1837\n",
      "Epoch [100/100], Step [3300/4091], Loss: 721.9089\n",
      "Epoch [100/100], Step [3400/4091], Loss: 574.1695\n",
      "Epoch [100/100], Step [3500/4091], Loss: 735.9194\n",
      "Epoch [100/100], Step [3600/4091], Loss: 983.1670\n",
      "Epoch [100/100], Step [3700/4091], Loss: 810.0714\n",
      "Epoch [100/100], Step [3800/4091], Loss: 630.0316\n",
      "Epoch [100/100], Step [3900/4091], Loss: 532.3007\n",
      "Epoch [100/100], Step [4000/4091], Loss: 523.7706\n"
     ]
    }
   ],
   "source": [
    "criteria = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.float()  # Convert inputs to float\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criteria(outputs.squeeze(), labels.float())  # Convert labels to float\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 896230.0000\n",
      "Mean Absolute Error (MAE): 657.5516\n",
      "R-squared (R²): -0.1003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Function to evaluate metrics\n",
    "def evaluate_metrics(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in data_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.float()).squeeze()  # Model predictions\n",
    "            all_predictions.extend(outputs.numpy())  # Convert to NumPy\n",
    "            all_labels.extend(labels.float().numpy())  # Convert to NumPy\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    y_true = torch.tensor(all_labels).numpy()\n",
    "    y_pred = torch.tensor(all_predictions).numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "# Example: Evaluate on test set\n",
    "mse, mae, r2 = evaluate_metrics(model, test_loader)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
